
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E7%BB%83%E4%B9%A0/ch05/ch05/">
      
      
        <link rel="prev" href="../../ch04/ch04/">
      
      
        <link rel="next" href="../../ch06/ch06/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>第5章 深度学习计算 - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#5" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              第5章 深度学习计算
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E6%95%99%E7%A8%8B/" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/09-recurrent-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/12-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/13-computational-performance/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch04/ch04/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" checked>
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Ch05
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    第5章 深度学习计算
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    第5章 深度学习计算
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 层和块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.1 层和块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#511" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#512" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#513" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 参数管理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 参数管理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#521" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#522" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#523" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#524" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 延后初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 延后初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#531" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#532" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#533" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#54" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 自定义层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.4 自定义层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#541" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#542" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.4.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#55" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 读写文件
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.5 读写文件">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#551" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#552" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#553" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#56-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 GPU
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.6 GPU">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#561" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#562" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#563" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#564" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch09/ch09/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#51" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 层和块
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.1 层和块">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#511" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#512" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#513" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.1.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#52" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 参数管理
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.2 参数管理">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#521" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#522" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#523" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#524" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.2.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#53" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 延后初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.3 延后初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#531" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#532" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#533" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.3.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#54" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 自定义层
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.4 自定义层">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#541" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#542" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.4.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#55" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 读写文件
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.5 读写文件">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#551" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#552" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#553" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.5.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#56-gpu" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 GPU
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5.6 GPU">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#561" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#562" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#563" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#564" class="md-nav__link">
    <span class="md-ellipsis">
      练习 5.6.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch05/ch05.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch05/ch05.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="5">第5章 深度学习计算<a class="headerlink" href="#5" title="Permanent link">⚓︎</a></h1>
<h2 id="51">5.1 层和块<a class="headerlink" href="#51" title="Permanent link">⚓︎</a></h2>
<h3 id="511">练习 5.1.1<a class="headerlink" href="#511" title="Permanent link">⚓︎</a></h3>
<p>如果将MySequential中存储块的方式更改为Python列表，会出现什么样的问题？ </p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;如果将MySequential中存储块的方式从OrderedDict更改为Python列表,代码可以正常计算。但无法像<code>_modules</code>一样使用<code>net.state_dict()</code>方便的访问模型的网络结构和参数。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">MySequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
            <span class="c1"># 这里，module是Module子类的一个实例。我们把它保存在&#39;Module&#39;类的成员</span>
            <span class="c1"># 变量_modules中。_module的类型是OrderedDict</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">module</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># OrderedDict保证了按照成员添加的顺序遍历它们</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>

<span class="k">class</span> <span class="nc">MySequential_list</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># 使用list</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySequential_list</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequential</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sequential</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequential</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">X</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">MySequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">net_list</span> <span class="o">=</span> <span class="n">MySequential_list</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="c1"># 结果一样</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net_list</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="c1"># 使用_modules方便打印net的网络结构和参数，而list则无法做到</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net_list</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">net_list</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[ 0.0822, -0.1590,  0.3334,  0.5160,  0.0290,  0.2195,  0.0100, -0.1426,
         -0.2757,  0.0305]], grad_fn=&lt;AddmmBackward0&gt;)
tensor([[-1.1942e-01, -9.6460e-02, -2.7601e-01, -1.5968e-01, -1.1686e-01,
          2.4949e-01,  1.4880e-01, -1.9188e-04, -2.8319e-02,  2.5360e-01]],
       grad_fn=&lt;AddmmBackward0&gt;)
MySequential(
  (0): Linear(in_features=10, out_features=20, bias=True)
  (1): ReLU()
  (2): Linear(in_features=20, out_features=10, bias=True)
) 
 OrderedDict([(&#39;0.weight&#39;, tensor([[-0.0159, -0.0721,  0.0345, -0.2683, -0.0870,  0.0101,  0.0377,  0.1490,
          0.2500,  0.0221],
        [-0.1784, -0.0185, -0.2567, -0.0060, -0.2049, -0.2430, -0.0439,  0.1238,
         -0.2498, -0.3140],
        [ 0.1973,  0.1610, -0.0951, -0.0050,  0.2192, -0.0419,  0.0493,  0.1120,
         -0.1944, -0.0728],
        [-0.1068, -0.1210,  0.0203, -0.1285, -0.1516,  0.0395,  0.1699,  0.1095,
         -0.1498,  0.0963],
        [-0.3096,  0.0453, -0.0816,  0.2177,  0.1166,  0.3048, -0.0891,  0.2068,
          0.2328,  0.2267],
        [ 0.0821,  0.2504, -0.0873,  0.2574,  0.3162,  0.0993,  0.1835, -0.1418,
         -0.1261, -0.0138],
        [-0.1506, -0.3137,  0.1983,  0.2221, -0.3008, -0.1465,  0.2545,  0.1994,
         -0.2081, -0.1057],
        [-0.1959, -0.0709,  0.0529,  0.3097, -0.0264,  0.2153,  0.3104,  0.2884,
         -0.1512, -0.2955],
        [ 0.2716, -0.0958,  0.2383, -0.0348, -0.0171, -0.0949,  0.2012, -0.2907,
          0.1929,  0.1713],
        [-0.0049,  0.2134, -0.1321, -0.1635, -0.3051, -0.1493, -0.0559, -0.1270,
         -0.2455, -0.2395],
        [ 0.3100, -0.1215,  0.2909,  0.2133,  0.1975, -0.1940, -0.0935,  0.0140,
         -0.2544,  0.2582],
        [-0.0716,  0.2863, -0.0544, -0.0938,  0.3091, -0.1831,  0.0854,  0.1830,
         -0.1335, -0.3051],
        [ 0.1412,  0.3076,  0.0638, -0.1089,  0.0180,  0.2572, -0.3001,  0.1987,
          0.0405,  0.1663],
        [-0.1405,  0.0016,  0.2649,  0.0699, -0.0926, -0.0967, -0.2321, -0.2091,
          0.0186, -0.3146],
        [ 0.1391,  0.2191,  0.1871,  0.0192,  0.1033,  0.1934, -0.2081, -0.1284,
          0.1665,  0.2631],
        [-0.0813, -0.1420,  0.0083,  0.3141, -0.0989, -0.1864,  0.0405, -0.1168,
          0.1896, -0.0655],
        [ 0.0833, -0.0498,  0.2223, -0.0178, -0.1713, -0.2366, -0.0249, -0.2457,
         -0.1285, -0.0058],
        [ 0.2920, -0.2619, -0.1863, -0.2542, -0.0801,  0.0413,  0.0236,  0.1786,
          0.2658, -0.3041],
        [-0.1729, -0.0945,  0.1047,  0.0583,  0.2903, -0.2030,  0.0143, -0.1866,
         -0.2270,  0.0629],
        [ 0.0658, -0.0758, -0.2035,  0.1981,  0.1900, -0.1183,  0.1472, -0.2829,
          0.0759,  0.2941]])), (&#39;0.bias&#39;, tensor([-0.1290, -0.0154, -0.0583, -0.2360,  0.3113, -0.1354, -0.2150, -0.2286,
        -0.0964,  0.0213,  0.0878,  0.2771, -0.1431, -0.3004, -0.1898, -0.0153,
         0.0695,  0.0700, -0.1644, -0.1362])), (&#39;2.weight&#39;, tensor([[ 0.2045, -0.0160, -0.1549,  0.1597,  0.2128,  0.1612, -0.0414, -0.0103,
          0.0970,  0.1702, -0.1074, -0.0500,  0.0703, -0.0708,  0.2070, -0.1618,
          0.1986, -0.1340, -0.0630, -0.0056],
        [-0.0521,  0.0947, -0.0158,  0.1325,  0.0528, -0.0929, -0.0549,  0.0243,
          0.0007, -0.2142,  0.1810, -0.1177, -0.0357,  0.1703,  0.0761, -0.2005,
         -0.1043, -0.0054, -0.0211,  0.2146],
        [-0.0388, -0.1602, -0.0344, -0.0357,  0.0772,  0.0263,  0.1804,  0.2091,
         -0.0846, -0.1859, -0.1996,  0.1939, -0.1468, -0.2229, -0.0644, -0.1292,
         -0.0459,  0.1968, -0.1825,  0.0852],
        [ 0.1273, -0.0381,  0.1399,  0.0193,  0.0314,  0.1677, -0.1239, -0.0553,
         -0.0246, -0.0401,  0.1710,  0.1898, -0.2031, -0.0030,  0.1949,  0.0466,
          0.1635, -0.2140,  0.1289,  0.0867],
        [-0.0198, -0.1877, -0.0885,  0.1384,  0.0551,  0.1654,  0.1269, -0.0846,
         -0.0203, -0.1484, -0.0401,  0.2185,  0.0378, -0.2043, -0.0641, -0.0560,
          0.1028, -0.1116,  0.0670,  0.1523],
        [-0.0493,  0.1663,  0.1335, -0.0739,  0.1126, -0.0299,  0.0695,  0.0505,
         -0.0973, -0.0895,  0.2085, -0.0046, -0.1319,  0.2130, -0.0386, -0.1066,
          0.2139, -0.0151,  0.0345, -0.0830],
        [-0.1197, -0.2136, -0.0140,  0.1400,  0.1051, -0.0645, -0.0747,  0.0679,
         -0.2209, -0.2090,  0.1050, -0.1265, -0.1021,  0.0025, -0.0952,  0.1447,
         -0.1373, -0.0905, -0.1445,  0.1771],
        [-0.1452,  0.1269,  0.2035,  0.0585,  0.1895, -0.1672,  0.2019, -0.0097,
          0.2059, -0.1276, -0.1455, -0.1000,  0.0103,  0.0553,  0.0539, -0.1043,
          0.1393, -0.0054, -0.1506,  0.1984],
        [ 0.1188,  0.2172, -0.0228,  0.1151, -0.2167,  0.0092,  0.0547,  0.0314,
         -0.0467,  0.0820,  0.1775, -0.0358, -0.0477, -0.2215,  0.0163, -0.0171,
         -0.0209, -0.1883,  0.1211,  0.1746],
        [-0.1085,  0.1217,  0.0867,  0.0127, -0.1328,  0.2147,  0.0677,  0.0716,
         -0.1452, -0.1269,  0.1990,  0.0357, -0.1935, -0.0784, -0.1453,  0.2082,
          0.0435,  0.1069, -0.0628,  0.1833]])), (&#39;2.bias&#39;, tensor([-0.0767, -0.1668,  0.1875,  0.2134, -0.1747,  0.0913,  0.0118, -0.1427,
        -0.2073, -0.1263]))])
MySequential_list() 
 OrderedDict()
</code></pre></div>
<h3 id="512">练习 5.1.2<a class="headerlink" href="#512" title="Permanent link">⚓︎</a></h3>
<p>实现一个块，它以两个块为参数，例如net1和net2，并返回前向传播中两个网络的串联输出。这也被称为平行块。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在本书7.4节中GoogleLet模型中的Inception块使用了平行块技术。
下面代码实现了一个并行网络，由两个子网络组成。输入数据先分别经过两个子网络的计算，分别得到两个部分的输出结果，然后在通道维度上合并结果得到最终输出。</p>
<p>&emsp;&emsp;其中，<code>net1</code>和<code>net2</code>分别表示两个子网络，torch.cat表示在指定维度上拼接张量。输出结果的大小为torch.Size([2, 36])，其中第一个维度表示batch_size为2，第二个维度表示输出特征图的通道数为36（12+24）。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>


<span class="k">class</span> <span class="nc">Parallel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net1</span><span class="p">,</span> <span class="n">net2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net1</span><span class="o">=</span><span class="n">net1</span> <span class="c1"># 第一个子网络</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net2</span><span class="o">=</span><span class="n">net2</span> <span class="c1"># 第二个子网络</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
        <span class="n">x1</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># 第一个子网络的输出</span>
        <span class="n">x2</span><span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># 第二个子网络的输出</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">),</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 在通道维度上合并输出结果</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># 输入数据</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">24</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()))</span> <span class="c1"># 实例化并行网络</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="c1"># 输出结果的大小</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([2, 36])
</code></pre></div>
<h3 id="513">练习 5.1.3<a class="headerlink" href="#513" title="Permanent link">⚓︎</a></h3>
<p>假设我们想要连接同一网络的多个实例。实现一个函数，该函数生成同一个块的多个实例，并在此基础上构建更大的网络。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;下面代码定义了一个函数<code>create_network</code>，该函数接受四个参数：<code>num_instances</code>、<code>input_size</code>、<code>hidden_size</code> 和 <code>output_size</code>，并返回一个Sequential模型。</p>
<p>&emsp;&emsp;其中，该网络模型首先包含 <code>num_instances</code> 个相同的线性层，每个线性层有两个子层：一个输入维度为 <code>input_size</code>，输出维度为 <code>hidden_size</code> 的全连接层，和一个 ReLU 非线性激活层。然后，这 <code>hidden_size</code> 个线性层连接在一起作为整个网络的前馈部分。最后，额外添加一个输出层，其输入维度为 <code>input_size</code>，输出维度为 <code>output_size</code>。</p>
<p>&emsp;&emsp;因此，最终的网络结构是由 <code>output_size</code> 个相同的线性层组成的前馈神经网络，每个线性层内部包含一个全连接层和一个ReLU激活层，以及一个独立的输出层。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">create_network</span><span class="p">(</span><span class="n">num_instances</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
    <span class="c1"># 创建一个线性层</span>
    <span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># 创建多个实例并连接</span>
    <span class="n">instances</span> <span class="o">=</span> <span class="p">[</span><span class="n">linear_layer</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_instances</span><span class="p">)]</span>
    <span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">instances</span><span class="p">)</span>

    <span class="c1"># 添加输出层</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
    <span class="n">network</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">network</span>
<span class="c1"># 示例用法</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">create_network</span><span class="p">(</span><span class="n">num_instances</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">net</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Sequential(
  (0): Sequential(
    (0): Linear(in_features=10, out_features=5, bias=True)
    (1): ReLU()
    (2): Linear(in_features=5, out_features=10, bias=True)
  )
  (1): Sequential(
    (0): Linear(in_features=10, out_features=5, bias=True)
    (1): ReLU()
    (2): Linear(in_features=5, out_features=10, bias=True)
  )
  (2): Sequential(
    (0): Linear(in_features=10, out_features=5, bias=True)
    (1): ReLU()
    (2): Linear(in_features=5, out_features=10, bias=True)
  )
  (output): Linear(in_features=10, out_features=2, bias=True)
)
</code></pre></div>
<h2 id="52">5.2 参数管理<a class="headerlink" href="#52" title="Permanent link">⚓︎</a></h2>
<h3 id="521">练习 5.2.1<a class="headerlink" href="#521" title="Permanent link">⚓︎</a></h3>
<p>使用<code>NestMLP</code>模型，访问各个层的参数。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;引用上5.1节中的<code>NestMLP</code>模型,可以使用以下代码访问该模型各个层的参数,输出结果将显示每个层对应的参数名称、形状和具体参数。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">NestMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">NestMLP</span><span class="p">()</span>

<span class="c1"># 访问net层的参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;访问net层的参数&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, shape:</span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Parameter: </span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 访问linear层的参数</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;访问linear层的参数&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">, shape:</span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, Parameter: </span><span class="si">{</span><span class="n">param</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>访问net层的参数
Parameter name: 0.weight, shape:torch.Size([64, 20]), Parameter: Parameter containing:
tensor([[-0.1808,  0.1623,  0.1909,  ...,  0.0106,  0.0485, -0.1297],
        [ 0.0486,  0.0337, -0.1276,  ...,  0.1684,  0.1599, -0.1760],
        [ 0.1231,  0.0936,  0.1819,  ..., -0.1704, -0.1879,  0.0596],
        ...,
        [-0.0950,  0.1598, -0.0491,  ..., -0.0407,  0.0716, -0.0979],
        [-0.1242,  0.2079,  0.1782,  ..., -0.1273,  0.1436, -0.2166],
        [-0.2123, -0.0288,  0.1501,  ...,  0.1547,  0.0819,  0.0293]],
       requires_grad=True)
Parameter name: 0.bias, shape:torch.Size([64]), Parameter: Parameter containing:
tensor([-0.1261, -0.0023,  0.0281, -0.0212,  0.1164, -0.1347,  0.1767,  0.1912,
        -0.1671, -0.0260,  0.1449, -0.0187, -0.0012,  0.1228,  0.0514, -0.1662,
        -0.2011, -0.2227, -0.0638, -0.1534,  0.2052,  0.0034, -0.1758,  0.0989,
         0.0733,  0.1926, -0.0881,  0.0852,  0.1977,  0.1340,  0.0270,  0.1664,
        -0.0567,  0.0511, -0.0518,  0.1008,  0.0869,  0.0298, -0.0761,  0.0583,
        -0.1586,  0.1321, -0.0922,  0.0719,  0.1676,  0.0500, -0.1327,  0.1057,
         0.0687, -0.2095, -0.1943,  0.0591, -0.2097,  0.1565,  0.1494,  0.1002,
        -0.0552,  0.0946, -0.0186,  0.0429,  0.2049, -0.1003, -0.2212,  0.0837],
       requires_grad=True)
Parameter name: 2.weight, shape:torch.Size([32, 64]), Parameter: Parameter containing:
tensor([[-0.0622,  0.0184,  0.0581,  ...,  0.0973, -0.0306,  0.0617],
        [-0.0218,  0.0515,  0.0183,  ...,  0.0367,  0.0720, -0.0936],
        [-0.1094,  0.0040, -0.1073,  ..., -0.0152, -0.0694,  0.0299],
        ...,
        [ 0.0685, -0.0158, -0.0579,  ...,  0.0384, -0.0336, -0.0009],
        [ 0.0295,  0.0049,  0.0573,  ...,  0.0113, -0.0152,  0.0805],
        [-0.1228,  0.0676, -0.0697,  ..., -0.0804, -0.0315,  0.0960]],
       requires_grad=True)
Parameter name: 2.bias, shape:torch.Size([32]), Parameter: Parameter containing:
tensor([ 0.0332, -0.0710, -0.0883,  0.1078,  0.0642, -0.0313,  0.0398, -0.0952,
         0.0641,  0.0624,  0.0576, -0.0333,  0.0714,  0.1044, -0.0732,  0.0477,
        -0.0283,  0.0032,  0.1023, -0.0056,  0.0940,  0.0739, -0.1093, -0.0777,
         0.0723,  0.1116,  0.1102, -0.1202, -0.0717, -0.0863,  0.0949,  0.0335],
       requires_grad=True)
访问linear层的参数
Parameter name: weight, shape:torch.Size([16, 32]), Parameter: Parameter containing:
tensor([[-0.0232, -0.0074,  0.1396,  0.0738, -0.0259,  0.0405, -0.1646, -0.1197,
          0.1180, -0.1047,  0.0617, -0.1469, -0.0458,  0.1325,  0.1365, -0.0445,
          0.1145,  0.0715, -0.0149,  0.0984,  0.1517, -0.1463,  0.1390, -0.1377,
          0.1494, -0.0851, -0.0335,  0.1598, -0.0165, -0.1292, -0.0101,  0.0614],
        [ 0.0951,  0.1639,  0.1425,  0.0471, -0.0065,  0.1242,  0.1740,  0.0798,
         -0.1496,  0.1044,  0.0049, -0.0039,  0.0507,  0.1219, -0.1344, -0.0739,
          0.0153, -0.1608,  0.0176,  0.1231,  0.1180,  0.1196,  0.0942,  0.1668,
         -0.1735,  0.0610, -0.0822, -0.1125,  0.0139,  0.0715, -0.1311, -0.1524],
        [ 0.1722, -0.0933, -0.0183, -0.1403,  0.1073,  0.0237, -0.0722,  0.0828,
          0.1526, -0.0265,  0.1055,  0.0238,  0.1518, -0.0095,  0.1459, -0.0948,
         -0.0592,  0.0595, -0.0323,  0.1172, -0.0226, -0.0537, -0.0524, -0.1173,
         -0.0489, -0.1416,  0.1185,  0.1506,  0.0756, -0.0858,  0.0110, -0.0134],
        [-0.1483, -0.0189, -0.1632,  0.0639, -0.1736,  0.0263,  0.0949,  0.1423,
          0.1441, -0.1204, -0.0571, -0.0095, -0.0934, -0.0541, -0.0071,  0.0778,
          0.1376, -0.0952,  0.0384,  0.1614, -0.0972, -0.0686,  0.0631, -0.0041,
         -0.0480,  0.0125,  0.0343, -0.0615, -0.0559,  0.0343,  0.0858, -0.0640],
        [ 0.0062, -0.1718,  0.0104, -0.1249,  0.0289, -0.1222,  0.1176,  0.0595,
          0.1318,  0.1251,  0.1452,  0.1133, -0.0116,  0.0924,  0.0341,  0.0296,
         -0.1584,  0.1635,  0.1280,  0.1457,  0.1399,  0.1513,  0.1663, -0.0917,
         -0.1226, -0.0156, -0.1078, -0.1649, -0.0122,  0.0927,  0.0417,  0.0039],
        [-0.1019,  0.0150, -0.0196, -0.0307, -0.1435, -0.1224, -0.0149, -0.0350,
         -0.1457,  0.1388,  0.0321,  0.0796, -0.1161, -0.0784, -0.1638, -0.0651,
          0.1356, -0.1720,  0.0965,  0.0289,  0.0681, -0.0177, -0.1409,  0.1049,
         -0.0814,  0.0763,  0.1512,  0.1510, -0.1766, -0.1671,  0.0180, -0.1098],
        [-0.1238,  0.1767, -0.0090, -0.1724, -0.0894,  0.1031, -0.1674,  0.0348,
          0.1493,  0.1279, -0.1717,  0.1240, -0.0945, -0.0093,  0.1411,  0.0792,
          0.0471, -0.0120, -0.1017,  0.0428, -0.0915, -0.1454,  0.0993, -0.0714,
          0.0747,  0.1250,  0.1745, -0.1377,  0.0760, -0.0355, -0.1333,  0.0544],
        [-0.1462,  0.1400,  0.0823,  0.0624, -0.0666,  0.0298, -0.0386, -0.1449,
         -0.0784,  0.1730, -0.1150, -0.1504, -0.0391, -0.1244,  0.1157,  0.1280,
         -0.1670, -0.1242,  0.0244, -0.0424,  0.0276, -0.0282,  0.1302,  0.1720,
          0.0151, -0.1006, -0.0725, -0.0294,  0.0299, -0.0053,  0.0720,  0.0312],
        [ 0.1512,  0.1465, -0.0214, -0.0329, -0.1551, -0.1160, -0.1711,  0.1499,
         -0.1559, -0.1560,  0.0519,  0.0681, -0.0929, -0.1707,  0.1708,  0.0207,
          0.0358,  0.0963, -0.0357, -0.1649, -0.0066,  0.0862,  0.0841,  0.0528,
         -0.1014,  0.0213,  0.1427,  0.0799, -0.0530,  0.1383,  0.1750, -0.0412],
        [-0.0015,  0.1362, -0.1036,  0.1521,  0.0428,  0.1214, -0.0891,  0.1622,
          0.0051,  0.1049, -0.1496,  0.1162,  0.0525, -0.1709,  0.0388,  0.0997,
         -0.0933, -0.0578, -0.1116, -0.1219, -0.1161, -0.0573,  0.1610,  0.0816,
          0.1637,  0.1071,  0.1735,  0.0611, -0.1755, -0.0262,  0.1059, -0.0502],
        [-0.1590, -0.1014, -0.0301,  0.1680,  0.1743, -0.0944, -0.1628,  0.1520,
         -0.1077, -0.0240, -0.0518, -0.1610,  0.1062,  0.0675,  0.0750,  0.1533,
          0.1645,  0.0941, -0.0317,  0.1616,  0.1691, -0.1415,  0.0816, -0.1539,
          0.0551, -0.0873,  0.1093, -0.0014, -0.0646,  0.0296,  0.0099,  0.0821],
        [-0.0776,  0.0437,  0.1527,  0.0721,  0.1172, -0.1365, -0.0709, -0.1444,
         -0.0107, -0.0096,  0.0436, -0.1741,  0.0384, -0.0547,  0.0973, -0.1340,
         -0.1163, -0.1587,  0.0155, -0.0050, -0.1426, -0.1644, -0.0285,  0.1734,
          0.0310,  0.1168,  0.0195, -0.0133, -0.1557, -0.0277, -0.1099, -0.1665],
        [-0.1351,  0.0648, -0.1566,  0.1130, -0.1280, -0.1355,  0.1487,  0.1617,
          0.0101,  0.1749,  0.0658, -0.0783, -0.0760,  0.0182, -0.1726, -0.0524,
         -0.0842,  0.0378, -0.0885, -0.1729, -0.1124,  0.1251, -0.0356, -0.1331,
         -0.1463,  0.0752,  0.0150, -0.1492, -0.1112, -0.1569, -0.0942, -0.1177],
        [ 0.1064,  0.1641, -0.0470, -0.1650, -0.0817, -0.0256,  0.0727,  0.0006,
         -0.0386,  0.1136,  0.0664, -0.0881, -0.1431,  0.0073,  0.1605, -0.1007,
          0.0932, -0.1090,  0.1740, -0.1245, -0.1634, -0.0978,  0.0419, -0.1756,
         -0.1634, -0.0036, -0.1719, -0.1329,  0.1040, -0.1101, -0.0228, -0.0696],
        [ 0.0607, -0.1152,  0.0515, -0.1260,  0.0946,  0.0849, -0.0166,  0.0661,
         -0.1080,  0.1381,  0.0205, -0.1644,  0.1621,  0.1494, -0.0393, -0.1761,
          0.1229, -0.0595, -0.0349,  0.0861, -0.0183,  0.1491, -0.0850, -0.1251,
         -0.1227, -0.0830,  0.1248, -0.1408,  0.0043,  0.1699, -0.0942, -0.0666],
        [-0.1370, -0.1550, -0.0089,  0.0830,  0.1532,  0.1474, -0.0253, -0.1312,
          0.0644, -0.0508,  0.0944, -0.1388, -0.1637, -0.0980, -0.0410,  0.0174,
         -0.0032,  0.0544, -0.1290, -0.0948,  0.1059,  0.0469, -0.1130,  0.0791,
          0.0410, -0.0457,  0.0691, -0.1226,  0.0160, -0.1255, -0.0521,  0.0237]],
       requires_grad=True)
Parameter name: bias, shape:torch.Size([16]), Parameter: Parameter containing:
tensor([-0.0587, -0.1316, -0.1294,  0.0608,  0.0629, -0.0954, -0.0122, -0.0232,
        -0.0588, -0.0454, -0.0374,  0.1164,  0.1096, -0.1144, -0.1118, -0.0008],
       requires_grad=True)
</code></pre></div>
<h3 id="522">练习 5.2.2<a class="headerlink" href="#522" title="Permanent link">⚓︎</a></h3>
<p>查看初始化模块文档以了解不同的初始化方法。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;通过查看深度学习框架文档，有以下初始化方法 （参考链接：https://pytorch.org/docs/stable/nn.init.html ）
- <code>torch.nn.init.uniform_(tensor, a=0.0, b=1.0)</code>：从均匀分布<span class="arithmatex">\(U(a,b)\)</span>中提取填充输入张量。</p>
<ul>
<li>
<p><code>torch.nn.init.normal_(tensor, mean=0.0, std=1.0)</code>：从正态分布<span class="arithmatex">\(N(mean, std^2)\)</span>中提取填充输入张量。</p>
</li>
<li>
<p><code>torch.nn.init.constant_(tensor, val)</code>：以一确定数值初始化张量。</p>
</li>
<li>
<p><code>torch.nn.init.ones_(tensor)</code>：用标量值 1 填充输入张量。</p>
</li>
<li>
<p><code>torch.nn.init.zeros_(tensor)</code>：用标量值 0 填充输入张量。</p>
</li>
<li>
<p><code>torch.nn.init.eye_(tensor)</code>：用单位矩阵填充二维输入张量。</p>
</li>
<li>
<p><code>torch.nn.init.xavier_uniform_(tensor, gain=1.0)</code>：从均匀分布<span class="arithmatex">\(U(−a, a)\)</span>中采样，初始化输入张量，其中<span class="arithmatex">\(a\)</span>的值由如下公式确定</p>
</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(a= gain * \sqrt{\frac{6}{fan_{in}+fan_{out}}}\)</span>\)</span></p>
<p>其中<span class="arithmatex">\(gain\)</span>的取值如下表所示</p>
<table>
<thead>
<tr>
<th>非线性函数</th>
<th>gain值</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linear/Identity</td>
<td>1</td>
</tr>
<tr>
<td>Conv1D</td>
<td>1</td>
</tr>
<tr>
<td>Conv2D</td>
<td>1</td>
</tr>
<tr>
<td>Conv3D</td>
<td>1</td>
</tr>
<tr>
<td>Sigmoid</td>
<td>1</td>
</tr>
<tr>
<td>Tanh</td>
<td><span class="arithmatex">\(\displaystyle\frac{5}{3}\)</span></td>
</tr>
<tr>
<td>ReLU</td>
<td><span class="arithmatex">\(\sqrt{2}\)</span></td>
</tr>
<tr>
<td>Leaky ReLU</td>
<td><span class="arithmatex">\(<span class="arithmatex">\(\sqrt{\frac{2}{1+negative\_slope^2}}\)</span>\)</span></td>
</tr>
<tr>
<td>SELU</td>
<td>1 (adaptive)</td>
</tr>
</tbody>
</table>
<ul>
<li><code>torch.nn.init.xavier_normal_(tensor, gain=1.0)</code>:从正态分布<span class="arithmatex">\(N(0,std^2)\)</span>中采样，初始化输入张量，其中std值由下式确定：</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(a= gain * \sqrt{\frac{2}{fan_{in}+fan_{out}}}\)</span>\)</span></p>
<ul>
<li><code>torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')</code>:服从均匀分布<span class="arithmatex">\(U(−bound, bound)\)</span>，其中<span class="arithmatex">\(bound\)</span>值由下式确定</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(bound= gain * \sqrt{\frac{3}{fan_{mode}}}\)</span>\)</span></p>
<ul>
<li><code>torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')</code>:服从从正态分布<span class="arithmatex">\(N(0,std^2)\)</span>中采样，其中<span class="arithmatex">\(std\)</span>值由下式确定</li>
</ul>
<p><span class="arithmatex">\(<span class="arithmatex">\(std= \frac{gain}{\sqrt{fan_{mode}}}\)</span>\)</span></p>
<ul>
<li>
<p><code>torch.nn.init.trunc_normal_(tensor, mean=0.0, std=1.0, a=- 2.0, b=2.0)</code>:用从截断的正态分布中提取的值填充输入张量。这些值实际上是从正态分布 <span class="arithmatex">\(N(mean, std^2)\)</span>中提取的。</p>
</li>
<li>
<p><code>torch.nn.init.sparse_(tensor, sparsity, std=0.01)</code>：将 2D 输入张量填充为稀疏矩阵，其中非零元素将从正态分布<span class="arithmatex">\(N(0,0.01)\)</span>中提取。</p>
</li>
</ul>
<h3 id="523">练习 5.2.3<a class="headerlink" href="#523" title="Permanent link">⚓︎</a></h3>
<p>构建包含共享参数层的多层感知机并对其进行训练。在训练过程中，观察模型各层的参数和梯度。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;在训练过程中，我们每个epoch都打印了每层的参数和梯度。可以看到shared_fc层的参数和梯度都是相同的，因为它们共享同一个参数。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># 模型参数</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># 构建带有共享参数层的多层感知机</span>
<span class="n">shared_fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<span class="n">MLP</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">shared_fc</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">shared_fc</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># 训练数据</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="c1"># 优化器</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">MLP</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="c1"># 训练模型</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># 前向传播和计算损失</span>
    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="c1"># 反向传播和更新梯度</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># 打印每层的参数和梯度</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">MLP</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: </span><span class="si">{}</span><span class="s1">, Loss: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>0.weight tensor([[-0.1223, -0.2865, -0.1142, -0.1206],
        [ 0.0428,  0.0664, -0.3060, -0.2732],
        [-0.2939,  0.3809,  0.4409,  0.2039],
        [-0.2752,  0.1679,  0.3662,  0.4009],
        [ 0.3634, -0.1864,  0.2473,  0.2193],
        [ 0.2975, -0.3068,  0.3993, -0.3316],
        [-0.1651, -0.0725,  0.1861,  0.4409],
        [ 0.4155,  0.1977,  0.2613, -0.2014]]) tensor([[ 0.0000,  0.0000, -0.0000,  0.0000],
        [-0.2118, -0.0760,  0.1077, -0.0336],
        [ 0.0000,  0.0000, -0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.0000,  0.0000],
        [-0.1781, -0.0639,  0.0906, -0.0283],
        [ 0.0000,  0.0000, -0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.0000,  0.0000],
        [-0.1566, -0.0562,  0.0796, -0.0249]])
0.bias tensor([ 0.3000, -0.1717,  0.4032, -0.0697, -0.2140, -0.3950, -0.2322, -0.2666]) tensor([ 0.0000, -0.0968,  0.0000,  0.0000, -0.0814,  0.0000,  0.0000, -0.0716])
2.weight tensor([[-0.2533, -0.2829, -0.2677,  0.1634, -0.1019,  0.1053, -0.1058,  0.2976],
        [ 0.2634, -0.0198, -0.1916,  0.0107, -0.1541, -0.2566,  0.0304,  0.3258],
        [-0.2977, -0.1825,  0.1853, -0.2739, -0.2335,  0.1091, -0.0049, -0.2277],
        [-0.2091, -0.3297, -0.1003,  0.0363, -0.3410,  0.2284,  0.1777, -0.1423],
        [-0.0588, -0.0658, -0.1319, -0.2297,  0.3178, -0.2209, -0.3093, -0.2859],
        [-0.0958, -0.1032,  0.3259, -0.0770, -0.0698, -0.2427,  0.2445, -0.2620],
        [ 0.3108, -0.1900,  0.3295,  0.3409,  0.3048,  0.2717, -0.2628,  0.0300],
        [-0.2384, -0.3000,  0.2284, -0.3389, -0.2287,  0.0040,  0.1502, -0.0355]]) tensor([[ 0.0133,  0.0644,  0.0000,  0.0119,  0.0738,  0.0000,  0.0034,  0.0991],
        [ 0.0303,  0.0297,  0.0000,  0.0272,  0.0414,  0.0000,  0.0078, -0.0126],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0163,  0.0722,  0.0000,  0.0146,  0.0832,  0.0000,  0.0042,  0.1078],
        [ 0.0210,  0.0708,  0.0000,  0.0188,  0.0831,  0.0000,  0.0054,  0.0936],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0524,  0.0761,  0.0000,  0.0469,  0.0984,  0.0000,  0.0134,  0.0289],
        [-0.0084, -0.0036,  0.0000, -0.0075, -0.0065,  0.0000, -0.0022,  0.0128]])
2.bias tensor([ 0.0603,  0.1333, -0.2945,  0.3031,  0.3488, -0.0981, -0.0183,  0.3488]) tensor([ 0.2903,  0.1092,  0.0000,  0.3240,  0.3125,  0.0000,  0.3057, -0.0086])
6.weight tensor([[-0.3528, -0.2028, -0.1961,  0.3527, -0.1456,  0.0696,  0.3069,  0.1214],
        [ 0.1391,  0.0669,  0.0042,  0.2146, -0.2063, -0.1007,  0.2317, -0.0355],
        [ 0.2470, -0.0490,  0.0801,  0.2788, -0.3073, -0.1294, -0.1830, -0.2430],
        [ 0.1278,  0.2530,  0.0247, -0.0373,  0.2861,  0.2157,  0.2341, -0.0928]]) tensor([[ 0.0043,  0.0450,  0.0000,  0.0207,  0.0793,  0.0000,  0.0228,  0.0360],
        [ 0.0102,  0.1064,  0.0000,  0.0489,  0.1874,  0.0000,  0.0540,  0.0851],
        [-0.0011, -0.0117, -0.0000, -0.0054, -0.0206, -0.0000, -0.0059, -0.0093],
        [ 0.0200,  0.2093,  0.0000,  0.0961,  0.3685,  0.0000,  0.1062,  0.1674]])
6.bias tensor([-0.1153,  0.0429,  0.1363, -0.0886]) tensor([ 0.2409,  0.5692, -0.0625,  1.1196])
Epoch: 0, Loss: 1.639384150505066
0.weight tensor([[-0.1223, -0.2865, -0.1142, -0.1206],
        [ 0.0449,  0.0672, -0.3071, -0.2729],
        [-0.2939,  0.3809,  0.4409,  0.2039],
        [-0.2752,  0.1679,  0.3662,  0.4009],
        [ 0.3652, -0.1857,  0.2464,  0.2196],
        [ 0.2975, -0.3068,  0.3993, -0.3316],
        [-0.1651, -0.0725,  0.1861,  0.4409],
        [ 0.4171,  0.1983,  0.2605, -0.2012]]) tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.2112, -0.0758,  0.1074, -0.0335],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.1782, -0.0639,  0.0906, -0.0283],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [-0.1550, -0.0556,  0.0788, -0.0246]])
0.bias tensor([ 0.3000, -0.1707,  0.4032, -0.0697, -0.2131, -0.3950, -0.2322, -0.2659]) tensor([ 0.0000, -0.0965,  0.0000,  0.0000, -0.0815,  0.0000,  0.0000, -0.0708])
2.weight tensor([[-0.2534, -0.2835, -0.2677,  0.1633, -0.1027,  0.1053, -0.1058,  0.2966],
        [ 0.2631, -0.0201, -0.1916,  0.0105, -0.1545, -0.2566,  0.0303,  0.3260],
        [-0.2977, -0.1825,  0.1853, -0.2739, -0.2335,  0.1091, -0.0049, -0.2277],
        [-0.2093, -0.3304, -0.1003,  0.0361, -0.3418,  0.2284,  0.1777, -0.1433],
        [-0.0590, -0.0665, -0.1319, -0.2298,  0.3170, -0.2209, -0.3093, -0.2868],
        [-0.0958, -0.1032,  0.3259, -0.0770, -0.0698, -0.2427,  0.2445, -0.2620],
        [ 0.3103, -0.1908,  0.3295,  0.3405,  0.3039,  0.2717, -0.2629,  0.0298],
        [-0.2383, -0.3000,  0.2284, -0.3388, -0.2286,  0.0040,  0.1502, -0.0356]]) tensor([[ 0.0126,  0.0649,  0.0000,  0.0106,  0.0736,  0.0000,  0.0030,  0.0985],
        [ 0.0285,  0.0276,  0.0000,  0.0241,  0.0384,  0.0000,  0.0068, -0.0146],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0153,  0.0727,  0.0000,  0.0129,  0.0828,  0.0000,  0.0037,  0.1074],
        [ 0.0194,  0.0695,  0.0000,  0.0164,  0.0806,  0.0000,  0.0047,  0.0911],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0496,  0.0739,  0.0000,  0.0419,  0.0945,  0.0000,  0.0119,  0.0261],
        [-0.0082, -0.0036,  0.0000, -0.0069, -0.0064,  0.0000, -0.0020,  0.0129]])
2.bias tensor([ 0.0574,  0.1323, -0.2945,  0.2998,  0.3458, -0.0981, -0.0213,  0.3489]) tensor([ 0.2871,  0.1065,  0.0000,  0.3208,  0.3036,  0.0000,  0.3030, -0.0108])
6.weight tensor([[-0.3529, -0.2033, -0.1961,  0.3525, -0.1464,  0.0696,  0.3067,  0.1211],
        [ 0.1391,  0.0659,  0.0042,  0.2141, -0.2081, -0.1007,  0.2312, -0.0364],
        [ 0.2470, -0.0489,  0.0801,  0.2788, -0.3071, -0.1294, -0.1829, -0.2430],
        [ 0.1276,  0.2510,  0.0247, -0.0382,  0.2825,  0.2157,  0.2332, -0.0945]]) tensor([[ 0.0033,  0.0439,  0.0000,  0.0201,  0.0786,  0.0000,  0.0206,  0.0370],
        [ 0.0077,  0.1036,  0.0000,  0.0474,  0.1854,  0.0000,  0.0485,  0.0873],
        [-0.0009, -0.0115,  0.0000, -0.0053, -0.0205,  0.0000, -0.0054, -0.0097],
        [ 0.0152,  0.2039,  0.0000,  0.0934,  0.3651,  0.0000,  0.0955,  0.1719]])
6.bias tensor([-0.1177,  0.0373,  0.1369, -0.0997]) tensor([ 0.2392,  0.5642, -0.0625,  1.1109])
Epoch: 1, Loss: 1.613648772239685
</code></pre></div>
<h3 id="524">练习 5.2.4<a class="headerlink" href="#524" title="Permanent link">⚓︎</a></h3>
<p>为什么共享参数是个好主意？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;1. 节约内存：共享参数可以减少模型中需要存储的参数数量，从而减少内存占用。</p>
<p>&emsp;&emsp;2. 加速收敛：共享参数可以让模型更加稳定，加速收敛。</p>
<p>&emsp;&emsp;3. 提高泛化能力：共享参数可以帮助模型更好地捕捉数据中的共性，提高模型的泛化能力。</p>
<p>&emsp;&emsp;4. 加强模型的可解释性：共享参数可以让模型更加简洁明了，加强模型的可解释性。 </p>
<h2 id="53">5.3 延后初始化<a class="headerlink" href="#53" title="Permanent link">⚓︎</a></h2>
<h3 id="531">练习 5.3.1<a class="headerlink" href="#531" title="Permanent link">⚓︎</a></h3>
<p>如果指定了第一层的输入尺寸，但没有指定后续层的尺寸，会发生什么？是否立即进行初始化？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;可以正常运行。第一层会立即初始化,但其他层是直到数据第一次通过模型传递才会初始化。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="sd">&quot;&quot;&quot;延后初始化&quot;&quot;&quot;</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="c1"># 尚未初始化</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Sequential(
  (0): LazyLinear(in_features=0, out_features=256, bias=True)
  (1): ReLU()
  (2): LazyLinear(in_features=0, out_features=10, bias=True)
)
Sequential(
  (0): Linear(in_features=20, out_features=256, bias=True)
  (1): ReLU()
  (2): Linear(in_features=256, out_features=10, bias=True)
)
</code></pre></div>
<h3 id="532">练习 5.3.2<a class="headerlink" href="#532" title="Permanent link">⚓︎</a></h3>
<p>如果指定了不匹配的维度会发生什么？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;会由于矩阵乘法的维度不匹配而报错。在下面的代码中便指定了不匹配的维度。</p>
<p>&emsp;&emsp;由于第一层 nn.Linear(20, 256) 的输入维度为 20，所以输入数据 X 的最后一维必须为 20 才能与该层的权重矩阵相乘。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>mat1 and mat2 shapes cannot be multiplied (2x10 and 20x256)
</code></pre></div>
<h3 id="533">练习 5.3.3<a class="headerlink" href="#533" title="Permanent link">⚓︎</a></h3>
<p>如果输入具有不同的维度，需要做什么？提示：查看参数绑定的相关内容。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;添加一个额外的线性层，并将第一个线性层的权重与该层的权重绑定在一起。这样就可以解决维度不匹配的问题，并且保持模型的权重不变。注意，在上面的代码中，我们假设第一个线性层的偏置项为零，因此不需要对其进行参数绑定。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># 添加额外的线性层</span>
<span class="n">extra_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>

<span class="c1"># 将第一个线性层与额外的线性层的权重进行绑定</span>
<span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">extra_layer</span><span class="o">.</span><span class="n">weight</span>

<span class="c1"># 使用新的输入（维度为20）调用模型</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[-0.0332, -0.2036,  0.0035,  0.0578, -0.0328,  0.0436, -0.1417,  0.0474,
          0.1288,  0.0482],
        [-0.0327, -0.1565,  0.0213,  0.0434, -0.0187,  0.0178, -0.1491, -0.0147,
          0.0906,  0.0088]], grad_fn=&lt;AddmmBackward0&gt;)
</code></pre></div>
<h2 id="54">5.4 自定义层<a class="headerlink" href="#54" title="Permanent link">⚓︎</a></h2>
<h3 id="541">练习 5.4.1<a class="headerlink" href="#541" title="Permanent link">⚓︎</a></h3>
<p>设计一个接受输入并计算张量降维的层，它返回<span class="arithmatex">\(y_k = \sum_{i, j} W_{ijk} x_i x_j\)</span>。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;这个公式表示一个线性变换，将输入张量<span class="arithmatex">\(x\)</span>中所有可能的二元组<span class="arithmatex">\((x_i,x_j)\)</span>进行组合，并对它们进行加权求和。其中，<span class="arithmatex">\(W_{ijk}\)</span>表示权重张量中第<span class="arithmatex">\(i,j,k\)</span>个元素的值。具体而言，该公式计算了输入张量<span class="arithmatex">\(x\)</span>中所有二元组<span class="arithmatex">\((x_i, x_j)\)</span>对应的特征向量<span class="arithmatex">\(u_{ij}\)</span>为：</p>
<div class="arithmatex">\[
u_{ij} = x_i \cdot x_j
\]</div>
<p>&emsp;&emsp;然后，根据权重张量<span class="arithmatex">\(W\)</span>中的权重<span class="arithmatex">\(W_{ijk}\)</span>，对所有特征向量<span class="arithmatex">\(u_{ij}\)</span>进行线性组合，得到输出向量<span class="arithmatex">\(y_k\)</span>为：</p>
<div class="arithmatex">\[
y_k = \sum_{i,j} W_{ijk} u_{ij} = \sum_{i,j} W_{ijk} x_i x_j
\]</div>
<p>&emsp;&emsp;该操作可以被视为一种降维操作，将高维输入<span class="arithmatex">\(x\)</span>映射到低维输出空间<span class="arithmatex">\(y\)</span>中。</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">TensorReduction</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TensorReduction</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 定义一个可训练的权重参数，维度为(dim2, dim1, dim1)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">dim2</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">dim1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="c1"># 初始化一个全零张量，大小为(X.shape[0], self.weight.shape[0])</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="c1"># 计算temp = X @ weight[k] @ X^T</span>
            <span class="n">temp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span>
            <span class="c1"># 取temp的对角线元素，存入Y[:, k]</span>
            <span class="n">Y</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">Y</span>

<span class="c1"># 创建一个TensorReduction层，dim1=10, dim2=5</span>
<span class="n">layer</span> <span class="o">=</span> <span class="n">TensorReduction</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="c1"># 创建一个大小为(2, 10)的张量X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># 对layer(X)进行前向传播，返回一个大小为(2, 5)的张量</span>
<span class="n">layer</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([2, 5])
</code></pre></div>
<h3 id="542">练习 5.4.2<a class="headerlink" href="#542" title="Permanent link">⚓︎</a></h3>
<p>设计一个返回输入数据的傅立叶系数前半部分的层。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;根据<a href="https://en.wikipedia.org/wiki/Fourier_series">维基百科</a>中:</p>
<blockquote>
<p>&emsp;&emsp;傅里叶级数是将任意周期函数表示为一组正弦和余弦函数的无限级数的方法。假设<span class="arithmatex">\(f(x)\)</span>是在区间<span class="arithmatex">\([-L,L]\)</span>中定义的一个函数，其周期为<span class="arithmatex">\(2L\)</span>，则其傅里叶级数可表示为：</p>
<div class="arithmatex">\[f(x) = \frac{a_0}{2} + \sum_{n=1}^{\infty} [a_n \cos(\frac{n\pi x}{L}) + b_n \sin(\frac{n\pi x}{L})]\]</div>
<p>&emsp;&emsp;其中，系数<span class="arithmatex">\(a_0, a_n\)</span>和<span class="arithmatex">\(b_n\)</span>可以通过以下公式计算得出：</p>
<div class="arithmatex">\[a_0 = \frac{1}{2L} \int_{-L}^{L} f(x)dx\]</div>
<div class="arithmatex">\[a_n = \frac{1}{L} \int_{-L}^{L} f(x) \cos(\frac{n\pi x}{L}) dx, n&gt;0\]</div>
<div class="arithmatex">\[b_n = \frac{1}{L} \int_{-L}^{L} f(x) \sin(\frac{n\pi x}{L}) dx, n&gt;0\]</div>
<p>&emsp;&emsp;系数<span class="arithmatex">\(a_n\)</span>和<span class="arithmatex">\(b_n\)</span>实际上是<span class="arithmatex">\(f(x)\)</span>与<span class="arithmatex">\(\cos(\frac{n\pi x}{L})\)</span>和<span class="arithmatex">\(\sin(\frac{n\pi x}{L})\)</span>的内积，而<span class="arithmatex">\(a_0\)</span>是<span class="arithmatex">\(f(x)\)</span>平均值的一半。</p>
</blockquote>
<p>&emsp;&emsp;在torch中有相应的函数可以轻松的实现傅里叶级数，如下代码所示：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.fft</span> <span class="k">as</span> <span class="nn">fft</span>

<span class="k">class</span> <span class="nc">FourierLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FourierLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># 对输入的张量 x 进行快速傅里叶变换</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">fft</span><span class="o">.</span><span class="n">fftn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># 取出第三个维度的前半部分，即去掉直流分量和镜像分量</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span>
        <span class="c1"># 返回处理后的张量</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># 创建一个随机数值为 [0, 1) 的形状为 (1, 2, 5) 的张量 X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="c1"># 实例化一个 FourierLayer 的网络对象 net</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">FourierLayer</span><span class="p">()</span>
<span class="c1"># 将 X 输入到网络 net 中进行前向计算，并输出结果</span>
<span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[[ 5.7054+0.0000j,  0.0402+0.0496j],
         [-0.2460+0.0000j,  1.0908-0.0832j]]])
</code></pre></div>
<h2 id="55">5.5 读写文件<a class="headerlink" href="#55" title="Permanent link">⚓︎</a></h2>
<h3 id="551">练习 5.5.1<a class="headerlink" href="#551" title="Permanent link">⚓︎</a></h3>
<p>即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;1. 加速模型训练：存储模型参数可以避免每次重新训练模型时需要重复计算之前已经计算过的权重和偏置。</p>
<p>&emsp;&emsp;2. 节省内存空间：保存模型参数比保存完整的模型文件更加节省内存空间，这在处理大型模型或使用内存受限设备时尤为重要。</p>
<p>&emsp;&emsp;3. 便于共享和复现：存储模型参数可以方便地共享和复现已经训练好的模型，其他人可以直接加载这些参数并使用它们进行预测或微调。</p>
<p>&emsp;&emsp;4. 便于调试和分析：通过检查模型参数，可以更容易地诊断模型中存在的问题，并对其进行调整和优化。</p>
<h3 id="552">练习 5.5.2<a class="headerlink" href="#552" title="Permanent link">⚓︎</a></h3>
<p>假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;使用保存模型某层参数的办法，保存网络的前两层，然后再加载到新的网络中使用。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>             <span class="c1"># 定义 MLP 类</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>   <span class="c1"># 定义隐藏层层，输入尺寸为 20，输出尺寸为 256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># 定义输出层，输入尺寸为 256，输出尺寸为 10</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>          <span class="c1"># 定义前向传播函数</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 使用 ReLU 激活函数，计算隐藏层和输出层的输出</span>

<span class="k">class</span> <span class="nc">MLP_new</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>             <span class="c1"># 定义 MLP 类</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>   <span class="c1"># 定义隐藏层层，输入尺寸为 20，输出尺寸为 256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># 定义输出层，输入尺寸为 256，输出尺寸为 10</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>          <span class="c1"># 定义前向传播函数</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 使用 ReLU 激活函数，计算隐藏层和输出层的输出</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>                       <span class="c1"># 创建 MLP 的实例</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;mlp.hidden.params&#39;</span><span class="p">)</span>  <span class="c1"># 将隐藏层的参数保存到文件中</span>
<span class="n">clone</span> <span class="o">=</span> <span class="n">MLP_new</span><span class="p">()</span>                     <span class="c1"># 创建另一个 MLP 的实例</span>
<span class="n">clone</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;mlp.hidden.params&#39;</span><span class="p">))</span>  <span class="c1"># 加载已保存的参数到克隆实例的隐藏层中</span>
<span class="nb">print</span><span class="p">(</span><span class="n">clone</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">weight</span> <span class="o">==</span> <span class="n">net</span><span class="o">.</span><span class="n">hidden</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>  <span class="c1"># 比较两个 MLP 实例的隐藏层权重是否相等，并输出结果</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([[True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        ...,
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True],
        [True, True, True,  ..., True, True, True]])
</code></pre></div>
<h3 id="553">练习 5.5.3<a class="headerlink" href="#553" title="Permanent link">⚓︎</a></h3>
<p>如何同时保存网络架构和参数？需要对架构加上什么限制？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;在PyTorch中，可以使用<code>torch.save()</code>函数同时保存网络架构和参数。为了保存网络架构，需要将模型的结构定义在一个Python类中，并将该类实例化为模型对象。此外，必须确保该类的构造函数不包含任何随机性质的操作，例如dropout层的随机丢弃率应该是固定的。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>             <span class="c1"># 定义 MLP 类</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>   <span class="c1"># 定义隐藏层层，输入尺寸为 20，输出尺寸为 256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># 定义输出层，输入尺寸为 256，输出尺寸为 10</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>          <span class="c1"># 定义前向传播函数</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 使用 ReLU 激活函数，计算隐藏层和输出层的输出</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>

<span class="c1"># 存储模型</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;model.pt&#39;</span><span class="p">)</span>

<span class="c1"># 导入模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;model.pt&#39;</span><span class="p">)</span>
<span class="n">model</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>OrderedDict([(&#39;hidden.weight&#39;,
              tensor([[-0.1156,  0.1863, -0.0175,  ..., -0.1466, -0.2019,  0.0216],
                      [ 0.0895, -0.1677, -0.0554,  ..., -0.1252, -0.2170,  0.0083],
                      [ 0.0219,  0.1506, -0.0535,  ...,  0.1031, -0.1729,  0.1682],
                      ...,
                      [-0.1097,  0.0599, -0.1763,  ...,  0.1636,  0.1202, -0.0097],
                      [-0.1457,  0.2051,  0.2128,  ...,  0.1272, -0.0476, -0.0765],
                      [-0.1741, -0.1148,  0.1382,  ...,  0.0671,  0.1791, -0.1454]])),
             (&#39;hidden.bias&#39;,
              tensor([ 0.1766, -0.0295, -0.1861, -0.0068,  0.2015, -0.0649, -0.0570, -0.2172,
                       0.0714, -0.1939,  0.2156,  0.0916,  0.1790, -0.1583,  0.0692, -0.1513,
                      -0.1918,  0.1775,  0.2189, -0.0194, -0.1804, -0.1995, -0.0825, -0.0024,
                       0.0511,  0.1024,  0.0159,  0.1635,  0.1716,  0.2139,  0.1466, -0.1488,
                       0.0122, -0.0310,  0.1765, -0.1931,  0.1383,  0.0725,  0.1630,  0.0622,
                      -0.0836,  0.0341, -0.0112,  0.0356,  0.0274, -0.1440,  0.0020, -0.0793,
                      -0.1728,  0.1986, -0.2185,  0.0159, -0.1773, -0.1332,  0.0944, -0.0076,
                       0.1248,  0.0570, -0.1019, -0.1706, -0.1054,  0.1165,  0.1299, -0.0062,
                      -0.1740,  0.1895, -0.1824, -0.1933,  0.1936, -0.1204,  0.2207,  0.1267,
                       0.1236,  0.0671, -0.1981,  0.0835, -0.0292,  0.0989,  0.0729,  0.1339,
                       0.0196, -0.0299, -0.1500,  0.0006,  0.1628, -0.0434,  0.0067, -0.1456,
                       0.1304, -0.1666,  0.1803,  0.2052,  0.1699, -0.1716,  0.1595,  0.1105,
                      -0.1859,  0.0438,  0.0998,  0.0628, -0.1161,  0.0794, -0.1899,  0.1666,
                      -0.1218, -0.1331, -0.0222, -0.1483,  0.2037,  0.0646,  0.0780, -0.1663,
                      -0.0258, -0.0954,  0.0507,  0.1409,  0.0035,  0.0075,  0.0272,  0.1016,
                       0.2113, -0.0838,  0.2073, -0.0815,  0.1675,  0.0785, -0.0213,  0.0250,
                       0.0124, -0.1796,  0.1304,  0.0415,  0.0501, -0.0830, -0.1177, -0.0184,
                       0.1451,  0.2138, -0.0849,  0.1035, -0.1483,  0.1134,  0.0372,  0.0114,
                       0.2180,  0.1472, -0.0085,  0.0218,  0.0432,  0.0168, -0.0995,  0.0535,
                       0.2126,  0.0948,  0.0413, -0.1711, -0.0574,  0.1348, -0.1017,  0.2058,
                       0.0341, -0.0094,  0.0182, -0.1423,  0.0180,  0.0717,  0.0249,  0.1916,
                       0.0109, -0.0301, -0.0721,  0.0041, -0.1025, -0.1381, -0.1428, -0.2062,
                       0.1903,  0.2106,  0.0542, -0.0143, -0.0606, -0.0076,  0.1080,  0.0385,
                      -0.1319, -0.0086,  0.1028, -0.2122, -0.1795, -0.0077, -0.2020, -0.0379,
                       0.1401,  0.0745, -0.2204, -0.2118, -0.2111, -0.1001, -0.1703,  0.0028,
                      -0.1287, -0.1110, -0.1749,  0.0086,  0.1138, -0.0624,  0.0978,  0.1115,
                      -0.0148,  0.0990,  0.1336,  0.0328,  0.0651,  0.1320,  0.1443,  0.0800,
                       0.2155,  0.1570,  0.0192, -0.1268,  0.1085,  0.0400, -0.0108,  0.1133,
                      -0.1684,  0.2001, -0.0513, -0.0052, -0.0617,  0.1917,  0.1170,  0.1218,
                      -0.2125, -0.0716, -0.0619, -0.0967, -0.0929, -0.2126,  0.2150,  0.0424,
                      -0.2172,  0.1137,  0.0601, -0.0266,  0.1998,  0.0429, -0.0619, -0.0983,
                      -0.1875,  0.0654, -0.1324, -0.0647, -0.1327, -0.0441, -0.0721,  0.0988])),
             (&#39;output.weight&#39;,
              tensor([[-0.0009,  0.0294, -0.0051,  ..., -0.0006,  0.0582,  0.0326],
                      [ 0.0174, -0.0336, -0.0176,  ..., -0.0027,  0.0142, -0.0435],
                      [-0.0136,  0.0579, -0.0130,  ..., -0.0463,  0.0178, -0.0148],
                      ...,
                      [ 0.0538,  0.0350, -0.0365,  ..., -0.0312,  0.0151, -0.0308],
                      [ 0.0241, -0.0240, -0.0613,  ...,  0.0461, -0.0597,  0.0160],
                      [ 0.0439,  0.0540,  0.0307,  ..., -0.0360, -0.0272, -0.0426]])),
             (&#39;output.bias&#39;,
              tensor([-0.0548, -0.0609, -0.0241,  0.0394, -0.0228, -0.0331, -0.0540, -0.0416,
                       0.0147,  0.0345]))])
</code></pre></div>
<h2 id="56-gpu">5.6 GPU<a class="headerlink" href="#56-gpu" title="Permanent link">⚓︎</a></h2>
<h3 id="561">练习 5.6.1<a class="headerlink" href="#561" title="Permanent link">⚓︎</a></h3>
<p>尝试一个计算量更大的任务，比如大矩阵的乘法，看看CPU和GPU之间的速度差异。再试一个计算量很小的任务呢？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;计算量很大的任务：使用GPU速度明显更快</p>
<p>&emsp;&emsp;计算量很小的任务：CPU速度可能更快，因为数据传输到GPU需要时间</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># 计算量较大的任务</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">time_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cpu time cost: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">time_end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">ms&#39;</span><span class="p">)</span>
<span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">time_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;gpu time cost: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">time_end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">ms&#39;</span><span class="p">)</span>

<span class="c1"># 计算量很小的任务</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">time_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cpu time cost: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">time_end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">)</span><span class="si">}</span><span class="s1">ms&#39;</span><span class="p">)</span>
<span class="n">time_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">time_end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;gpu time cost: </span><span class="si">{</span><span class="nb">round</span><span class="p">((</span><span class="n">time_end</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">time_start</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">)</span><span class="si">}</span><span class="s1">ms&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>cpu time cost: 10666.56ms
gpu time cost: 1193.48ms
cpu time cost: 0ms
gpu time cost: 0ms
</code></pre></div>
<h3 id="562">练习 5.6.2<a class="headerlink" href="#562" title="Permanent link">⚓︎</a></h3>
<p>我们应该如何在GPU上读写模型参数？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;使用<code>net.to(device)</code>将模型迁移到GPU上，然后再按照之前的方法读写参数。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>             <span class="c1"># 定义 MLP 类</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>   <span class="c1"># 定义隐藏层层，输入尺寸为 20，输出尺寸为 256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>   <span class="c1"># 定义输出层，输入尺寸为 256，输出尺寸为 10</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>          <span class="c1"># 定义前向传播函数</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># 使用 ReLU 激活函数，计算隐藏层和输出层的输出</span>

<span class="c1"># 选择GPU，没有GPU就选CPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="c1"># 创建模型实例对象</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">()</span>
<span class="c1"># 将模型参数传输到GPU上</span>
<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 访问模型参数</span>
<span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>OrderedDict([(&#39;hidden.weight&#39;,
              tensor([[-0.0432, -0.1930,  0.2123,  ...,  0.0261,  0.1068, -0.1317],
                      [ 0.0600, -0.0118,  0.1694,  ...,  0.0250,  0.1431, -0.0099],
                      [-0.0433,  0.0347,  0.0848,  ..., -0.1433, -0.1530,  0.0941],
                      ...,
                      [ 0.0463, -0.0126, -0.1281,  ...,  0.0086,  0.1511, -0.0612],
                      [-0.0961,  0.0380,  0.1699,  ...,  0.0807, -0.1931, -0.1482],
                      [ 0.0692,  0.1754, -0.1558,  ..., -0.0194, -0.0038, -0.1192]],
                     device=&#39;cuda:0&#39;)),
             (&#39;hidden.bias&#39;,
              tensor([-0.0917,  0.1111,  0.0606,  0.1126, -0.0134,  0.1238, -0.1166, -0.1253,
                      -0.2017, -0.0720, -0.1909, -0.1292, -0.2150, -0.0914,  0.0252,  0.1119,
                      -0.1487,  0.1433, -0.0134, -0.0190, -0.0965,  0.0042, -0.0422, -0.1297,
                      -0.1726,  0.1291,  0.0240, -0.0975, -0.0563, -0.0059,  0.0663, -0.1109,
                       0.1318, -0.0842,  0.1192, -0.0094, -0.0738,  0.0525, -0.0794,  0.0294,
                      -0.0594, -0.0539,  0.0464, -0.1584, -0.1031,  0.0378, -0.0634, -0.0937,
                       0.1925,  0.0734, -0.0786,  0.1569,  0.2214,  0.0881, -0.0914, -0.0423,
                      -0.1731,  0.0549,  0.1029, -0.1754,  0.0755,  0.1749,  0.1429, -0.1584,
                       0.0883, -0.0443,  0.2183,  0.0243, -0.1041, -0.1404, -0.2173,  0.0926,
                      -0.0041, -0.1878,  0.0221,  0.0115,  0.0226, -0.2167,  0.2117, -0.0912,
                       0.1352, -0.0309, -0.1846,  0.0896, -0.0330, -0.1251, -0.0828,  0.1357,
                      -0.1486,  0.1482,  0.2110, -0.1634,  0.0424, -0.0310, -0.2083,  0.1316,
                       0.1220,  0.1329, -0.0534,  0.1006, -0.0690, -0.2045,  0.1394, -0.0197,
                      -0.1316,  0.0192, -0.1713, -0.0355,  0.0741, -0.1259, -0.0676,  0.1689,
                       0.0559,  0.0930,  0.1198,  0.1338, -0.0996, -0.1344, -0.1331, -0.1800,
                       0.1331,  0.1098,  0.0771, -0.1508, -0.0768, -0.1873,  0.0574,  0.1658,
                       0.0138,  0.0859,  0.1685,  0.0780, -0.0465, -0.0818,  0.0875,  0.1189,
                      -0.0610, -0.2144,  0.0712, -0.0919, -0.0027, -0.1690, -0.0875, -0.1343,
                       0.1530, -0.0886, -0.0698,  0.1540,  0.1790, -0.0707,  0.1121,  0.1836,
                       0.1868, -0.0792,  0.2077, -0.0793, -0.1420,  0.0465, -0.0088,  0.1172,
                      -0.0367, -0.1313, -0.0480,  0.0676, -0.1355,  0.0982,  0.1367, -0.0494,
                      -0.0798,  0.0952,  0.1556,  0.0431,  0.1364,  0.0783,  0.1828,  0.0923,
                      -0.1137,  0.1838,  0.1636,  0.1233,  0.1776, -0.1573,  0.0854,  0.0007,
                       0.1211,  0.0110, -0.2182, -0.0487, -0.0093,  0.2103, -0.2203, -0.1809,
                       0.0250, -0.1747, -0.0134,  0.1462,  0.0606,  0.0120,  0.1267, -0.1504,
                       0.0651,  0.2034, -0.1150, -0.1709, -0.1697,  0.0113, -0.0758,  0.1178,
                       0.0164, -0.1215, -0.0651,  0.0680, -0.1631,  0.0755, -0.1190,  0.0384,
                      -0.1965,  0.0182, -0.0724, -0.0316,  0.0176, -0.1655,  0.0507, -0.1219,
                       0.1202,  0.0254,  0.1698, -0.0890,  0.1968, -0.1419, -0.1922,  0.0703,
                       0.1278,  0.0852,  0.0899, -0.1138, -0.0535, -0.0802, -0.1164,  0.1638,
                      -0.1939,  0.1950, -0.1853, -0.2065,  0.1341,  0.0865,  0.1317,  0.0514,
                      -0.0098, -0.0319, -0.0282,  0.1304,  0.1279,  0.0616,  0.0902,  0.1834],
                     device=&#39;cuda:0&#39;)),
             (&#39;output.weight&#39;,
              tensor([[ 0.0378,  0.0368, -0.0586,  ...,  0.0592, -0.0195, -0.0052],
                      [-0.0527, -0.0614, -0.0420,  ...,  0.0054, -0.0490,  0.0007],
                      [ 0.0558, -0.0129,  0.0006,  ..., -0.0409,  0.0259,  0.0535],
                      ...,
                      [-0.0624, -0.0108,  0.0038,  ..., -0.0055,  0.0586,  0.0554],
                      [ 0.0592,  0.0014, -0.0083,  ..., -0.0480, -0.0523, -0.0138],
                      [ 0.0562,  0.0339,  0.0364,  ...,  0.0122,  0.0533, -0.0364]],
                     device=&#39;cuda:0&#39;)),
             (&#39;output.bias&#39;,
              tensor([ 0.0610, -0.0384, -0.0256, -0.0007,  0.0381, -0.0479, -0.0177, -0.0192,
                       0.0078, -0.0304], device=&#39;cuda:0&#39;))])
</code></pre></div>
<h3 id="563">练习 5.6.3<a class="headerlink" href="#563" title="Permanent link">⚓︎</a></h3>
<p>测量计算1000个<span class="arithmatex">\(100 \times 100\)</span>矩阵的矩阵乘法所需的时间，并记录输出矩阵的Frobenius范数，一次记录一个结果，而不是在GPU上保存日志并仅传输最终结果。</p>
<p><strong>解答:</strong> </p>
<p>&emsp;&emsp;中文版翻译有点问题，英文原版这句话是：</p>
<blockquote>
<p>&emsp;&emsp;Measure the time it takes to compute 1000 matrix-matrix multiplications of <span class="arithmatex">\(100×100\)</span> matrices and log the Frobenius norm of the output matrix one result at a time vs. keeping a log on the GPU and transferring only the final result.</p>
</blockquote>
<p>&emsp;&emsp;所以这道题的本质还是希望我们做个比较。</p>
<p>&emsp;&emsp;实验一：仅记录1000次<span class="arithmatex">\(100×100\)</span>矩阵相乘所用的时间，不需要打印Frobenius范数。</p>
<p>&emsp;&emsp;实验二：记录1000次<span class="arithmatex">\(100×100\)</span>矩阵相乘所用的时间，并打印Frobenius范数。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="c1"># 生成随机矩阵</span>
<span class="n">matrices</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)]</span>

<span class="c1"># 实验一：计算时间</span>
<span class="n">start_time_1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
    <span class="n">frobenius_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="c1">#     print(frobenius_norm)</span>
<span class="n">end_time_1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time taken:&quot;</span><span class="p">,</span> <span class="n">end_time_1</span> <span class="o">-</span> <span class="n">start_time_1</span><span class="p">)</span>

<span class="c1"># 实验二：计算时间</span>
<span class="n">start_time_2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
    <span class="n">frobenius_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">frobenius_norm</span><span class="p">)</span>
<span class="n">end_time_2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time taken:&quot;</span><span class="p">,</span> <span class="n">end_time_2</span> <span class="o">-</span> <span class="n">start_time_2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;实验一消耗时间：</span><span class="si">{</span><span class="n">end_time_1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time_1</span><span class="si">}</span><span class="s1">，实验二消耗时间：</span><span class="si">{</span><span class="n">end_time_2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_time_2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Time taken: 0.083892822265625
tensor(1414.3264, device=&#39;cuda:0&#39;)
tensor(1420.3613, device=&#39;cuda:0&#39;)
tensor(1426.7102, device=&#39;cuda:0&#39;)
tensor(1404.4108, device=&#39;cuda:0&#39;)
tensor(1399.9667, device=&#39;cuda:0&#39;)
tensor(1423.5759, device=&#39;cuda:0&#39;)
tensor(1404.5486, device=&#39;cuda:0&#39;)
tensor(1386.4878, device=&#39;cuda:0&#39;)
tensor(1453.0780, device=&#39;cuda:0&#39;)
tensor(1399.2872, device=&#39;cuda:0&#39;)
tensor(1401.3347, device=&#39;cuda:0&#39;)
tensor(1442.3737, device=&#39;cuda:0&#39;)
tensor(1409.5651, device=&#39;cuda:0&#39;)
tensor(1412.1494, device=&#39;cuda:0&#39;)
tensor(1399.0287, device=&#39;cuda:0&#39;)
tensor(1377.4283, device=&#39;cuda:0&#39;)
tensor(1409.3846, device=&#39;cuda:0&#39;)
tensor(1440.5291, device=&#39;cuda:0&#39;)
tensor(1383.9038, device=&#39;cuda:0&#39;)
tensor(1401.8132, device=&#39;cuda:0&#39;)
tensor(1444.8940, device=&#39;cuda:0&#39;)
tensor(1407.5876, device=&#39;cuda:0&#39;)
tensor(1392.9998, device=&#39;cuda:0&#39;)
tensor(1447.4484, device=&#39;cuda:0&#39;)
tensor(1441.7650, device=&#39;cuda:0&#39;)
tensor(1424.2852, device=&#39;cuda:0&#39;)
tensor(1412.0476, device=&#39;cuda:0&#39;)
tensor(1446.4708, device=&#39;cuda:0&#39;)
tensor(1439.6016, device=&#39;cuda:0&#39;)
tensor(1400.5818, device=&#39;cuda:0&#39;)
tensor(1442.8463, device=&#39;cuda:0&#39;)
tensor(1401.3495, device=&#39;cuda:0&#39;)
tensor(1416.1384, device=&#39;cuda:0&#39;)
tensor(1407.5288, device=&#39;cuda:0&#39;)
tensor(1400.6179, device=&#39;cuda:0&#39;)
tensor(1439.5996, device=&#39;cuda:0&#39;)
tensor(1390.1395, device=&#39;cuda:0&#39;)
tensor(1424.9067, device=&#39;cuda:0&#39;)
tensor(1419.1511, device=&#39;cuda:0&#39;)
tensor(1397.7457, device=&#39;cuda:0&#39;)
tensor(1424.5667, device=&#39;cuda:0&#39;)
tensor(1431.6057, device=&#39;cuda:0&#39;)
tensor(1414.7839, device=&#39;cuda:0&#39;)
tensor(1404.5869, device=&#39;cuda:0&#39;)
tensor(1410.4812, device=&#39;cuda:0&#39;)
tensor(1426.4489, device=&#39;cuda:0&#39;)
tensor(1395.1388, device=&#39;cuda:0&#39;)
tensor(1432.4199, device=&#39;cuda:0&#39;)
tensor(1388.4635, device=&#39;cuda:0&#39;)
tensor(1412.4142, device=&#39;cuda:0&#39;)
tensor(1409.0317, device=&#39;cuda:0&#39;)
tensor(1444.3677, device=&#39;cuda:0&#39;)
tensor(1425.9957, device=&#39;cuda:0&#39;)
tensor(1399.0273, device=&#39;cuda:0&#39;)
tensor(1391.0610, device=&#39;cuda:0&#39;)
tensor(1422.5696, device=&#39;cuda:0&#39;)
tensor(1385.3455, device=&#39;cuda:0&#39;)
tensor(1405.2266, device=&#39;cuda:0&#39;)
tensor(1414.0631, device=&#39;cuda:0&#39;)
tensor(1441.1052, device=&#39;cuda:0&#39;)
tensor(1404.9672, device=&#39;cuda:0&#39;)
tensor(1434.1139, device=&#39;cuda:0&#39;)
tensor(1382.1471, device=&#39;cuda:0&#39;)
tensor(1431.5863, device=&#39;cuda:0&#39;)
tensor(1393.2568, device=&#39;cuda:0&#39;)
tensor(1398.7456, device=&#39;cuda:0&#39;)
tensor(1452.7546, device=&#39;cuda:0&#39;)
tensor(1422.0884, device=&#39;cuda:0&#39;)
tensor(1426.9169, device=&#39;cuda:0&#39;)
tensor(1406.6737, device=&#39;cuda:0&#39;)
tensor(1415.6372, device=&#39;cuda:0&#39;)
tensor(1425.7087, device=&#39;cuda:0&#39;)
tensor(1436.4384, device=&#39;cuda:0&#39;)
tensor(1408.1709, device=&#39;cuda:0&#39;)
tensor(1397.7487, device=&#39;cuda:0&#39;)
tensor(1432.1602, device=&#39;cuda:0&#39;)
tensor(1401.4945, device=&#39;cuda:0&#39;)
tensor(1364.3336, device=&#39;cuda:0&#39;)
tensor(1432.4294, device=&#39;cuda:0&#39;)
tensor(1420.6379, device=&#39;cuda:0&#39;)
tensor(1402.3220, device=&#39;cuda:0&#39;)
tensor(1415.9830, device=&#39;cuda:0&#39;)
tensor(1427.9037, device=&#39;cuda:0&#39;)
tensor(1426.5095, device=&#39;cuda:0&#39;)
tensor(1404.6687, device=&#39;cuda:0&#39;)
tensor(1412.2659, device=&#39;cuda:0&#39;)
tensor(1425.6060, device=&#39;cuda:0&#39;)
tensor(1455.0330, device=&#39;cuda:0&#39;)
tensor(1425.2367, device=&#39;cuda:0&#39;)
tensor(1412.7449, device=&#39;cuda:0&#39;)
tensor(1383.8060, device=&#39;cuda:0&#39;)
tensor(1462.7919, device=&#39;cuda:0&#39;)
tensor(1441.7439, device=&#39;cuda:0&#39;)
tensor(1428.8705, device=&#39;cuda:0&#39;)
tensor(1388.8622, device=&#39;cuda:0&#39;)
tensor(1409.4866, device=&#39;cuda:0&#39;)
tensor(1408.3340, device=&#39;cuda:0&#39;)
tensor(1409.9652, device=&#39;cuda:0&#39;)
tensor(1428.4456, device=&#39;cuda:0&#39;)
tensor(1458.7307, device=&#39;cuda:0&#39;)
tensor(1412.8656, device=&#39;cuda:0&#39;)
tensor(1398.3041, device=&#39;cuda:0&#39;)
tensor(1454.4297, device=&#39;cuda:0&#39;)
tensor(1420.5155, device=&#39;cuda:0&#39;)
tensor(1409.4517, device=&#39;cuda:0&#39;)
tensor(1437.3512, device=&#39;cuda:0&#39;)
tensor(1439.3440, device=&#39;cuda:0&#39;)
tensor(1420.8407, device=&#39;cuda:0&#39;)
tensor(1385.2998, device=&#39;cuda:0&#39;)
tensor(1403.2085, device=&#39;cuda:0&#39;)
tensor(1443.1156, device=&#39;cuda:0&#39;)
tensor(1436.5155, device=&#39;cuda:0&#39;)
tensor(1412.8850, device=&#39;cuda:0&#39;)
tensor(1430.8556, device=&#39;cuda:0&#39;)
tensor(1426.4655, device=&#39;cuda:0&#39;)
tensor(1437.0756, device=&#39;cuda:0&#39;)
tensor(1448.4524, device=&#39;cuda:0&#39;)
tensor(1406.4270, device=&#39;cuda:0&#39;)
tensor(1416.3265, device=&#39;cuda:0&#39;)
tensor(1385.5703, device=&#39;cuda:0&#39;)
tensor(1409.6227, device=&#39;cuda:0&#39;)
tensor(1387.6338, device=&#39;cuda:0&#39;)
tensor(1387.0051, device=&#39;cuda:0&#39;)
tensor(1401.6917, device=&#39;cuda:0&#39;)
tensor(1459.0684, device=&#39;cuda:0&#39;)
tensor(1415.2648, device=&#39;cuda:0&#39;)
tensor(1400.3497, device=&#39;cuda:0&#39;)
tensor(1427.4443, device=&#39;cuda:0&#39;)
tensor(1427.0580, device=&#39;cuda:0&#39;)
tensor(1434.4236, device=&#39;cuda:0&#39;)
tensor(1428.7977, device=&#39;cuda:0&#39;)
tensor(1415.7834, device=&#39;cuda:0&#39;)
tensor(1419.2070, device=&#39;cuda:0&#39;)
tensor(1450.7157, device=&#39;cuda:0&#39;)
tensor(1426.0618, device=&#39;cuda:0&#39;)
tensor(1411.4818, device=&#39;cuda:0&#39;)
tensor(1393.3303, device=&#39;cuda:0&#39;)
tensor(1429.1759, device=&#39;cuda:0&#39;)
tensor(1438.4055, device=&#39;cuda:0&#39;)
tensor(1382.0458, device=&#39;cuda:0&#39;)
tensor(1414.6213, device=&#39;cuda:0&#39;)
tensor(1416.8164, device=&#39;cuda:0&#39;)
tensor(1402.7170, device=&#39;cuda:0&#39;)
tensor(1424.0973, device=&#39;cuda:0&#39;)
tensor(1396.5586, device=&#39;cuda:0&#39;)
tensor(1397.8713, device=&#39;cuda:0&#39;)
tensor(1413.1685, device=&#39;cuda:0&#39;)
tensor(1420.2782, device=&#39;cuda:0&#39;)
tensor(1451.3582, device=&#39;cuda:0&#39;)
tensor(1389.3899, device=&#39;cuda:0&#39;)
tensor(1417.5210, device=&#39;cuda:0&#39;)
tensor(1405.4589, device=&#39;cuda:0&#39;)
tensor(1418.8301, device=&#39;cuda:0&#39;)
tensor(1441.7411, device=&#39;cuda:0&#39;)
tensor(1393.5591, device=&#39;cuda:0&#39;)
tensor(1459.0192, device=&#39;cuda:0&#39;)
tensor(1384.6997, device=&#39;cuda:0&#39;)
tensor(1367.1498, device=&#39;cuda:0&#39;)
tensor(1411.3000, device=&#39;cuda:0&#39;)
tensor(1449.4939, device=&#39;cuda:0&#39;)
tensor(1432.4763, device=&#39;cuda:0&#39;)
tensor(1407.5201, device=&#39;cuda:0&#39;)
tensor(1423.5007, device=&#39;cuda:0&#39;)
tensor(1421.6755, device=&#39;cuda:0&#39;)
tensor(1407.4553, device=&#39;cuda:0&#39;)
tensor(1396.2762, device=&#39;cuda:0&#39;)
tensor(1438.9589, device=&#39;cuda:0&#39;)
tensor(1426.8402, device=&#39;cuda:0&#39;)
tensor(1426.7487, device=&#39;cuda:0&#39;)
tensor(1408.7693, device=&#39;cuda:0&#39;)
tensor(1412.2242, device=&#39;cuda:0&#39;)
tensor(1390.1692, device=&#39;cuda:0&#39;)
tensor(1397.5320, device=&#39;cuda:0&#39;)
tensor(1418.8942, device=&#39;cuda:0&#39;)
tensor(1409.5818, device=&#39;cuda:0&#39;)
tensor(1450.8793, device=&#39;cuda:0&#39;)
tensor(1445.1687, device=&#39;cuda:0&#39;)
tensor(1436.6711, device=&#39;cuda:0&#39;)
tensor(1380.7662, device=&#39;cuda:0&#39;)
tensor(1420.0610, device=&#39;cuda:0&#39;)
tensor(1449.6732, device=&#39;cuda:0&#39;)
tensor(1410.6570, device=&#39;cuda:0&#39;)
tensor(1399.0934, device=&#39;cuda:0&#39;)
tensor(1402.6781, device=&#39;cuda:0&#39;)
tensor(1419.4244, device=&#39;cuda:0&#39;)
tensor(1431.7424, device=&#39;cuda:0&#39;)
tensor(1425.0427, device=&#39;cuda:0&#39;)
tensor(1422.3596, device=&#39;cuda:0&#39;)
tensor(1446.0736, device=&#39;cuda:0&#39;)
tensor(1393.0781, device=&#39;cuda:0&#39;)
tensor(1403.0770, device=&#39;cuda:0&#39;)
tensor(1420.0957, device=&#39;cuda:0&#39;)
tensor(1443.6151, device=&#39;cuda:0&#39;)
tensor(1412.4930, device=&#39;cuda:0&#39;)
tensor(1459.8573, device=&#39;cuda:0&#39;)
tensor(1405.6935, device=&#39;cuda:0&#39;)
tensor(1372.5243, device=&#39;cuda:0&#39;)
tensor(1411.5518, device=&#39;cuda:0&#39;)
tensor(1391.6947, device=&#39;cuda:0&#39;)
tensor(1415.2728, device=&#39;cuda:0&#39;)
tensor(1444.5618, device=&#39;cuda:0&#39;)
tensor(1408.9080, device=&#39;cuda:0&#39;)
tensor(1392.5614, device=&#39;cuda:0&#39;)
tensor(1427.8918, device=&#39;cuda:0&#39;)
tensor(1419.5483, device=&#39;cuda:0&#39;)
tensor(1415.6810, device=&#39;cuda:0&#39;)
tensor(1397.2209, device=&#39;cuda:0&#39;)
tensor(1396.9866, device=&#39;cuda:0&#39;)
tensor(1426.4923, device=&#39;cuda:0&#39;)
tensor(1456.2041, device=&#39;cuda:0&#39;)
tensor(1369.0884, device=&#39;cuda:0&#39;)
tensor(1405.4847, device=&#39;cuda:0&#39;)
tensor(1434.1417, device=&#39;cuda:0&#39;)
tensor(1429.5665, device=&#39;cuda:0&#39;)
tensor(1471.4082, device=&#39;cuda:0&#39;)
tensor(1424.3124, device=&#39;cuda:0&#39;)
tensor(1403.1338, device=&#39;cuda:0&#39;)
tensor(1405.5498, device=&#39;cuda:0&#39;)
tensor(1450.0192, device=&#39;cuda:0&#39;)
tensor(1415.6967, device=&#39;cuda:0&#39;)
tensor(1396.4835, device=&#39;cuda:0&#39;)
tensor(1420.1073, device=&#39;cuda:0&#39;)
tensor(1467.6332, device=&#39;cuda:0&#39;)
tensor(1442.1469, device=&#39;cuda:0&#39;)
tensor(1435.9219, device=&#39;cuda:0&#39;)
tensor(1429.7675, device=&#39;cuda:0&#39;)
tensor(1382.4639, device=&#39;cuda:0&#39;)
tensor(1421.8973, device=&#39;cuda:0&#39;)
tensor(1385.1857, device=&#39;cuda:0&#39;)
tensor(1421.3765, device=&#39;cuda:0&#39;)
tensor(1399.2683, device=&#39;cuda:0&#39;)
tensor(1415.0687, device=&#39;cuda:0&#39;)
tensor(1429.7700, device=&#39;cuda:0&#39;)
tensor(1387.0018, device=&#39;cuda:0&#39;)
tensor(1431.9097, device=&#39;cuda:0&#39;)
tensor(1417.7034, device=&#39;cuda:0&#39;)
tensor(1443.3807, device=&#39;cuda:0&#39;)
tensor(1383.3411, device=&#39;cuda:0&#39;)
tensor(1453.2593, device=&#39;cuda:0&#39;)
tensor(1443.6071, device=&#39;cuda:0&#39;)
tensor(1407.7806, device=&#39;cuda:0&#39;)
tensor(1460.8347, device=&#39;cuda:0&#39;)
tensor(1385.2125, device=&#39;cuda:0&#39;)
tensor(1442.6860, device=&#39;cuda:0&#39;)
tensor(1435.8127, device=&#39;cuda:0&#39;)
tensor(1385.6194, device=&#39;cuda:0&#39;)
tensor(1423.0961, device=&#39;cuda:0&#39;)
tensor(1397.1876, device=&#39;cuda:0&#39;)
tensor(1429.1403, device=&#39;cuda:0&#39;)
tensor(1383.8939, device=&#39;cuda:0&#39;)
tensor(1420.3212, device=&#39;cuda:0&#39;)
tensor(1428.1782, device=&#39;cuda:0&#39;)
tensor(1405.0005, device=&#39;cuda:0&#39;)
tensor(1403.5986, device=&#39;cuda:0&#39;)
tensor(1366.1530, device=&#39;cuda:0&#39;)
tensor(1409.2677, device=&#39;cuda:0&#39;)
tensor(1393.9169, device=&#39;cuda:0&#39;)
tensor(1411.2216, device=&#39;cuda:0&#39;)
tensor(1401.5234, device=&#39;cuda:0&#39;)
tensor(1419.8258, device=&#39;cuda:0&#39;)
tensor(1402.1510, device=&#39;cuda:0&#39;)
tensor(1382.2053, device=&#39;cuda:0&#39;)
tensor(1428.4900, device=&#39;cuda:0&#39;)
tensor(1432.6130, device=&#39;cuda:0&#39;)
tensor(1432.9546, device=&#39;cuda:0&#39;)
tensor(1402.5962, device=&#39;cuda:0&#39;)
tensor(1414.0640, device=&#39;cuda:0&#39;)
tensor(1390.7435, device=&#39;cuda:0&#39;)
tensor(1421.4161, device=&#39;cuda:0&#39;)
tensor(1396.6892, device=&#39;cuda:0&#39;)
tensor(1438.0793, device=&#39;cuda:0&#39;)
tensor(1434.9421, device=&#39;cuda:0&#39;)
tensor(1422.1665, device=&#39;cuda:0&#39;)
tensor(1381.1476, device=&#39;cuda:0&#39;)
tensor(1420.3358, device=&#39;cuda:0&#39;)
tensor(1404.7455, device=&#39;cuda:0&#39;)
tensor(1395.9352, device=&#39;cuda:0&#39;)
tensor(1432.2086, device=&#39;cuda:0&#39;)
tensor(1462.7440, device=&#39;cuda:0&#39;)
tensor(1455.9264, device=&#39;cuda:0&#39;)
tensor(1434.2323, device=&#39;cuda:0&#39;)
tensor(1412.7642, device=&#39;cuda:0&#39;)
tensor(1416.1359, device=&#39;cuda:0&#39;)
tensor(1436.3552, device=&#39;cuda:0&#39;)
tensor(1424.6135, device=&#39;cuda:0&#39;)
tensor(1405.4802, device=&#39;cuda:0&#39;)
tensor(1382.1775, device=&#39;cuda:0&#39;)
tensor(1444.7761, device=&#39;cuda:0&#39;)
tensor(1391.2672, device=&#39;cuda:0&#39;)
tensor(1407.9937, device=&#39;cuda:0&#39;)
tensor(1444.0236, device=&#39;cuda:0&#39;)
tensor(1425.7430, device=&#39;cuda:0&#39;)
tensor(1434.1818, device=&#39;cuda:0&#39;)
tensor(1388.1573, device=&#39;cuda:0&#39;)
tensor(1378.3517, device=&#39;cuda:0&#39;)
tensor(1433.2560, device=&#39;cuda:0&#39;)
tensor(1413.1733, device=&#39;cuda:0&#39;)
tensor(1425.3997, device=&#39;cuda:0&#39;)
tensor(1415.9795, device=&#39;cuda:0&#39;)
tensor(1426.1742, device=&#39;cuda:0&#39;)
tensor(1401.4117, device=&#39;cuda:0&#39;)
tensor(1400.5546, device=&#39;cuda:0&#39;)
tensor(1409.5291, device=&#39;cuda:0&#39;)
tensor(1424.6991, device=&#39;cuda:0&#39;)
tensor(1404.9939, device=&#39;cuda:0&#39;)
tensor(1416.3623, device=&#39;cuda:0&#39;)
tensor(1413.5933, device=&#39;cuda:0&#39;)
tensor(1414.0509, device=&#39;cuda:0&#39;)
tensor(1419.7173, device=&#39;cuda:0&#39;)
tensor(1429.9849, device=&#39;cuda:0&#39;)
tensor(1408.4830, device=&#39;cuda:0&#39;)
tensor(1403.2603, device=&#39;cuda:0&#39;)
tensor(1394.5729, device=&#39;cuda:0&#39;)
tensor(1414.0874, device=&#39;cuda:0&#39;)
tensor(1465.8975, device=&#39;cuda:0&#39;)
tensor(1451.1857, device=&#39;cuda:0&#39;)
tensor(1470.9673, device=&#39;cuda:0&#39;)
tensor(1380.7628, device=&#39;cuda:0&#39;)
tensor(1412.7468, device=&#39;cuda:0&#39;)
tensor(1426.3804, device=&#39;cuda:0&#39;)
tensor(1405.4205, device=&#39;cuda:0&#39;)
tensor(1428.5094, device=&#39;cuda:0&#39;)
tensor(1412.5598, device=&#39;cuda:0&#39;)
tensor(1417.3813, device=&#39;cuda:0&#39;)
tensor(1426.7632, device=&#39;cuda:0&#39;)
tensor(1396.8458, device=&#39;cuda:0&#39;)
tensor(1390.5662, device=&#39;cuda:0&#39;)
tensor(1465.5986, device=&#39;cuda:0&#39;)
tensor(1368.3411, device=&#39;cuda:0&#39;)
tensor(1451.1282, device=&#39;cuda:0&#39;)
tensor(1451.7244, device=&#39;cuda:0&#39;)
tensor(1389.8445, device=&#39;cuda:0&#39;)
tensor(1444.2655, device=&#39;cuda:0&#39;)
tensor(1416.1716, device=&#39;cuda:0&#39;)
tensor(1429.8531, device=&#39;cuda:0&#39;)
tensor(1467.9452, device=&#39;cuda:0&#39;)
tensor(1447.1864, device=&#39;cuda:0&#39;)
tensor(1409.8638, device=&#39;cuda:0&#39;)
tensor(1420.3434, device=&#39;cuda:0&#39;)
tensor(1423.9861, device=&#39;cuda:0&#39;)
tensor(1429.1010, device=&#39;cuda:0&#39;)
tensor(1439.2847, device=&#39;cuda:0&#39;)
tensor(1466.9221, device=&#39;cuda:0&#39;)
tensor(1438.8833, device=&#39;cuda:0&#39;)
tensor(1433.8713, device=&#39;cuda:0&#39;)
tensor(1416.6282, device=&#39;cuda:0&#39;)
tensor(1400.9237, device=&#39;cuda:0&#39;)
tensor(1418.0923, device=&#39;cuda:0&#39;)
tensor(1433.3290, device=&#39;cuda:0&#39;)
tensor(1429.4817, device=&#39;cuda:0&#39;)
tensor(1418.6892, device=&#39;cuda:0&#39;)
tensor(1412.2926, device=&#39;cuda:0&#39;)
tensor(1415.1140, device=&#39;cuda:0&#39;)
tensor(1427.6580, device=&#39;cuda:0&#39;)
tensor(1470.7190, device=&#39;cuda:0&#39;)
tensor(1428.6884, device=&#39;cuda:0&#39;)
tensor(1449.6207, device=&#39;cuda:0&#39;)
tensor(1404.9960, device=&#39;cuda:0&#39;)
tensor(1410.9005, device=&#39;cuda:0&#39;)
tensor(1405.3414, device=&#39;cuda:0&#39;)
tensor(1374.9852, device=&#39;cuda:0&#39;)
tensor(1398.2344, device=&#39;cuda:0&#39;)
tensor(1365.1029, device=&#39;cuda:0&#39;)
tensor(1384.9991, device=&#39;cuda:0&#39;)
tensor(1418.4922, device=&#39;cuda:0&#39;)
tensor(1397.8925, device=&#39;cuda:0&#39;)
tensor(1421.8087, device=&#39;cuda:0&#39;)
tensor(1409.1899, device=&#39;cuda:0&#39;)
tensor(1409.6622, device=&#39;cuda:0&#39;)
tensor(1437.6113, device=&#39;cuda:0&#39;)
tensor(1435.6271, device=&#39;cuda:0&#39;)
tensor(1424.1324, device=&#39;cuda:0&#39;)
tensor(1407.0251, device=&#39;cuda:0&#39;)
tensor(1398.9154, device=&#39;cuda:0&#39;)
tensor(1402.5077, device=&#39;cuda:0&#39;)
tensor(1401.2939, device=&#39;cuda:0&#39;)
tensor(1360.6781, device=&#39;cuda:0&#39;)
tensor(1454.7137, device=&#39;cuda:0&#39;)
tensor(1454.7367, device=&#39;cuda:0&#39;)
tensor(1388.7833, device=&#39;cuda:0&#39;)
tensor(1408.0422, device=&#39;cuda:0&#39;)
tensor(1432.1945, device=&#39;cuda:0&#39;)
tensor(1404.3351, device=&#39;cuda:0&#39;)
tensor(1418.7017, device=&#39;cuda:0&#39;)
tensor(1432.2267, device=&#39;cuda:0&#39;)
tensor(1421.2924, device=&#39;cuda:0&#39;)
tensor(1384.1738, device=&#39;cuda:0&#39;)
tensor(1437.2968, device=&#39;cuda:0&#39;)
tensor(1423.3580, device=&#39;cuda:0&#39;)
tensor(1404.5396, device=&#39;cuda:0&#39;)
tensor(1444.3097, device=&#39;cuda:0&#39;)
tensor(1401.6013, device=&#39;cuda:0&#39;)
tensor(1412.9150, device=&#39;cuda:0&#39;)
tensor(1422.6688, device=&#39;cuda:0&#39;)
tensor(1422.4749, device=&#39;cuda:0&#39;)
tensor(1428.0391, device=&#39;cuda:0&#39;)
tensor(1402.7891, device=&#39;cuda:0&#39;)
tensor(1403.7410, device=&#39;cuda:0&#39;)
tensor(1403.7869, device=&#39;cuda:0&#39;)
tensor(1420.3461, device=&#39;cuda:0&#39;)
tensor(1423.8771, device=&#39;cuda:0&#39;)
tensor(1430.0901, device=&#39;cuda:0&#39;)
tensor(1432.7458, device=&#39;cuda:0&#39;)
tensor(1375.4868, device=&#39;cuda:0&#39;)
tensor(1413.0044, device=&#39;cuda:0&#39;)
tensor(1418.3054, device=&#39;cuda:0&#39;)
tensor(1426.6083, device=&#39;cuda:0&#39;)
tensor(1380.1199, device=&#39;cuda:0&#39;)
tensor(1392.9200, device=&#39;cuda:0&#39;)
tensor(1439.8191, device=&#39;cuda:0&#39;)
tensor(1391.5569, device=&#39;cuda:0&#39;)
tensor(1415.3403, device=&#39;cuda:0&#39;)
tensor(1394.4769, device=&#39;cuda:0&#39;)
tensor(1411.8767, device=&#39;cuda:0&#39;)
tensor(1387.7863, device=&#39;cuda:0&#39;)
tensor(1417.2864, device=&#39;cuda:0&#39;)
tensor(1408.4110, device=&#39;cuda:0&#39;)
tensor(1413.7633, device=&#39;cuda:0&#39;)
tensor(1418.6460, device=&#39;cuda:0&#39;)
tensor(1426.2806, device=&#39;cuda:0&#39;)
tensor(1411.6372, device=&#39;cuda:0&#39;)
tensor(1402.4010, device=&#39;cuda:0&#39;)
tensor(1397.1362, device=&#39;cuda:0&#39;)
tensor(1439.5264, device=&#39;cuda:0&#39;)
tensor(1437.9934, device=&#39;cuda:0&#39;)
tensor(1414.0233, device=&#39;cuda:0&#39;)
tensor(1407.7537, device=&#39;cuda:0&#39;)
tensor(1402.5347, device=&#39;cuda:0&#39;)
tensor(1408.2753, device=&#39;cuda:0&#39;)
tensor(1438.6881, device=&#39;cuda:0&#39;)
tensor(1408.5067, device=&#39;cuda:0&#39;)
tensor(1439.3190, device=&#39;cuda:0&#39;)
tensor(1435.7350, device=&#39;cuda:0&#39;)
tensor(1407.3895, device=&#39;cuda:0&#39;)
tensor(1399.8881, device=&#39;cuda:0&#39;)
tensor(1422.3414, device=&#39;cuda:0&#39;)
tensor(1408.3064, device=&#39;cuda:0&#39;)
tensor(1365.7664, device=&#39;cuda:0&#39;)
tensor(1433.2239, device=&#39;cuda:0&#39;)
tensor(1424.7485, device=&#39;cuda:0&#39;)
tensor(1420.8862, device=&#39;cuda:0&#39;)
tensor(1426.5361, device=&#39;cuda:0&#39;)
tensor(1386.8502, device=&#39;cuda:0&#39;)
tensor(1430.3644, device=&#39;cuda:0&#39;)
tensor(1409.7175, device=&#39;cuda:0&#39;)
tensor(1455.3163, device=&#39;cuda:0&#39;)
tensor(1439.4346, device=&#39;cuda:0&#39;)
tensor(1400.4198, device=&#39;cuda:0&#39;)
tensor(1374.9525, device=&#39;cuda:0&#39;)
tensor(1437.6892, device=&#39;cuda:0&#39;)
tensor(1425.2881, device=&#39;cuda:0&#39;)
tensor(1395.4740, device=&#39;cuda:0&#39;)
tensor(1436.3489, device=&#39;cuda:0&#39;)
tensor(1402.9910, device=&#39;cuda:0&#39;)
tensor(1407.4963, device=&#39;cuda:0&#39;)
tensor(1405.6246, device=&#39;cuda:0&#39;)
tensor(1435.1608, device=&#39;cuda:0&#39;)
tensor(1390.6985, device=&#39;cuda:0&#39;)
tensor(1442.0021, device=&#39;cuda:0&#39;)
tensor(1441.5020, device=&#39;cuda:0&#39;)
tensor(1426.5122, device=&#39;cuda:0&#39;)
tensor(1473.3478, device=&#39;cuda:0&#39;)
tensor(1416.2357, device=&#39;cuda:0&#39;)
tensor(1421.5352, device=&#39;cuda:0&#39;)
tensor(1431.3108, device=&#39;cuda:0&#39;)
tensor(1415.8021, device=&#39;cuda:0&#39;)
tensor(1395.7290, device=&#39;cuda:0&#39;)
tensor(1422.5176, device=&#39;cuda:0&#39;)
tensor(1430.6995, device=&#39;cuda:0&#39;)
tensor(1417.5221, device=&#39;cuda:0&#39;)
tensor(1413.3586, device=&#39;cuda:0&#39;)
tensor(1408.5188, device=&#39;cuda:0&#39;)
tensor(1414.3170, device=&#39;cuda:0&#39;)
tensor(1447.1042, device=&#39;cuda:0&#39;)
tensor(1385.1370, device=&#39;cuda:0&#39;)
tensor(1418.7260, device=&#39;cuda:0&#39;)
tensor(1380.2251, device=&#39;cuda:0&#39;)
tensor(1404.6027, device=&#39;cuda:0&#39;)
tensor(1417.0959, device=&#39;cuda:0&#39;)
tensor(1439.8796, device=&#39;cuda:0&#39;)
tensor(1417.5627, device=&#39;cuda:0&#39;)
tensor(1433.6448, device=&#39;cuda:0&#39;)
tensor(1413.6857, device=&#39;cuda:0&#39;)
tensor(1436.9205, device=&#39;cuda:0&#39;)
tensor(1425.8083, device=&#39;cuda:0&#39;)
tensor(1433.5669, device=&#39;cuda:0&#39;)
tensor(1395.6774, device=&#39;cuda:0&#39;)
tensor(1384.6754, device=&#39;cuda:0&#39;)
tensor(1405.2471, device=&#39;cuda:0&#39;)
tensor(1401.4568, device=&#39;cuda:0&#39;)
tensor(1426.3107, device=&#39;cuda:0&#39;)
tensor(1439.5176, device=&#39;cuda:0&#39;)
tensor(1419.9882, device=&#39;cuda:0&#39;)
tensor(1380.9194, device=&#39;cuda:0&#39;)
tensor(1413.2659, device=&#39;cuda:0&#39;)
tensor(1411.4631, device=&#39;cuda:0&#39;)
tensor(1439.6840, device=&#39;cuda:0&#39;)
tensor(1385.5994, device=&#39;cuda:0&#39;)
tensor(1429.2371, device=&#39;cuda:0&#39;)
tensor(1394.6469, device=&#39;cuda:0&#39;)
tensor(1439.3892, device=&#39;cuda:0&#39;)
tensor(1415.7286, device=&#39;cuda:0&#39;)
tensor(1391.0919, device=&#39;cuda:0&#39;)
tensor(1382.4852, device=&#39;cuda:0&#39;)
tensor(1386.4874, device=&#39;cuda:0&#39;)
tensor(1422.5387, device=&#39;cuda:0&#39;)
tensor(1447.5110, device=&#39;cuda:0&#39;)
tensor(1416.0176, device=&#39;cuda:0&#39;)
tensor(1400.7793, device=&#39;cuda:0&#39;)
tensor(1398.1163, device=&#39;cuda:0&#39;)
tensor(1427.2731, device=&#39;cuda:0&#39;)
tensor(1425.4888, device=&#39;cuda:0&#39;)
tensor(1439.1068, device=&#39;cuda:0&#39;)
tensor(1433.0099, device=&#39;cuda:0&#39;)
tensor(1408.9768, device=&#39;cuda:0&#39;)
tensor(1389.0740, device=&#39;cuda:0&#39;)
tensor(1405.4551, device=&#39;cuda:0&#39;)
tensor(1417.8910, device=&#39;cuda:0&#39;)
tensor(1392.1174, device=&#39;cuda:0&#39;)
tensor(1416.3024, device=&#39;cuda:0&#39;)
tensor(1441.5596, device=&#39;cuda:0&#39;)
tensor(1418.6179, device=&#39;cuda:0&#39;)
tensor(1421.4349, device=&#39;cuda:0&#39;)
tensor(1468.2260, device=&#39;cuda:0&#39;)
tensor(1448.2383, device=&#39;cuda:0&#39;)
tensor(1412.8549, device=&#39;cuda:0&#39;)
tensor(1443.3477, device=&#39;cuda:0&#39;)
tensor(1416.3853, device=&#39;cuda:0&#39;)
tensor(1406.0111, device=&#39;cuda:0&#39;)
tensor(1443.9180, device=&#39;cuda:0&#39;)
tensor(1425.6541, device=&#39;cuda:0&#39;)
tensor(1413.3318, device=&#39;cuda:0&#39;)
tensor(1421.2944, device=&#39;cuda:0&#39;)
tensor(1419.3005, device=&#39;cuda:0&#39;)
tensor(1430.3191, device=&#39;cuda:0&#39;)
tensor(1412.7074, device=&#39;cuda:0&#39;)
tensor(1421.5516, device=&#39;cuda:0&#39;)
tensor(1413.7882, device=&#39;cuda:0&#39;)
tensor(1436.7692, device=&#39;cuda:0&#39;)
tensor(1425.3563, device=&#39;cuda:0&#39;)
tensor(1417.0079, device=&#39;cuda:0&#39;)
tensor(1403.8787, device=&#39;cuda:0&#39;)
tensor(1441.4609, device=&#39;cuda:0&#39;)
tensor(1414.7581, device=&#39;cuda:0&#39;)
tensor(1414.9227, device=&#39;cuda:0&#39;)
tensor(1417.8657, device=&#39;cuda:0&#39;)
tensor(1446.0958, device=&#39;cuda:0&#39;)
tensor(1402.4999, device=&#39;cuda:0&#39;)
tensor(1414.6422, device=&#39;cuda:0&#39;)
tensor(1410.7300, device=&#39;cuda:0&#39;)
tensor(1400.5583, device=&#39;cuda:0&#39;)
tensor(1426.6515, device=&#39;cuda:0&#39;)
tensor(1443.7634, device=&#39;cuda:0&#39;)
tensor(1426.3607, device=&#39;cuda:0&#39;)
tensor(1402.7223, device=&#39;cuda:0&#39;)
tensor(1415.4741, device=&#39;cuda:0&#39;)
tensor(1404.5396, device=&#39;cuda:0&#39;)
tensor(1414.0891, device=&#39;cuda:0&#39;)
tensor(1420.7969, device=&#39;cuda:0&#39;)
tensor(1396.9275, device=&#39;cuda:0&#39;)
tensor(1458.3097, device=&#39;cuda:0&#39;)
tensor(1434.4164, device=&#39;cuda:0&#39;)
tensor(1393.2557, device=&#39;cuda:0&#39;)
tensor(1441.0255, device=&#39;cuda:0&#39;)
tensor(1380.6505, device=&#39;cuda:0&#39;)
tensor(1409.9803, device=&#39;cuda:0&#39;)
tensor(1368.8228, device=&#39;cuda:0&#39;)
tensor(1400.6229, device=&#39;cuda:0&#39;)
tensor(1415.9321, device=&#39;cuda:0&#39;)
tensor(1424.6715, device=&#39;cuda:0&#39;)
tensor(1385.3785, device=&#39;cuda:0&#39;)
tensor(1417.8522, device=&#39;cuda:0&#39;)
tensor(1421.3883, device=&#39;cuda:0&#39;)
tensor(1449.0311, device=&#39;cuda:0&#39;)
tensor(1426.6940, device=&#39;cuda:0&#39;)
tensor(1438.8097, device=&#39;cuda:0&#39;)
tensor(1407.8922, device=&#39;cuda:0&#39;)
tensor(1435.3757, device=&#39;cuda:0&#39;)
tensor(1455.0043, device=&#39;cuda:0&#39;)
tensor(1391.4935, device=&#39;cuda:0&#39;)
tensor(1417.1824, device=&#39;cuda:0&#39;)
tensor(1428.1558, device=&#39;cuda:0&#39;)
tensor(1431.2241, device=&#39;cuda:0&#39;)
tensor(1420.5492, device=&#39;cuda:0&#39;)
tensor(1425.2817, device=&#39;cuda:0&#39;)
tensor(1389.0997, device=&#39;cuda:0&#39;)
tensor(1409.1003, device=&#39;cuda:0&#39;)
tensor(1409.8082, device=&#39;cuda:0&#39;)
tensor(1379.0896, device=&#39;cuda:0&#39;)
tensor(1408.6285, device=&#39;cuda:0&#39;)
tensor(1383.6857, device=&#39;cuda:0&#39;)
tensor(1410.5594, device=&#39;cuda:0&#39;)
tensor(1400.9836, device=&#39;cuda:0&#39;)
tensor(1405.1199, device=&#39;cuda:0&#39;)
tensor(1449.0201, device=&#39;cuda:0&#39;)
tensor(1381.7177, device=&#39;cuda:0&#39;)
tensor(1435.9558, device=&#39;cuda:0&#39;)
tensor(1395.7903, device=&#39;cuda:0&#39;)
tensor(1414.4789, device=&#39;cuda:0&#39;)
tensor(1418.1703, device=&#39;cuda:0&#39;)
tensor(1439.0444, device=&#39;cuda:0&#39;)
tensor(1433.3157, device=&#39;cuda:0&#39;)
tensor(1450.6144, device=&#39;cuda:0&#39;)
tensor(1382.4734, device=&#39;cuda:0&#39;)
tensor(1421.0452, device=&#39;cuda:0&#39;)
tensor(1432.8387, device=&#39;cuda:0&#39;)
tensor(1416.5317, device=&#39;cuda:0&#39;)
tensor(1449.9954, device=&#39;cuda:0&#39;)
tensor(1382.6801, device=&#39;cuda:0&#39;)
tensor(1448.8501, device=&#39;cuda:0&#39;)
tensor(1417.5383, device=&#39;cuda:0&#39;)
tensor(1430.1782, device=&#39;cuda:0&#39;)
tensor(1435.8892, device=&#39;cuda:0&#39;)
tensor(1367.6129, device=&#39;cuda:0&#39;)
tensor(1384.8370, device=&#39;cuda:0&#39;)
tensor(1377.2517, device=&#39;cuda:0&#39;)
tensor(1392.1387, device=&#39;cuda:0&#39;)
tensor(1412.3425, device=&#39;cuda:0&#39;)
tensor(1441.9358, device=&#39;cuda:0&#39;)
tensor(1447.9532, device=&#39;cuda:0&#39;)
tensor(1404.0717, device=&#39;cuda:0&#39;)
tensor(1424.9260, device=&#39;cuda:0&#39;)
tensor(1428.9032, device=&#39;cuda:0&#39;)
tensor(1444.6342, device=&#39;cuda:0&#39;)
tensor(1446.0267, device=&#39;cuda:0&#39;)
tensor(1434.1827, device=&#39;cuda:0&#39;)
tensor(1392.0759, device=&#39;cuda:0&#39;)
tensor(1375.9364, device=&#39;cuda:0&#39;)
tensor(1442.5314, device=&#39;cuda:0&#39;)
tensor(1428.5896, device=&#39;cuda:0&#39;)
tensor(1378.6542, device=&#39;cuda:0&#39;)
tensor(1398.1370, device=&#39;cuda:0&#39;)
tensor(1400.0981, device=&#39;cuda:0&#39;)
tensor(1431.5441, device=&#39;cuda:0&#39;)
tensor(1403.0608, device=&#39;cuda:0&#39;)
tensor(1440.6503, device=&#39;cuda:0&#39;)
tensor(1429.8313, device=&#39;cuda:0&#39;)
tensor(1441.6162, device=&#39;cuda:0&#39;)
tensor(1391.8026, device=&#39;cuda:0&#39;)
tensor(1425.2073, device=&#39;cuda:0&#39;)
tensor(1423.4188, device=&#39;cuda:0&#39;)
tensor(1389.9656, device=&#39;cuda:0&#39;)
tensor(1411.0577, device=&#39;cuda:0&#39;)
tensor(1423.1200, device=&#39;cuda:0&#39;)
tensor(1401.7646, device=&#39;cuda:0&#39;)
tensor(1408.5344, device=&#39;cuda:0&#39;)
tensor(1412.2050, device=&#39;cuda:0&#39;)
tensor(1436.6595, device=&#39;cuda:0&#39;)
tensor(1407.4791, device=&#39;cuda:0&#39;)
tensor(1394.5499, device=&#39;cuda:0&#39;)
tensor(1413.3774, device=&#39;cuda:0&#39;)
tensor(1415.2762, device=&#39;cuda:0&#39;)
tensor(1453.4368, device=&#39;cuda:0&#39;)
tensor(1434.2491, device=&#39;cuda:0&#39;)
tensor(1388.5255, device=&#39;cuda:0&#39;)
tensor(1383.2640, device=&#39;cuda:0&#39;)
tensor(1424.7712, device=&#39;cuda:0&#39;)
tensor(1397.3434, device=&#39;cuda:0&#39;)
tensor(1418.6311, device=&#39;cuda:0&#39;)
tensor(1402.5612, device=&#39;cuda:0&#39;)
tensor(1440.5050, device=&#39;cuda:0&#39;)
tensor(1402.3740, device=&#39;cuda:0&#39;)
tensor(1408.8771, device=&#39;cuda:0&#39;)
tensor(1420.6165, device=&#39;cuda:0&#39;)
tensor(1427.5487, device=&#39;cuda:0&#39;)
tensor(1410.8777, device=&#39;cuda:0&#39;)
tensor(1383.2748, device=&#39;cuda:0&#39;)
tensor(1395.0757, device=&#39;cuda:0&#39;)
tensor(1393.4822, device=&#39;cuda:0&#39;)
tensor(1393.1779, device=&#39;cuda:0&#39;)
tensor(1441.6558, device=&#39;cuda:0&#39;)
tensor(1444.5702, device=&#39;cuda:0&#39;)
tensor(1421.3900, device=&#39;cuda:0&#39;)
tensor(1431.2898, device=&#39;cuda:0&#39;)
tensor(1430.2230, device=&#39;cuda:0&#39;)
tensor(1386.1057, device=&#39;cuda:0&#39;)
tensor(1405.4774, device=&#39;cuda:0&#39;)
tensor(1450.7740, device=&#39;cuda:0&#39;)
tensor(1401.5381, device=&#39;cuda:0&#39;)
tensor(1438.6777, device=&#39;cuda:0&#39;)
tensor(1416.8682, device=&#39;cuda:0&#39;)
tensor(1404.4166, device=&#39;cuda:0&#39;)
tensor(1412.6957, device=&#39;cuda:0&#39;)
tensor(1429.1792, device=&#39;cuda:0&#39;)
tensor(1447.5914, device=&#39;cuda:0&#39;)
tensor(1384.9110, device=&#39;cuda:0&#39;)
tensor(1375.4346, device=&#39;cuda:0&#39;)
tensor(1417.9133, device=&#39;cuda:0&#39;)
tensor(1425.8375, device=&#39;cuda:0&#39;)
tensor(1422.2826, device=&#39;cuda:0&#39;)
tensor(1416.1715, device=&#39;cuda:0&#39;)
tensor(1448.8301, device=&#39;cuda:0&#39;)
tensor(1426.6920, device=&#39;cuda:0&#39;)
tensor(1428.4994, device=&#39;cuda:0&#39;)
tensor(1429.9166, device=&#39;cuda:0&#39;)
tensor(1403.6028, device=&#39;cuda:0&#39;)
tensor(1366.8010, device=&#39;cuda:0&#39;)
tensor(1396.8983, device=&#39;cuda:0&#39;)
tensor(1446.0986, device=&#39;cuda:0&#39;)
tensor(1402.0897, device=&#39;cuda:0&#39;)
tensor(1417.4302, device=&#39;cuda:0&#39;)
tensor(1395.6691, device=&#39;cuda:0&#39;)
tensor(1426.8137, device=&#39;cuda:0&#39;)
tensor(1409.6072, device=&#39;cuda:0&#39;)
tensor(1425.8777, device=&#39;cuda:0&#39;)
tensor(1395.2622, device=&#39;cuda:0&#39;)
tensor(1450.3542, device=&#39;cuda:0&#39;)
tensor(1416.1274, device=&#39;cuda:0&#39;)
tensor(1428.4930, device=&#39;cuda:0&#39;)
tensor(1414.3604, device=&#39;cuda:0&#39;)
tensor(1418.1160, device=&#39;cuda:0&#39;)
tensor(1410.1843, device=&#39;cuda:0&#39;)
tensor(1406.0295, device=&#39;cuda:0&#39;)
tensor(1390.4836, device=&#39;cuda:0&#39;)
tensor(1416.7998, device=&#39;cuda:0&#39;)
tensor(1420.3181, device=&#39;cuda:0&#39;)
tensor(1414.9705, device=&#39;cuda:0&#39;)
tensor(1441.2191, device=&#39;cuda:0&#39;)
tensor(1432.8761, device=&#39;cuda:0&#39;)
tensor(1409.1808, device=&#39;cuda:0&#39;)
tensor(1423.1477, device=&#39;cuda:0&#39;)
tensor(1381.2469, device=&#39;cuda:0&#39;)
tensor(1382.9114, device=&#39;cuda:0&#39;)
tensor(1367.7100, device=&#39;cuda:0&#39;)
tensor(1408.9882, device=&#39;cuda:0&#39;)
tensor(1422.5929, device=&#39;cuda:0&#39;)
tensor(1479.0715, device=&#39;cuda:0&#39;)
tensor(1444.9457, device=&#39;cuda:0&#39;)
tensor(1404.3279, device=&#39;cuda:0&#39;)
tensor(1406.7020, device=&#39;cuda:0&#39;)
tensor(1401.9086, device=&#39;cuda:0&#39;)
tensor(1411.5190, device=&#39;cuda:0&#39;)
tensor(1412.3406, device=&#39;cuda:0&#39;)
tensor(1407.0355, device=&#39;cuda:0&#39;)
tensor(1425.3019, device=&#39;cuda:0&#39;)
tensor(1471.7324, device=&#39;cuda:0&#39;)
tensor(1458.9967, device=&#39;cuda:0&#39;)
tensor(1458.5677, device=&#39;cuda:0&#39;)
tensor(1421.5378, device=&#39;cuda:0&#39;)
tensor(1424.3644, device=&#39;cuda:0&#39;)
tensor(1399.3219, device=&#39;cuda:0&#39;)
tensor(1426.1769, device=&#39;cuda:0&#39;)
tensor(1428.2299, device=&#39;cuda:0&#39;)
tensor(1394.2687, device=&#39;cuda:0&#39;)
tensor(1450.3566, device=&#39;cuda:0&#39;)
tensor(1429.1484, device=&#39;cuda:0&#39;)
tensor(1409.4882, device=&#39;cuda:0&#39;)
tensor(1401.9738, device=&#39;cuda:0&#39;)
tensor(1408.9937, device=&#39;cuda:0&#39;)
tensor(1431.1775, device=&#39;cuda:0&#39;)
tensor(1446.2382, device=&#39;cuda:0&#39;)
tensor(1389.8379, device=&#39;cuda:0&#39;)
tensor(1380.1997, device=&#39;cuda:0&#39;)
tensor(1434.7024, device=&#39;cuda:0&#39;)
tensor(1413.0824, device=&#39;cuda:0&#39;)
tensor(1375.3699, device=&#39;cuda:0&#39;)
tensor(1456.1954, device=&#39;cuda:0&#39;)
tensor(1448.0901, device=&#39;cuda:0&#39;)
tensor(1411.6409, device=&#39;cuda:0&#39;)
tensor(1381.5652, device=&#39;cuda:0&#39;)
tensor(1434.2756, device=&#39;cuda:0&#39;)
tensor(1439.8295, device=&#39;cuda:0&#39;)
tensor(1403.3726, device=&#39;cuda:0&#39;)
tensor(1388.3306, device=&#39;cuda:0&#39;)
tensor(1420.6050, device=&#39;cuda:0&#39;)
tensor(1438.3170, device=&#39;cuda:0&#39;)
tensor(1422.2806, device=&#39;cuda:0&#39;)
tensor(1403.1416, device=&#39;cuda:0&#39;)
tensor(1455.1946, device=&#39;cuda:0&#39;)
tensor(1393.4119, device=&#39;cuda:0&#39;)
tensor(1429.4374, device=&#39;cuda:0&#39;)
tensor(1388.5776, device=&#39;cuda:0&#39;)
tensor(1402.1976, device=&#39;cuda:0&#39;)
tensor(1419.8860, device=&#39;cuda:0&#39;)
tensor(1418.9652, device=&#39;cuda:0&#39;)
tensor(1420.8337, device=&#39;cuda:0&#39;)
tensor(1414.4735, device=&#39;cuda:0&#39;)
tensor(1408.0876, device=&#39;cuda:0&#39;)
tensor(1456.0737, device=&#39;cuda:0&#39;)
tensor(1406.4535, device=&#39;cuda:0&#39;)
tensor(1384.9897, device=&#39;cuda:0&#39;)
tensor(1414.2520, device=&#39;cuda:0&#39;)
tensor(1413.4073, device=&#39;cuda:0&#39;)
tensor(1400.8571, device=&#39;cuda:0&#39;)
tensor(1380.0747, device=&#39;cuda:0&#39;)
tensor(1377.0696, device=&#39;cuda:0&#39;)
tensor(1379.1771, device=&#39;cuda:0&#39;)
tensor(1399.6715, device=&#39;cuda:0&#39;)
tensor(1441.7579, device=&#39;cuda:0&#39;)
tensor(1399.0868, device=&#39;cuda:0&#39;)
tensor(1456.7535, device=&#39;cuda:0&#39;)
tensor(1401.8491, device=&#39;cuda:0&#39;)
tensor(1413.5541, device=&#39;cuda:0&#39;)
tensor(1429.7538, device=&#39;cuda:0&#39;)
tensor(1406.7175, device=&#39;cuda:0&#39;)
tensor(1453.6948, device=&#39;cuda:0&#39;)
tensor(1402.9825, device=&#39;cuda:0&#39;)
tensor(1411.7798, device=&#39;cuda:0&#39;)
tensor(1441.6416, device=&#39;cuda:0&#39;)
tensor(1404.1726, device=&#39;cuda:0&#39;)
tensor(1432.4253, device=&#39;cuda:0&#39;)
tensor(1413.1604, device=&#39;cuda:0&#39;)
tensor(1401.4050, device=&#39;cuda:0&#39;)
tensor(1425.7926, device=&#39;cuda:0&#39;)
tensor(1413.5303, device=&#39;cuda:0&#39;)
tensor(1405.1923, device=&#39;cuda:0&#39;)
tensor(1450.2354, device=&#39;cuda:0&#39;)
tensor(1407.7283, device=&#39;cuda:0&#39;)
tensor(1436.4534, device=&#39;cuda:0&#39;)
tensor(1384.6461, device=&#39;cuda:0&#39;)
tensor(1398.5176, device=&#39;cuda:0&#39;)
tensor(1438.2490, device=&#39;cuda:0&#39;)
tensor(1457.0647, device=&#39;cuda:0&#39;)
tensor(1426.2281, device=&#39;cuda:0&#39;)
tensor(1419.3256, device=&#39;cuda:0&#39;)
tensor(1399.1471, device=&#39;cuda:0&#39;)
tensor(1423.1528, device=&#39;cuda:0&#39;)
tensor(1397.5256, device=&#39;cuda:0&#39;)
tensor(1415.1674, device=&#39;cuda:0&#39;)
tensor(1407.4146, device=&#39;cuda:0&#39;)
tensor(1452.3379, device=&#39;cuda:0&#39;)
tensor(1446.0323, device=&#39;cuda:0&#39;)
tensor(1441.5829, device=&#39;cuda:0&#39;)
tensor(1407.5884, device=&#39;cuda:0&#39;)
tensor(1420.2661, device=&#39;cuda:0&#39;)
tensor(1431.3302, device=&#39;cuda:0&#39;)
tensor(1410.5631, device=&#39;cuda:0&#39;)
tensor(1417.2163, device=&#39;cuda:0&#39;)
tensor(1437.8044, device=&#39;cuda:0&#39;)
tensor(1412.6334, device=&#39;cuda:0&#39;)
tensor(1436.4994, device=&#39;cuda:0&#39;)
tensor(1418.1632, device=&#39;cuda:0&#39;)
tensor(1420.6115, device=&#39;cuda:0&#39;)
tensor(1439.8173, device=&#39;cuda:0&#39;)
tensor(1414.1357, device=&#39;cuda:0&#39;)
tensor(1394.1591, device=&#39;cuda:0&#39;)
tensor(1401.5677, device=&#39;cuda:0&#39;)
tensor(1402.8163, device=&#39;cuda:0&#39;)
tensor(1418.9330, device=&#39;cuda:0&#39;)
tensor(1441.8569, device=&#39;cuda:0&#39;)
tensor(1423.7625, device=&#39;cuda:0&#39;)
tensor(1399.2745, device=&#39;cuda:0&#39;)
tensor(1393.4146, device=&#39;cuda:0&#39;)
tensor(1401.2682, device=&#39;cuda:0&#39;)
tensor(1424.5221, device=&#39;cuda:0&#39;)
tensor(1394.0769, device=&#39;cuda:0&#39;)
tensor(1366.8616, device=&#39;cuda:0&#39;)
tensor(1410.2253, device=&#39;cuda:0&#39;)
tensor(1399.7590, device=&#39;cuda:0&#39;)
tensor(1407.2003, device=&#39;cuda:0&#39;)
tensor(1418.5439, device=&#39;cuda:0&#39;)
tensor(1460.2466, device=&#39;cuda:0&#39;)
tensor(1429.7393, device=&#39;cuda:0&#39;)
tensor(1385.3613, device=&#39;cuda:0&#39;)
tensor(1438.1396, device=&#39;cuda:0&#39;)
tensor(1390.1895, device=&#39;cuda:0&#39;)
tensor(1463.1154, device=&#39;cuda:0&#39;)
tensor(1409.0605, device=&#39;cuda:0&#39;)
tensor(1412.3632, device=&#39;cuda:0&#39;)
tensor(1437.3600, device=&#39;cuda:0&#39;)
tensor(1395.8154, device=&#39;cuda:0&#39;)
tensor(1365.6179, device=&#39;cuda:0&#39;)
tensor(1441.3519, device=&#39;cuda:0&#39;)
tensor(1386.6602, device=&#39;cuda:0&#39;)
tensor(1423.1627, device=&#39;cuda:0&#39;)
tensor(1410.9005, device=&#39;cuda:0&#39;)
tensor(1390.1128, device=&#39;cuda:0&#39;)
tensor(1435.8666, device=&#39;cuda:0&#39;)
tensor(1444.9093, device=&#39;cuda:0&#39;)
tensor(1387.8092, device=&#39;cuda:0&#39;)
tensor(1444.0508, device=&#39;cuda:0&#39;)
tensor(1418.8849, device=&#39;cuda:0&#39;)
tensor(1390.7021, device=&#39;cuda:0&#39;)
tensor(1424.4188, device=&#39;cuda:0&#39;)
tensor(1444.6207, device=&#39;cuda:0&#39;)
tensor(1423.9720, device=&#39;cuda:0&#39;)
tensor(1408.1212, device=&#39;cuda:0&#39;)
tensor(1435.5199, device=&#39;cuda:0&#39;)
tensor(1439.0817, device=&#39;cuda:0&#39;)
tensor(1428.3363, device=&#39;cuda:0&#39;)
tensor(1420.5914, device=&#39;cuda:0&#39;)
tensor(1456.4099, device=&#39;cuda:0&#39;)
tensor(1443.0768, device=&#39;cuda:0&#39;)
tensor(1404.6733, device=&#39;cuda:0&#39;)
tensor(1383.9767, device=&#39;cuda:0&#39;)
tensor(1411.3325, device=&#39;cuda:0&#39;)
tensor(1444.2469, device=&#39;cuda:0&#39;)
tensor(1422.6304, device=&#39;cuda:0&#39;)
tensor(1406.2065, device=&#39;cuda:0&#39;)
tensor(1426.7931, device=&#39;cuda:0&#39;)
tensor(1442.3892, device=&#39;cuda:0&#39;)
tensor(1475.6561, device=&#39;cuda:0&#39;)
tensor(1426.5789, device=&#39;cuda:0&#39;)
tensor(1421.5833, device=&#39;cuda:0&#39;)
tensor(1430.1593, device=&#39;cuda:0&#39;)
tensor(1438.6716, device=&#39;cuda:0&#39;)
tensor(1432.8663, device=&#39;cuda:0&#39;)
tensor(1440.8177, device=&#39;cuda:0&#39;)
tensor(1453.5370, device=&#39;cuda:0&#39;)
tensor(1414.8185, device=&#39;cuda:0&#39;)
tensor(1409.4082, device=&#39;cuda:0&#39;)
tensor(1443.3878, device=&#39;cuda:0&#39;)
tensor(1410.9117, device=&#39;cuda:0&#39;)
tensor(1450.1927, device=&#39;cuda:0&#39;)
tensor(1439.9794, device=&#39;cuda:0&#39;)
tensor(1455.7130, device=&#39;cuda:0&#39;)
tensor(1408.6846, device=&#39;cuda:0&#39;)
tensor(1370.5558, device=&#39;cuda:0&#39;)
tensor(1411.1130, device=&#39;cuda:0&#39;)
tensor(1425.2698, device=&#39;cuda:0&#39;)
tensor(1415.9679, device=&#39;cuda:0&#39;)
tensor(1426.5792, device=&#39;cuda:0&#39;)
tensor(1430.0621, device=&#39;cuda:0&#39;)
tensor(1429.0353, device=&#39;cuda:0&#39;)
tensor(1436.3405, device=&#39;cuda:0&#39;)
tensor(1415.4597, device=&#39;cuda:0&#39;)
tensor(1398.7305, device=&#39;cuda:0&#39;)
tensor(1412.2063, device=&#39;cuda:0&#39;)
tensor(1396.1304, device=&#39;cuda:0&#39;)
tensor(1392.3531, device=&#39;cuda:0&#39;)
tensor(1447.8683, device=&#39;cuda:0&#39;)
tensor(1408.5255, device=&#39;cuda:0&#39;)
tensor(1443.4084, device=&#39;cuda:0&#39;)
tensor(1392.5245, device=&#39;cuda:0&#39;)
tensor(1424.6589, device=&#39;cuda:0&#39;)
tensor(1386.9657, device=&#39;cuda:0&#39;)
tensor(1404.4888, device=&#39;cuda:0&#39;)
tensor(1411.2113, device=&#39;cuda:0&#39;)
tensor(1418.5787, device=&#39;cuda:0&#39;)
tensor(1425.8960, device=&#39;cuda:0&#39;)
tensor(1429.8405, device=&#39;cuda:0&#39;)
tensor(1439.3208, device=&#39;cuda:0&#39;)
tensor(1435.7345, device=&#39;cuda:0&#39;)
tensor(1378.0029, device=&#39;cuda:0&#39;)
tensor(1435.4418, device=&#39;cuda:0&#39;)
tensor(1424.1644, device=&#39;cuda:0&#39;)
tensor(1433.0961, device=&#39;cuda:0&#39;)
tensor(1409.1449, device=&#39;cuda:0&#39;)
tensor(1435.2638, device=&#39;cuda:0&#39;)
tensor(1427.7124, device=&#39;cuda:0&#39;)
tensor(1399.4819, device=&#39;cuda:0&#39;)
tensor(1431.6205, device=&#39;cuda:0&#39;)
tensor(1450.2629, device=&#39;cuda:0&#39;)
tensor(1408.6251, device=&#39;cuda:0&#39;)
tensor(1441.3998, device=&#39;cuda:0&#39;)
tensor(1424.9849, device=&#39;cuda:0&#39;)
tensor(1433.3588, device=&#39;cuda:0&#39;)
tensor(1412.4851, device=&#39;cuda:0&#39;)
tensor(1411.2235, device=&#39;cuda:0&#39;)
tensor(1418.6223, device=&#39;cuda:0&#39;)
tensor(1390.9233, device=&#39;cuda:0&#39;)
tensor(1391.8456, device=&#39;cuda:0&#39;)
tensor(1389.3798, device=&#39;cuda:0&#39;)
tensor(1441.3324, device=&#39;cuda:0&#39;)
tensor(1425.0355, device=&#39;cuda:0&#39;)
tensor(1428.2485, device=&#39;cuda:0&#39;)
tensor(1414.7605, device=&#39;cuda:0&#39;)
tensor(1451.6646, device=&#39;cuda:0&#39;)
tensor(1421.8340, device=&#39;cuda:0&#39;)
tensor(1419.5419, device=&#39;cuda:0&#39;)
tensor(1429.1060, device=&#39;cuda:0&#39;)
tensor(1424.3914, device=&#39;cuda:0&#39;)
tensor(1463.5829, device=&#39;cuda:0&#39;)
tensor(1442.8510, device=&#39;cuda:0&#39;)
tensor(1418.9368, device=&#39;cuda:0&#39;)
tensor(1417.0631, device=&#39;cuda:0&#39;)
tensor(1423.2100, device=&#39;cuda:0&#39;)
tensor(1418.9729, device=&#39;cuda:0&#39;)
tensor(1384.8419, device=&#39;cuda:0&#39;)
tensor(1415.7753, device=&#39;cuda:0&#39;)
tensor(1446.4684, device=&#39;cuda:0&#39;)
tensor(1367.5852, device=&#39;cuda:0&#39;)
tensor(1400.4757, device=&#39;cuda:0&#39;)
tensor(1425.3563, device=&#39;cuda:0&#39;)
tensor(1433.1383, device=&#39;cuda:0&#39;)
tensor(1422.0845, device=&#39;cuda:0&#39;)
tensor(1415.9822, device=&#39;cuda:0&#39;)
tensor(1424.4999, device=&#39;cuda:0&#39;)
tensor(1373.3406, device=&#39;cuda:0&#39;)
tensor(1412.9338, device=&#39;cuda:0&#39;)
tensor(1413.8733, device=&#39;cuda:0&#39;)
tensor(1384.5674, device=&#39;cuda:0&#39;)
tensor(1439.4919, device=&#39;cuda:0&#39;)
tensor(1423.0312, device=&#39;cuda:0&#39;)
tensor(1413.1295, device=&#39;cuda:0&#39;)
tensor(1444.2146, device=&#39;cuda:0&#39;)
tensor(1433.5981, device=&#39;cuda:0&#39;)
tensor(1446.2844, device=&#39;cuda:0&#39;)
tensor(1436.2203, device=&#39;cuda:0&#39;)
tensor(1388.2151, device=&#39;cuda:0&#39;)
tensor(1410.3483, device=&#39;cuda:0&#39;)
tensor(1428.2197, device=&#39;cuda:0&#39;)
tensor(1467.3116, device=&#39;cuda:0&#39;)
tensor(1387.5735, device=&#39;cuda:0&#39;)
tensor(1418.7992, device=&#39;cuda:0&#39;)
tensor(1389.2145, device=&#39;cuda:0&#39;)
tensor(1441.4642, device=&#39;cuda:0&#39;)
tensor(1430.0614, device=&#39;cuda:0&#39;)
tensor(1425.9270, device=&#39;cuda:0&#39;)
tensor(1379.5526, device=&#39;cuda:0&#39;)
Time taken: 1.1767361164093018
实验一消耗时间：0.083892822265625，实验二消耗时间：1.1767361164093018
</code></pre></div>
<h3 id="564">练习 5.6.4<a class="headerlink" href="#564" title="Permanent link">⚓︎</a></h3>
<p>测量同时在两个GPU上执行两个矩阵乘法与在一个GPU上按顺序执行两个矩阵乘法所需的时间。提示：应该看到近乎线性的缩放。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;执行两个矩阵乘法并行在两个GPU上所需的时间通常会比在单个GPU上按顺序执行这两个操作要快得多。但实际的时间取决于矩阵的大小、硬件配置和算法实现。</p>
<p>&emsp;&emsp;但由于笔者只有一张卡，所以只做了在单个GPU上顺序执行两个矩阵乘法的实验。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># 创建两个随机矩阵</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># 顺序计算</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">c1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">sequential_time</span> <span class="o">=</span> <span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequential time: </span><span class="si">{</span><span class="n">sequential_time</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Sequential time: 0.00299954 seconds
</code></pre></div>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../../ch04/ch04/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 第4章 多层感知机">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                第4章 多层感知机
              </div>
            </div>
          </a>
        
        
          
          <a href="../../ch06/ch06/" class="md-footer__link md-footer__link--next" aria-label="下一页: 第6章 卷积神经网络">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                第6章 卷积神经网络
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>