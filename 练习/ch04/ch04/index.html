
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E7%BB%83%E4%B9%A0/ch04/ch04/">
      
      
        <link rel="prev" href="../../ch03/ch03/">
      
      
        <link rel="next" href="../../ch05/ch05/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>第4章 多层感知机 - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#4" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              第4章 多层感知机
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E6%95%99%E7%A8%8B/" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/09-recurrent-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/12-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/13-computational-performance/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" checked>
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Ch04
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    第4章 多层感知机
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    第4章 多层感知机
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 多层感知机
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 多层感知机">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#411" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 多层感知机的从零开始实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 多层感知机的从零开始实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#421" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#425" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#426" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 多层感知机的简洁实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.3 多层感知机的简洁实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#431" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#432" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#433" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 模型选择、欠拟合和过拟合
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.4 模型选择、欠拟合和过拟合">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#441" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#442" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#443" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#444" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 权重衰减
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.5 权重衰减">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#451" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#452" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#453" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#454" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#455" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#456" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 暂退法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.6 暂退法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#461" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#462" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#463" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#464" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#465" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#467" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.7
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#468" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.8
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#47" class="md-nav__link">
    <span class="md-ellipsis">
      4.7 前向传播、反向传播和计算图
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.7 前向传播、反向传播和计算图">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#471" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#472" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#473" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#474" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#475" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#48" class="md-nav__link">
    <span class="md-ellipsis">
      4.8 数值稳定性和模型初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.8 数值稳定性和模型初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#481" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#482" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#483" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#484" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#49" class="md-nav__link">
    <span class="md-ellipsis">
      4.9 环境和分布偏移
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.9 环境和分布偏移">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#491" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#492" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#493" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#494" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#410-kaggle" class="md-nav__link">
    <span class="md-ellipsis">
      4.10 实战Kaggle比赛：预测房价
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.10 实战Kaggle比赛：预测房价">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4102" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4103" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4104" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4105" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4106" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch05/ch05/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch09/ch09/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#41" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 多层感知机
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.1 多层感知机">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#411" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#412" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#413" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#414" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.1.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 多层感知机的从零开始实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.2 多层感知机的从零开始实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#421" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#422" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#423" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#424" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#425" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#426" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.2.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 多层感知机的简洁实现
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.3 多层感知机的简洁实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#431" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#432" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#433" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.3.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#44" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 模型选择、欠拟合和过拟合
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.4 模型选择、欠拟合和过拟合">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#441" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#442" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#443" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#444" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.4.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#45" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 权重衰减
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.5 权重衰减">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#451" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#452" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#453" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#454" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#455" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#456" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.5.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#46" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 暂退法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.6 暂退法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#461" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#462" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#463" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#464" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#465" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#467" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.7
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#468" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.6.8
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#47" class="md-nav__link">
    <span class="md-ellipsis">
      4.7 前向传播、反向传播和计算图
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.7 前向传播、反向传播和计算图">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#471" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#472" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#473" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#474" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#475" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.7.5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#48" class="md-nav__link">
    <span class="md-ellipsis">
      4.8 数值稳定性和模型初始化
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.8 数值稳定性和模型初始化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#481" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#482" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#483" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#484" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.8.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#49" class="md-nav__link">
    <span class="md-ellipsis">
      4.9 环境和分布偏移
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.9 环境和分布偏移">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#491" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#492" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#493" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#494" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.9.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#410-kaggle" class="md-nav__link">
    <span class="md-ellipsis">
      4.10 实战Kaggle比赛：预测房价
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4.10 实战Kaggle比赛：预测房价">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4102" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4103" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4104" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4105" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4106" class="md-nav__link">
    <span class="md-ellipsis">
      练习4.10.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch04/ch04.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch04/ch04.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="4">第4章 多层感知机<a class="headerlink" href="#4" title="Permanent link">⚓︎</a></h1>
<h2 id="41">4.1 多层感知机<a class="headerlink" href="#41" title="Permanent link">⚓︎</a></h2>
<h3 id="411">练习4.1.1<a class="headerlink" href="#411" title="Permanent link">⚓︎</a></h3>
<p>计算pReLU激活函数的导数。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;由<span class="arithmatex">\(<span class="arithmatex">\(pReLU(x)= \begin{cases}x &amp; \text { if } x&gt;=0 \\ \alpha x  &amp; \text { if } x&lt;0 \end{cases}\)</span>\)</span></p>
<p>&emsp;&emsp;可得
$$ \frac{d}{d x} pReLU(x)= \begin{cases}1 &amp; \text { if } x&gt;=0 \ \alpha   &amp; \text { if } x&lt;0 \end{cases}$$</p>
<p>&emsp;&emsp;以下使用画图展示：</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="c1">#import numpy  as np</span>
<span class="c1">#import torchvision</span>
<span class="c1">#from torch import nn</span>
<span class="c1">#from torch.utils import data</span>
<span class="c1">#from torchvision import transforms</span>
<span class="c1">#import math</span>
<span class="c1">#import pandas as pd</span>
<span class="c1">#torch.nn.PReLU(num_parameters=1,init=0.25)不用d2l时的PReLU 函数 其中 a 由init设置 同时它是一个可学习的参数</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prelu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> 
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;prelu(x)&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;grad of prelu&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p><img alt="svg" src="../output_7_0.svg" /></p>
<h3 id="412">练习4.1.2<a class="headerlink" href="#412" title="Permanent link">⚓︎</a></h3>
<p>证明一个仅使用ReLU（或pReLU）的多层感知机构造了一个连续的分段线性函数。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;以下证明参考李宏毅老师课程的<a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html">讲义</a> 和<a href="https://www.youtube.com/watch?v=KKT2VkTdFyc&amp;list=RDCMUC2ggjtuuWvxrHHHiaDH1dlQ&amp;index=2">视频</a></p>
<p>&emsp;&emsp;假设我们是要近似一个如下式具有如下式子表示的性质的连续函数 L-Lipschitz函数<span class="arithmatex">\(f^*\)</span> </p>
<div class="arithmatex">\[
\left\|f^*\left(x_1\right)-f^*\left(x_2\right)\right\| \leq L\left\|x_1-x_2\right\|
\]</div>
<p>&emsp;&emsp;我们不妨假设要近似构造的函数定义域处在为0到1,同时我们定义当一个很小的误差值<span class="arithmatex">\(\epsilon\)</span>，当我们构造的函数,满足如下关系时,我们可以认为我们近似拟合了我们想要的目标函数</p>
<div class="arithmatex">\[\max _{0 \leq x \leq 1}\left|f(x)-f^*(x)\right| \leq \varepsilon \Leftrightarrow \int_0^1\left|f(x)-f^*(x)\right|^2 d x \leq \varepsilon\]</div>
<p>&emsp;&emsp;如图所示对于下图中蓝色的实线函数，只要两个relu神经元就可以拟合。</p>
<p><img alt="relu" src="../ch4-4-1-2-relu.png" /></p>
<p>&emsp;&emsp;所以如下图所示,当考虑要用多个relu（下图绿线,两个绿点之间表示一段用2个relu得到的分段函数）来近似拟合一个连续的定义域在0到1的L-Lipschitz函数(下图实线），我们只要考虑一个适当的分段范围$ l=\displaystyle\frac{\epsilon}{L}<span class="arithmatex">\((将在后面给出证明),就可以得到满足我们误差\)</span>\epsilon<span class="arithmatex">\(要求的近似的函数。当我们知道分段范围我们就可以计算我们所需要的分段函数数\)</span> \displaystyle\frac{L}{\epsilon}<span class="arithmatex">\(以及最终的relu数量\)</span>2 \displaystyle\frac{L}{\epsilon}$</p>
<p><img alt="relufit" src="../ch4-4-1-2-relufit.png" /></p>
<p>&emsp;&emsp;关于$ l=\displaystyle\frac{ \varepsilon}{L}$的证明</p>
<div class="arithmatex">\[\max _{长度为l的小段范围}\left|f(x)-f^*(x)\right| \leq \varepsilon \]</div>
<p>$$\max _{长度为l的小段范围}\left|f(x)-f^<em>(x)\right|=error \leq\left|f^</em>(x_1)-f^*(x_2)\right|\leq L \left|x_1-x_2\right| \leq  Ll $$
 &emsp;&emsp;这里的<span class="arithmatex">\(x_1\)</span>和<span class="arithmatex">\(x_2\)</span>是<span class="arithmatex">\(f^*\)</span>在小段范围内最大值点和最小值点</p>
<p>所以只要<span class="arithmatex">\(Ll\leq \varepsilon\)</span>就能满足近似要求，故<span class="arithmatex">\(l\)</span>最大取<span class="arithmatex">\(\displaystyle\frac{ \varepsilon}{L}\)</span></p>
<h3 id="413">练习4.1.3<a class="headerlink" href="#413" title="Permanent link">⚓︎</a></h3>
<p>证明<span class="arithmatex">\(\operatorname{tanh}(x) + 1 = 2 \operatorname{sigmoid}(2x)\)</span>。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;已知：$$
\operatorname{tanh}(x)=\frac{1 - \exp(-2x)}{1 + \exp(-2x)}
$$
&emsp;&emsp;故左式：<span class="arithmatex">\(<span class="arithmatex">\(\operatorname{tanh}(x) + 1 =\frac{1 - \exp(-2x)}{1 + \exp(-2x)}+1= \frac{2}{1 + \exp(-2x)}\)</span>\)</span>   </p>
<p>&emsp;&emsp;同时有<span class="arithmatex">\(<span class="arithmatex">\(\operatorname{sigmoid}(2x)= \frac{1}{1 + \exp(-2x)}\)</span>\)</span> 
&emsp;&emsp;故易证 左式=左式</p>
<p>&emsp;&emsp;以下使用<code>torch</code>编程进行验证：</p>
<div class="highlight"><pre><span></span><code><span class="c1">#加载包见4.1.1</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">+</span><span class="mf">1.0</span>
<span class="n">y2</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>


<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="p">[</span><span class="n">y1</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">y2</span><span class="o">.</span><span class="n">detach</span><span class="p">()],</span>
         <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tanh(x)+1&#39;</span><span class="p">,</span><span class="s1">&#39;2sigmoid(2x)&#39;</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">);</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">);</span>
</code></pre></div>
<p><img alt="svg" src="../output_29_0.svg" /></p>
<h3 id="414">练习4.1.4<a class="headerlink" href="#414" title="Permanent link">⚓︎</a></h3>
<p>假设我们有一个非线性单元，将它一次应用于一个小批量的数据。这会导致什么样的问题？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;将非线性单元一次应用于一个小批量的数据可能会导致以下问题：</p>
<ol>
<li>
<p>信息丢失：非线性单元通常引入非线性变换，将输入数据映射到新的表示空间。当应用于小批量的数据时，可能会存在数据样本之间的相关性和多样性不足的问题。这可能导致一部分样本的信息丢失或被模糊化，因为小批量数据可能无法充分捕捉到全局数据分布的特征。</p>
</li>
<li>
<p>噪声放大：小批量数据通常包含相对较少的样本，其中可能存在噪声或异常值。当非线性单元应用于这些数据时，噪声和异常值可能被放大，导致输出结果出现不稳定或错误的情况。</p>
</li>
<li>
<p>参数更新不准确：在训练神经网络时，通过反向传播算法进行参数更新。当应用非线性单元于小批量数据时，由于数据的有限性，可能导致梯度估计的不准确性。这可能影响参数的更新过程，使得网络收敛速度变慢或无法达到最佳状态。</p>
</li>
<li>
<p>过拟合风险增加：小批量数据的样本量较少，这可能增加过拟合的风险。由于小批量数据可能无法充分代表整体数据分布，模型可能更容易过度拟合训练集，导致泛化性能下降。</p>
</li>
</ol>
<p>为了缓解这些问题，可以考虑以下方法：</p>
<ul>
<li>增加小批量数据的样本量，以更好地代表整体数据分布。</li>
<li>使用正则化技术（如L1或L2正则化）来控制模型的复杂度，减少过拟合风险。</li>
<li>使用数据增强技术来扩充小批量数据的多样性，增加训练样本的数量和质量。</li>
<li>采用批归一化等技术来规范化输入数据，以减小噪声的影响。</li>
<li>如果可行，考虑使用更大的批量数据来提高模型性能和稳定性。</li>
</ul>
<h2 id="42">4.2 多层感知机的从零开始实现<a class="headerlink" href="#42" title="Permanent link">⚓︎</a></h2>
<h3 id="421">练习4.2.1<a class="headerlink" href="#421" title="Permanent link">⚓︎</a></h3>
<p>在所有其他参数保持不变的情况下，更改超参数<code>num_hiddens</code>的值，并查看此超参数的变化对结果有何影响。确定此超参数的最佳值。</p>
<p><strong>解答：</strong>  </p>
<p>&emsp;&emsp;256到376范围内num_hiddens得到结果基本一致，所以num_hiddens取256，能保证其他参数不变时得到最佳的结果。</p>
<p>&emsp;&emsp;以下使用torch编程进行实验：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">initweight4_2_1</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span><span class="p">):</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span> <span class="n">params</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">showtrain</span><span class="o">=</span><span class="mi">0</span> <span class="c1">#showtrain-1 可以展示训练过程的情况</span>
<span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span>
<span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">num_hiddenslist</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">230</span><span class="p">,</span><span class="mi">370</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">animatornum_hiddens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;num_hiddens&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="n">num_hiddenslist</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">num_hiddenslist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">num_hiddens</span> <span class="ow">in</span> <span class="n">num_hiddenslist</span><span class="p">:</span>
    <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">initweight4_2_1</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">)</span>
    <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="nd">@W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>  <span class="c1"># 这里“@”代表矩阵乘法</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">H</span><span class="nd">@W2</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">showtrain</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;epoch num_hiddens:</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span><span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">showtrain</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;num_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">,train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">,test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animatornum_hiddens</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,(</span><span class="n">train_acc</span><span class="p">,</span><span class="n">test_acc</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
    <span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
    <span class="k">assert</span> <span class="n">test_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_acc</span>
</code></pre></div>
<p><img alt="svg" src="../output_39_0.svg" /></p>
<h3 id="422">练习4.2.2<a class="headerlink" href="#422" title="Permanent link">⚓︎</a></h3>
<p>尝试添加更多的隐藏层，并查看它对结果有何影响。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在其他参数不变的情况下单纯增加隐藏层数会减少准确率。</p>
<p>&emsp;&emsp;以下使用torch编程进行实验：</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.2.1</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">initweight4_2_2</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span><span class="n">num_hiddenlayers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">params</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_hiddenlayers</span><span class="p">):</span>
            <span class="n">a</span><span class="o">=</span><span class="n">num_inputs</span> <span class="k">if</span> <span class="n">i</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">num_hiddens</span>
            <span class="n">b</span><span class="o">=</span><span class="n">num_hiddens</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">))</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">))</span>
    <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>       
    <span class="k">return</span> <span class="n">params</span>
<span class="n">showtrain</span><span class="o">=</span><span class="mi">0</span> <span class="c1">#showtrain-1 可以展示训练过程的情况</span>
<span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span>
<span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span>
<span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">num_hiddenlayerslist</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">animatornum_hiddenlayers</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;hiddenlayers&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="n">num_hiddenlayerslist</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">num_hiddenlayerslist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.88</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">num_hiddenlayers</span> <span class="ow">in</span> <span class="n">num_hiddenlayerslist</span><span class="p">:</span>
    <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">params</span><span class="o">=</span><span class="n">initweight4_2_2</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span><span class="n">num_hiddenlayers</span><span class="o">=</span><span class="n">num_hiddenlayers</span><span class="p">)</span>
    <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="nd">@params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="o">*</span><span class="n">num_hiddenlayers</span> <span class="p">,</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">H</span><span class="o">@</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># 这里“@”代表矩阵乘法</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">H</span><span class="o">@</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">showtrain</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;epoch num_hiddenlayers:</span><span class="si">{</span><span class="n">num_hiddenlayers</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span><span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">showtrain</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;num_hiddenlayers=</span><span class="si">{</span><span class="n">num_hiddenlayers</span><span class="si">}</span><span class="s1">,train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">,test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animatornum_hiddenlayers</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">num_hiddenlayers</span><span class="p">,(</span><span class="n">train_acc</span><span class="p">,</span><span class="n">test_acc</span><span class="p">))</span>
</code></pre></div>
<p><img alt="svg" src="../output_44_0.svg" /></p>
<h3 id="423">练习4.2.3<a class="headerlink" href="#423" title="Permanent link">⚓︎</a></h3>
<p>改变学习速率会如何影响结果？保持模型架构和其他超参数（包括轮数）不变，学习率设置为多少会带来最好的结果？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;较大的学习速率可以让loss下降更快，在初期更快的训练模型，但也可能造成更新参数值过大 ,导致参数在最优解附近来回跳跃无法收敛或者收敛在错误的值,同时过小的学习率会要求更多的训练轮数以达到收敛。最理想的学习率不是固定值, 而是一个随着训练次数衰减的变化的值, 也就是在训练初期, 学习率比较大, 随着训练的进行, 学习率不断减小, 直到模型收敛.</p>
<p>&emsp;&emsp;以下使用torch编程进行实验：</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.2.1</span>
<span class="n">listlr</span><span class="o">=</span><span class="p">[</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.001</span><span class="p">]</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">resize</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">num_epochs</span><span class="o">=</span><span class="mi">20</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">listlr</span><span class="p">:</span>
    <span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">;</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">;</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span><span class="p">;</span>
    <span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">initweight4_2_1</span><span class="p">()</span><span class="c1">#initweight4_2_1定义见4.2.1</span>
    <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="nd">@W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>  <span class="c1"># 这里“@”代表矩阵乘法</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">H</span><span class="nd">@W2</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>


        <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">epoch_loss</span><span class="p">,</span><span class="n">label</span><span class="o">=</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span> <span class="p">)</span>

<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">();</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div>
<p><img alt="svg" src="../output_49_0.svg" /></p>
<h3 id="424">练习4.2.4<a class="headerlink" href="#424" title="Permanent link">⚓︎</a></h3>
<p>通过对所有超参数（学习率、轮数、隐藏层数、每层的隐藏单元数）进行联合优化，可以得到的最佳结果是什么？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;考虑隐藏层数固定为1,学习轮数固定为10,每层的隐藏单元数在（256，128，64 ,32,16）中选取，学习率在（0.0001,0.001,0.01,0.1,1)范围内选取，batch_size(批大小)在（512,256,128,64,32,16）范围内选取的超参数优化。以下展示部分实验数据(由于训练的随机性后面展示的结果得到的数据与此表格会有一些不相符）
| num_epochs | batch_size |  lr  | num_hiddens | test_acc | train_acc | train_loss  |
| ---------- | ---------- | :--: | ----------- | -------- | --------- | ----------- |
| 10         | 256        | 0.1  | 32          | 0.8459   | 0.854367  | 0.41196403  |
| 10         | 128        | 0.1  | 256         | 0.8629   | 0.8808833 | 0.33219405  |
| 10         | 64         | 0.1  | 256         | 0.8769   | 0.89346   | 0.291003041 |
| 10         | 32         | 0.1  | 256         | 0.8865   | 0.9014    | 0.26649176  |
| 10         | 16         | 0.1  | 512         | 0.8824   | 0.90453   | 0.2544131   |</p>
<p>&emsp;&emsp;展示最优结果训练过程和数据</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.2.1</span>
<span class="n">num_inputs</span><span class="p">,</span><span class="n">num_outputs</span><span class="p">,</span><span class="n">num_hiddens</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">256</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span><span class="mi">32</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">initweight4_2_1</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">)</span><span class="c1">#initweight4_2_1定义见4.2.1</span>
<span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="nd">@W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span>  <span class="c1"># 这里“@”代表矩阵乘法</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">H</span><span class="nd">@W2</span> <span class="o">+</span> <span class="n">b2</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;epoch &#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.91</span><span class="p">],</span>
                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span>   <span class="n">updater</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>

    <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
<span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
<span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
<span class="k">assert</span> <span class="n">test_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_acc</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epochs=</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">,num_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">,lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">,batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">,train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">,test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epochs=10,num_hiddens=512,lr=0.1,batch_size=16,train_loss=0.25638708310673636, train_acc=0.9039666666666667,test_acc=0.8697
</code></pre></div>
<p><img alt="svg" src="../output_54_1.svg" /></p>
<p>&emsp;&emsp;考虑隐藏层数固定为2,并取第二层隐藏单元数为第一层隐藏单元数的一半和10两个数中较大的值，学习轮数固定为10,第一层的隐藏单元数在（256，128，64 ,32,16）中选取，学习率在（0.0001,0.001,0.01,0.1,1)范围内选取，batch_size(批大小)在（512,256,128,64,32,16）范围内选取的超参数优化。以下展示部分实验数据(由于训练的随机性后面展示的结果得到的数据与此表格会有一些不相符）
| num_epochs | batch_size |  lr  | num_hiddens1 | num_hiddens2 | test_acc | train_acc | train_loss |
| ---------- | ---------- | :--: | ------------ | ------------ | -------- | --------- | ---------- |
| 10         | 256        | 0.1  | 512          | 256          | 0.8854   | 0.90515   | 0.24805    |
| 10         | 128        | 0.1  | 256          | 128          | 0.8822   | 0.9017166 | 0.25835    |
| 10         | 64         | 0.1  | 512          | 256          | 0.8811   | 0.90435   | 0.248654   |
| 10         | 32         | 0.1  | 512          | 256          | 0.8837   | 0.906683  | 0.2463282  |
| 10         | 16         | 0.1  | 512          | 256          | 0.8789   | 0.90626   | 0.24752787 |</p>
<p>&emsp;&emsp;展示最优结果训练过程和数据</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.2.1</span>
<span class="k">def</span> <span class="nf">initweight4_2_4</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span><span class="p">):</span>
    <span class="n">num_hiddens2</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">num_hiddens</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="n">num_hiddens</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">10</span> <span class="k">else</span> <span class="mi">10</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">W3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">,</span><span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span><span class="n">params</span>
<span class="n">num_inputs</span><span class="p">,</span><span class="n">num_outputs</span><span class="p">,</span><span class="n">num_hiddens</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">512</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span><span class="mi">256</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">W1</span><span class="p">,</span><span class="n">b1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span><span class="n">b2</span><span class="p">,</span><span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">initweight4_2_4</span><span class="p">(</span><span class="n">num_inputs</span><span class="o">=</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">net</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">))</span>
    <span class="n">H</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X</span><span class="nd">@W1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span><span class="c1"># 这里“@”代表矩阵乘法</span>
    <span class="n">X2</span><span class="o">=</span><span class="n">H</span><span class="nd">@W2</span> <span class="o">+</span> <span class="n">b2</span>
    <span class="n">H2</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">X2</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">H2</span><span class="nd">@W3</span> <span class="o">+</span> <span class="n">b3</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;epoch &#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.91</span><span class="p">],</span>
                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span>   <span class="n">updater</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>

    <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
<span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
<span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
<span class="k">assert</span> <span class="n">test_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_acc</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;epochs=</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">,num_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">,num_hiddens2=</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">num_hiddens</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">num_hiddens</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">10</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="mi">10</span><span class="si">}</span><span class="s1">,lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">,batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">,train_loss=</span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s1">, train_acc=</span><span class="si">{</span><span class="n">train_acc</span><span class="si">}</span><span class="s1">,test_acc=</span><span class="si">{</span><span class="n">test_acc</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epochs=10,num_hiddens=512,lr=0.1,batch_size=256,train_loss=0.38585775864919025, train_acc=0.8599333333333333,test_acc=0.838
</code></pre></div>
<p><img alt="svg" src="../output_57_1.svg" /></p>
<h3 id="425">练习4.2.5<a class="headerlink" href="#425" title="Permanent link">⚓︎</a></h3>
<p>描述为什么涉及多个超参数更具挑战性。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;超参数无法通过常规的优化手段确定，每次调整超参数要依据训练结果导致调整一次需要的成本很大，而过多的超参数将导致更多的参数组合，使得通过训练来确定好最优的超参数很困难。</p>
<h3 id="426">练习4.2.6<a class="headerlink" href="#426" title="Permanent link">⚓︎</a></h3>
<p>如果想要构建多个超参数的搜索方法，请想出一个聪明的策略。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;超参数无法通过常规的优化手段确定，每次调整超参数要依据训练结果导致调整一次需要的成本很大，而过多的超参数将导致更多的参数组合，使得通过训练来确定好最优的超参数很困难。根据过往的经验（文献或以前的实践）选定好一组超参数，从调整后计算成本最小的参数入手确定好它的值以后，再去确定计算成本比它大一点的参数，一步确定一个超参数，最后得到所有超参数的值，然后重复之前步骤，直到结果满意为止。</p>
<h2 id="43">4.3 多层感知机的简洁实现<a class="headerlink" href="#43" title="Permanent link">⚓︎</a></h2>
<h3 id="431">练习4.3.1<a class="headerlink" href="#431" title="Permanent link">⚓︎</a></h3>
<p>尝试添加不同数量的隐藏层（也可以修改学习率），怎么样设置效果最好？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;考虑隐藏层数取512,256,128,64,32,16，以及0.0001,0.001,0.01,0.1,1,10取值范围的学习率，发现隐藏层数取256学习率取0.1效果最好。</p>
<p>&emsp;&emsp;以下使用torch编程进行实验：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="k">def</span> <span class="nf">init_weights4_3_1</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mytrain4_3_1</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">num_hiddens</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span><span class="n">ac</span><span class="o">=</span><span class="s1">&#39;ReLU&#39;</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">assertshow</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1">#print(ac)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ac</span><span class="o">==</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
    <span class="k">elif</span> <span class="n">ac</span><span class="o">==</span><span class="s2">&quot;Tanh&quot;</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Tanh&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;ReLU&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
    <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>             
    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights4_3_1</span><span class="p">);</span>
    <span class="n">batch_size</span><span class="p">,</span>  <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">10</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;epoch </span><span class="si">{</span><span class="n">ac</span><span class="si">}</span><span class="s1"> lr =</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1"> num_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span>  <span class="n">trainer</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
    <span class="k">if</span> <span class="n">assertshow</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
        <span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
        <span class="k">assert</span> <span class="n">test_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_acc</span>
    <span class="k">return</span> <span class="n">train_loss</span><span class="p">,</span><span class="n">train_acc</span><span class="p">,</span><span class="n">test_acc</span>
<span class="n">result</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">num_hiddens</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span><span class="mi">256</span><span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">16</span><span class="p">]:</span>
    <span class="n">animator2</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;lr num_hiddens=</span><span class="si">{</span><span class="n">num_hiddens</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="n">xscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">train_loss</span><span class="p">,</span><span class="n">train_acc</span><span class="p">,</span><span class="n">test_acc</span><span class="o">=</span><span class="n">mytrain4_3_1</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span><span class="n">num_hiddens</span><span class="o">=</span><span class="n">num_hiddens</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">assertshow</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">animator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="n">train_acc</span><span class="p">,</span><span class="n">test_acc</span><span class="p">))</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">,</span><span class="n">train_acc</span><span class="p">,</span><span class="n">train_loss</span><span class="p">])</span>
<span class="n">resultmax</span><span class="o">=</span><span class="nb">sorted</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39; max batch_size:</span><span class="si">{</span><span class="mi">256</span><span class="si">}</span><span class="s1">,num_epochs:</span><span class="si">{</span><span class="mi">10</span><span class="si">}</span><span class="s1">,num_hiddens:</span><span class="si">{</span><span class="n">resultmax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">,lr:</span><span class="si">{</span><span class="n">resultmax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s1">,test_acc:</span><span class="si">{</span><span class="n">resultmax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s1">,train_acc:</span><span class="si">{</span><span class="n">resultmax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s1">,train_loss:</span><span class="si">{</span><span class="n">resultmax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code> max batch_size:256,num_epochs:10,num_hiddens:512,lr:0.1,test_acc:0.8533,train_acc:0.8669833333333333,train_loss:0.3779251153945923
</code></pre></div>
<p><img alt="svg" src="../output_69_1.svg" /></p>
<p><img alt="svg" src="../output_69_2.svg" /></p>
<p><img alt="svg" src="../output_69_3.svg" /></p>
<p><img alt="svg" src="../output_69_4.svg" /></p>
<p><img alt="svg" src="../output_69_5.svg" /></p>
<p><img alt="svg" src="../output_69_6.svg" /></p>
<h3 id="432">练习4.3.2<a class="headerlink" href="#432" title="Permanent link">⚓︎</a></h3>
<p>尝试不同的激活函数，哪个效果最好？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;ReLU效果最好，Tanh次之，Sigmoid最差训练损失最后超过了0.5。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.3.1</span>
<span class="k">def</span> <span class="nf">init_weights4_3_2</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_diffactivation_function</span><span class="p">(</span><span class="n">ac</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ac</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">ac</span><span class="o">==</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
    <span class="k">elif</span> <span class="n">ac</span><span class="o">==</span><span class="s2">&quot;Tanh&quot;</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Tanh&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;ReLU&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
    <span class="n">net</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>             
    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights4_3_2</span><span class="p">);</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">train_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">);</span>


<span class="n">train_diffactivation_function</span><span class="p">(</span><span class="n">ac</span><span class="o">=</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">train_diffactivation_function</span><span class="p">(</span><span class="n">ac</span><span class="o">=</span><span class="s2">&quot;Tanh&quot;</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">train_diffactivation_function</span><span class="p">(</span><span class="n">ac</span><span class="o">=</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sigmoid train_loss:&#39;</span><span class="p">,</span><span class="n">e</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>train_loss: 0.5010108480453491
</code></pre></div>
<p><img alt="svg" src="../output_73_1.svg" /></p>
<p><img alt="svg" src="../output_73_2.svg" /></p>
<p><img alt="svg" src="../output_73_3.svg" /></p>
<h3 id="433">练习4.3.3<a class="headerlink" href="#433" title="Permanent link">⚓︎</a></h3>
<p>尝试不同的方案来初始化权重，什么方法效果最好？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;尝试了正态分布初始化权重，单位矩阵初始化权重，均匀分布初始化权重，在这个问题上单位矩阵初始权重的结果表现更好。</p>
<p>&emsp;&emsp;以下使用torch编程进行实验：</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.3.1</span>
<span class="k">def</span> <span class="nf">normal_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;normal&quot;</span><span class="p">,</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">eye_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">eye_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;eye&quot;</span><span class="p">,</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">uniform_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">a</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">b</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_diffweight</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>             
    <span class="k">if</span> <span class="n">w</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">normal_weights</span><span class="p">);</span>
    <span class="k">elif</span> <span class="n">w</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">eye_weights</span><span class="p">);</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">uniform_weights</span><span class="p">);</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">10</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">train_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>


<span class="n">train_diffweight</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">train_diffweight</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_diffweight</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<p><img alt="svg" src="../output_78_0.svg" /></p>
<p><img alt="svg" src="../output_78_1.svg" /></p>
<p><img alt="svg" src="../output_78_2.svg" /></p>
<h2 id="44">4.4 模型选择、欠拟合和过拟合<a class="headerlink" href="#44" title="Permanent link">⚓︎</a></h2>
<h3 id="441">练习4.4.1<a class="headerlink" href="#441" title="Permanent link">⚓︎</a></h3>
<p>这个多项式回归问题可以准确地解出吗？提示：使用线性代数。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;<span class="arithmatex">\(<span class="arithmatex">\(L(w)=\frac{1}{2} \sum_{i=1}^N\left(\sum_{j=0}^M w_j x_i^j-y_i\right)^2\)</span>\)</span>  </p>
<div class="arithmatex">\[取 \frac{\partial L(w)}{\partial w_k}=0\Rightarrow\frac{1}{2} \sum_{i=1}^N 2\left(\sum_{j=0}^M w_j x_i^j-y_i\right) \times x_i^k=0 \Rightarrow \sum_{i=1}^N \sum_{j=0}^M w_j x_i^{j+k}=\sum_{i=1}^N x_i^k y_i(k=0,1,2, \cdots, M)\Rightarrow X W=Y\]</div>
<div class="arithmatex">\[其中X=\left[\begin{array}{ccccc}
N &amp; \sum_{i=1}^N x_i &amp; \sum_{i=1}^N x_i^2 &amp; \cdots &amp; \sum_{i=1}^N x_i^M \\
\sum_{i=1}^M x_i &amp; \sum_{i=1}^M x_i^2 &amp; \sum_{i=1}^M x_i^3 &amp; \cdots &amp; \sum_{i=1}^M x_i^{N+1} \\
\sum_{i=1}^M x_i^2 &amp; \sum_{i=1}^M x_i^3 &amp; \sum_{i=1}^M x_i^4 &amp; \cdots &amp; \sum_{i=1}^M x_i^{N+2} \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\sum_{i=1}^M x_i^N &amp; \sum_{i=1}^M x_i^{N+1} &amp; \sum_{i=1}^M x_i^{N+2} &amp; \cdots &amp; \sum_{i=1}^M x_i^{2 N}
\end{array}\right], \quad W=\left[\begin{array}{c}
w_0 \\
w_1 \\
w_2 \\
\vdots \\
w_M
\end{array}\right], \quad Y=\left[\begin{array}{c}
\sum_{i=1}^N y_i \\
\sum_{i=1}^N\left(x_i^2 y_i\right) \\
\vdots \\
\sum_{i=1}^N\left(x_i^N y_i\right)
\end{array}\right]
\]</div>
<div class="arithmatex">\[ W=X^{-1} Y\]</div>
<h3 id="442">练习4.4.2<a class="headerlink" href="#442" title="Permanent link">⚓︎</a></h3>
<p>考虑多项式的模型选择。
1. 绘制训练损失与模型复杂度（多项式的阶数）的关系图。观察到了什么？需要多少阶的多项式才能将训练损失减少到0?
2. 在这种情况下绘制测试的损失图。
3. 生成同样的图，作为数据量的函数。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;
1.在多项式阶数没有达到4之前阶数增加使得训练损失下降 当阶数超过4时训练损失几乎不变稳定在0.01这个数量级</p>
<p>&emsp;&emsp;
2. 绘制测试的损失图。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span>  <span class="c1"># 训练和测试数据集大小</span>

<span class="k">def</span> <span class="nf">train4_4_2</span><span class="p">(</span><span class="n">orderlist</span><span class="p">,</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">max_degree</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># 多项式的最大阶数</span>
    <span class="n">true_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_degree</span><span class="p">)</span>  <span class="c1"># 分配大量的空间</span>
    <span class="n">true_w</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">])</span>

    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
    <span class="n">poly_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_degree</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_degree</span><span class="p">):</span>
        <span class="n">poly_features</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># gamma(n)=(n-1)!</span>
    <span class="c1"># labels的维度:(n_train+n_test,)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">poly_features</span><span class="p">,</span> <span class="n">true_w</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">true_w</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">poly_features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">true_w</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">poly_features</span><span class="p">,</span> <span class="n">labels</span><span class="p">]]</span>
    <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;order&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;log(loss)&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span>
                                <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">orderlist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span>
                                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">])</span>
        <span class="c1">#animator2 = d2l.Animator(xlabel=&#39;order&#39;, ylabel=&#39;loss&#39;,</span>
                                <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">orderlist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">],</span>
                                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">])</span>
    <span class="n">train_losslist</span><span class="p">,</span><span class="n">test_losslist</span><span class="o">=</span><span class="p">[],[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">orderlist</span><span class="p">:</span>
        <span class="n">train_features</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_labels</span><span class="o">=</span><span class="n">poly_features</span><span class="p">[:</span><span class="n">n_train</span><span class="p">,</span> <span class="p">:</span><span class="n">i</span><span class="p">],</span><span class="n">poly_features</span><span class="p">[</span><span class="n">n_test</span><span class="p">:,</span> <span class="p">:</span><span class="n">i</span><span class="p">],</span><span class="n">labels</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">n_test</span><span class="p">:]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># 不设置偏置，因为我们已经在多项式中实现了它</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                               <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
        <span class="n">train_loss</span><span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="n">test_loss</span><span class="o">=</span><span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="n">train_losslist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
        <span class="n">test_losslist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="n">test_loss</span><span class="p">))</span>
            <span class="c1">#animator2.add(i, (train_loss,test_loss))</span>
    <span class="k">return</span> <span class="n">train_losslist</span><span class="p">,</span><span class="n">test_losslist</span>
    <span class="c1">#print(&#39;weight:&#39;, net[0].weight.data.numpy())</span>
    <span class="c1">#return d2l.evaluate_loss(net, train_iter, loss),d2l.evaluate_loss(net, test_iter, loss)</span>
<span class="n">train4_4_2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">21</span><span class="p">),</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span><span class="mi">400</span><span class="p">);</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_90_0.svg" />
​    </p>
<p><img alt="svg" src="../output_90_1.svg" /></p>
<p>&emsp;&emsp;
3. 生成同样的图，作为数据量的函数。</p>
<div class="highlight"><pre><span></span><code><span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;datasize&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;log(trainloss)&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span>
                                <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">1100</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span>
                                <span class="n">legend</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;order </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">5</span><span class="p">))))</span>
<span class="n">animator2</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;datasize&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;log(testloss)&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span>
                                <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">1100</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span>
                                <span class="n">legend</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot;order </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">5</span><span class="p">))))</span>
<span class="k">for</span> <span class="n">datasize</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1100</span><span class="p">,</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">train_losslist</span><span class="p">,</span><span class="n">test_losslist</span><span class="o">=</span><span class="n">train4_4_2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span><span class="n">datasize</span><span class="p">,</span> <span class="n">datasize</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">datasize</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_losslist</span><span class="p">))</span>
    <span class="n">animator2</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">datasize</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">test_losslist</span><span class="p">))</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_92_0.svg" />
​    </p>
<p><img alt="svg" src="../output_92_1.svg" /></p>
<h3 id="443">练习4.4.3<a class="headerlink" href="#443" title="Permanent link">⚓︎</a></h3>
<p>如果不对多项式特征<span class="arithmatex">\(x^i\)</span>进行标准化(<span class="arithmatex">\(1/i!\)</span>)，会发生什么事情？能用其他方法解决这个问题吗？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;避免出现较大的梯度值或者损失值。除了这个办法我们也可以让每个特征减去该特征数据的平均值并除于标准差。</p>
<h3 id="444">练习4.4.4<a class="headerlink" href="#444" title="Permanent link">⚓︎</a></h3>
<p>泛化误差可能为零吗？</p>
<p><strong>解答：</strong>  </p>
<p>&emsp;&emsp;在训练数据足够多的时候泛化误差接近经验误差，实验对于确定可解，且数据没有噪声的问题泛化误差可以为零。</p>
<h2 id="45">4.5 权重衰减<a class="headerlink" href="#45" title="Permanent link">⚓︎</a></h2>
<h3 id="451">练习4.5.1<a class="headerlink" href="#451" title="Permanent link">⚓︎</a></h3>
<p>在本节的估计问题中使用<span class="arithmatex">\(\lambda\)</span>的值进行实验。绘制训练和测试精度关于<span class="arithmatex">\(\lambda\)</span>的函数图。可以观察到什么？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;随着<span class="arithmatex">\(\lambda\)</span>增加训练精度和测试进度逐渐靠近，但最终没有靠到一起。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">5</span>
<span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="n">n_test</span><span class="p">)</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_wd</span><span class="p">(</span><span class="n">wdlist</span><span class="p">,</span><span class="n">net</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">train_data</span><span class="p">,</span><span class="n">test_iter</span><span class="p">,</span><span class="n">layer</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.003</span><span class="p">):</span>

    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;$\lambda$&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span>
                            <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="n">wdlist</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">wdlist</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">()</span>


    <span class="c1"># 偏置参数没有衰减</span>
    <span class="k">for</span> <span class="n">wd</span> <span class="ow">in</span> <span class="n">wdlist</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">layer</span><span class="p">:</span>
            <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span>
                <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="n">net</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">wd</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="n">net</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">}],</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
                <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
                <span class="n">l</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">wd</span><span class="p">,(</span><span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">),</span>
                              <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_loss</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">)))</span>
<span class="n">train_wd</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">100.</span><span class="p">,</span><span class="mi">150</span><span class="p">),</span><span class="n">net</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">train_iter</span><span class="p">,</span><span class="n">test_iter</span><span class="p">)</span>      
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_103_0.svg" />
​    </p>
<h3 id="452">练习4.5.2<a class="headerlink" href="#452" title="Permanent link">⚓︎</a></h3>
<p>使用验证集来找到最佳值<span class="arithmatex">\(\lambda\)</span>。它真的是最优值吗？这有关系吗？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;不一定是最优的解，但绝对不是过拟合的解。</p>
<h3 id="453">练习4.5.3<a class="headerlink" href="#453" title="Permanent link">⚓︎</a></h3>
<p>如果我们使用<span class="arithmatex">\(\sum_i |w_i|\)</span>作为我们选择的惩罚（<span class="arithmatex">\(L_1\)</span>正则化），那么更新方程会是什么样子？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;<span class="arithmatex">\(<span class="arithmatex">\(L(\mathbf{w}, b)+\lambda\|\mathbf{w}\|_1\)</span>\)</span></p>
<div class="arithmatex">\[\mathbf{w} \leftarrow \mathbf{w}-\eta \lambda sign(\mathbf{w})-\frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)}\left(\mathbf{w}^{\top} \mathbf{x}^{(i)}+b-y^{(i)}\right)\]</div>
<h3 id="454">练习4.5.4<a class="headerlink" href="#454" title="Permanent link">⚓︎</a></h3>
<p>我们知道<span class="arithmatex">\(\|\mathbf{w}\|^2 = \mathbf{w}^\top \mathbf{w}\)</span>。能找到类似的矩阵方程吗？（见2.3.10节中的佛罗贝尼乌斯范数）</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;<span class="arithmatex">\(<span class="arithmatex">\(\|\mathbf{w}\|_2= \left[\mathbf{w}^\top \mathbf{w}\right]^{1 / 2}\)</span>\)</span></p>
<h3 id="455">练习4.5.5<a class="headerlink" href="#455" title="Permanent link">⚓︎</a></h3>
<p>回顾训练误差和泛化误差之间的关系。除了权重衰减、增加训练数据、使用适当复杂度的模型之外，还能想出其他什么方法来处理过拟合？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;可以在验证误差下降到最低点的时候停止训练，防止过拟合。</p>
<h3 id="456">练习4.5.6<a class="headerlink" href="#456" title="Permanent link">⚓︎</a></h3>
<p>在贝叶斯统计中，我们使用先验和似然的乘积，通过公式<span class="arithmatex">\(P(w \mid x) \propto P(x \mid w) P(w)\)</span>得到后验。如何得到带正则化的<span class="arithmatex">\(P(w)\)</span>？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;如果考虑最大后验估计（MAP）$$ w=\underset{w}{\arg \max } P(w \mid x)=\underset{w}{\arg \max }(P(x \mid w) P(w))=\underset{w}{\arg \max }log(P(x \mid w) P(w))=\underset{w}{\arg \max }log(P(x \mid w) +log(P(w))$$
如果考虑P(w)为正态分布 </p>
<p>$$
\begin{gathered}
w_i \sim N\left(0, \sigma^2\right) \
\log P(w)=\log \prod_i \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{\left(w_i-0\right)^2}{2 \sigma^2}} \
=-\frac{1}{2 \sigma^2} \sum_i w_i^2+C
\end{gathered}
$$
将得到<span class="arithmatex">\(L_2\)</span>正则化的结果,如果考虑P(w)为拉普拉斯分布</p>
<p>$$
\begin{aligned}
w_i &amp; \sim \operatorname{Laplace}(0, b) \
\log P(w) &amp; =\log \prod_i \frac{1}{2 b} e^{-\frac{\left|w_i-0\right|}{b}} \
&amp; =-\frac{1}{b} \sum_i\left|w_i\right|+C
\end{aligned}
$$
将得到<span class="arithmatex">\(L_1\)</span>正则化的结果</p>
<h2 id="46">4.6 暂退法<a class="headerlink" href="#46" title="Permanent link">⚓︎</a></h2>
<h3 id="461">练习4.6.1<a class="headerlink" href="#461" title="Permanent link">⚓︎</a></h3>
<p>如果更改第一层和第二层的暂退法概率，会发生什么情况？具体地说，如果交换这两个层，会发生什么情况？设计一个实验来回答这些问题，定量描述该结果，并总结定性的结论。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;交换两层的暂退法概率会会导致结果变差。提高暂退法概率会也会使得loss更大训练预测的准确度下降，同时调整第一层暂退法概率带来的影响比第二层的大。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1">#修改Animator定义 用来画多行多列的图</span>
<span class="k">class</span> <span class="nc">myAnimator</span><span class="p">:</span>  
<span class="w">    </span><span class="sd">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">ylim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xscale</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                 <span class="n">fmts</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;m--&#39;</span><span class="p">,</span> <span class="s1">&#39;g-.&#39;</span><span class="p">,</span> <span class="s1">&#39;r:&#39;</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">),</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
        <span class="c1"># 增量地绘制多条线</span>
        <span class="k">if</span> <span class="n">legend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">legend</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">use_svg_display</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nrows</span> <span class="o">*</span> <span class="n">ncols</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">,</span> <span class="p">]</span>
        <span class="c1"># 使用lambda函数捕获参数</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config_axes</span> <span class="o">=</span><span class="k">lambda</span> <span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">set_axes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">],</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="p">,</span> <span class="n">xscale</span><span class="p">,</span> <span class="n">yscale</span><span class="p">,</span> <span class="n">legend</span><span class="p">)</span> <span class="k">if</span> <span class="n">axesnx</span><span class="o">==</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">axesny</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="n">d2l</span><span class="o">.</span><span class="n">set_axes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">],</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="p">,</span> <span class="n">xscale</span><span class="p">,</span> <span class="n">yscale</span><span class="p">,[])</span>

        <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span><span class="n">wspace</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="n">hspace</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmts</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fmts</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># 向图表中添加多个数据点</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="s2">&quot;__len__&quot;</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">y</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;__len__&quot;</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">b</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">]</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fmt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fmts</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fmt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config_axes</span><span class="p">(</span><span class="n">axesnx</span><span class="p">,</span><span class="n">axesny</span><span class="p">)</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">)</span>
        <span class="n">d2l</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">Net</span><span class="p">(</span><span class="n">dropout1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">dropout2</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="o">=</span><span class="mi">256</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout1</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span>

<span class="k">def</span> <span class="nf">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">],</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                  <span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span><span class="n">wd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
                  <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">ndropout1</span><span class="p">,</span><span class="n">ndropout2</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dropout1list</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">dropout2list</span><span class="p">)</span><span class="c1">#计算要画几行几列的图</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">ndropout1</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">ndropout2</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
                                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">],</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
                <span class="n">animator</span> <span class="o">=</span> <span class="n">myAnimator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">,</span>
                                <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">],</span><span class="n">nrows</span><span class="o">=</span><span class="n">ndropout1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">ndropout2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="n">wspace</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="n">hspace</span><span class="p">)</span>

    <span class="n">train_losslist</span><span class="p">,</span> <span class="n">train_acclist</span><span class="p">,</span><span class="n">test_acclist</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span> <span class="n">ndropout1</span><span class="p">,</span><span class="n">ndropout2</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ndropout1</span><span class="p">,</span><span class="n">ndropout2</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ndropout1</span><span class="p">,</span><span class="n">ndropout2</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndropout1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndropout2</span><span class="p">):</span>
            <span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="o">=</span><span class="n">dropout1list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">dropout2list</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">)</span>
            <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">);</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">wd</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
                <span class="n">trainer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">paramslist</span><span class="o">=</span><span class="p">[]</span>
                <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">net</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
                            <span class="n">paramslist</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="n">wd</span><span class="p">})</span>
                            <span class="n">paramslist</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;params&quot;</span><span class="p">:</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">})</span>
                <span class="n">trainer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">paramslist</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span><span class="c1">#设置权重衰减</span>

            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
                <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
                <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
                <span class="n">train_losslist</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">epoch</span><span class="p">],</span><span class="n">train_acclist</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">epoch</span><span class="p">],</span><span class="n">test_acclist</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">epoch</span><span class="p">]</span><span class="o">=</span><span class="n">train_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">train_metrics</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">test_acc</span>
                <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">ndropout1</span><span class="o">==</span><span class="mi">1</span><span class="o">&amp;</span><span class="n">ndropout2</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
                        <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">,</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,),</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;dropout1:</span><span class="si">{</span><span class="n">dropout1</span><span class="si">}</span><span class="s2">,dropout2:</span><span class="si">{</span><span class="n">dropout2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1">#animator.axes[i,j].set_title(f&quot;dropout1:{dropout1},dropout2:{dropout2}&quot;)    </span>
            <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
                <span class="n">animator</span><span class="o">.</span><span class="n">X</span><span class="p">,</span><span class="n">animator</span><span class="o">.</span><span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

            <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
            <span class="c1">#实验中不能保证loss较低所以不使用后面这段代码</span>
<span class="c1">#            assert train_loss &lt; 0.5, train_loss</span>
<span class="c1">#            assert train_acc &lt;= 1 and train_acc &gt; 0.7, train_acc</span>
<span class="c1">#            assert test_acc &lt;= 1 and test_acc &gt; 0.7, test_acc</span>
    <span class="k">return</span>  <span class="n">train_losslist</span><span class="p">,</span><span class="n">train_acclist</span><span class="p">,</span><span class="n">test_acclist</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">dropout1list</span><span class="p">,</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.7</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.7</span><span class="p">]</span>
<span class="n">train_losslist</span><span class="p">,</span><span class="n">train_acclist</span><span class="p">,</span><span class="n">test_acclist</span><span class="o">=</span><span class="n">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.7</span><span class="p">],</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.7</span><span class="p">])</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_127_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">train_losslist</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;train_loss&#39;</span><span class="p">,</span>
                     <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;dropout1:</span><span class="si">{</span><span class="n">dropout1</span><span class="si">}</span><span class="s1">,dropout2:</span><span class="si">{</span><span class="n">dropout2</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">dropout1</span> <span class="ow">in</span> <span class="n">dropout1list</span> <span class="k">for</span> <span class="n">dropout2</span> <span class="ow">in</span> <span class="n">dropout1list</span><span class="p">])</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">train_acclist</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;train_acc&#39;</span><span class="p">)</span>
                     <span class="c1">#legend=[f&#39;dropout1:{dropout1},dropout2:{dropout2}&#39; for dropout1 in dropout1list for dropout2 in dropout1list],figsize=(10, 8))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">test_acclist</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">)</span>
                     <span class="c1">#legend=[f&#39;dropout1:{dropout1},dropout2:{dropout2}&#39; for dropout1 in dropout1list for dropout2 in dropout1list],figsize=(10, 8))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_128_0.svg" />
​    </p>
<h3 id="462">练习4.6.2<a class="headerlink" href="#462" title="Permanent link">⚓︎</a></h3>
<p>增加训练轮数，并将使用暂退法和不使用暂退法时获得的结果进行比较。</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;没使用dropout会出现loss值突然上升的情况（这可能使因为学习率设置过高），使用dropout的结果这种情况则会消失。</p>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="o">=</span><span class="mi">50</span>
<span class="n">dropout1list</span><span class="p">,</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span> 
<span class="n">train_losslist</span><span class="p">,</span><span class="n">train_acclist</span><span class="p">,</span><span class="n">test_acclist</span><span class="o">=</span><span class="n">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="n">dropout1list</span><span class="p">,</span><span class="n">dropout2list</span><span class="o">=</span><span class="n">dropout2list</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_132_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">12.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span> 
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">train_losslist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:],</span><span class="n">train_losslist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,:])),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;train_loss&#39;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">train_acclist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:],</span><span class="n">train_acclist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,:])),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;train_acc&#39;</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">)),</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">test_acclist</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:],</span><span class="n">test_acclist</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,:])),</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">,</span>
                     <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dropout1:0,dropout2:0&#39;</span><span class="p">,</span><span class="s1">&#39;dropout1:0.2,dropout2:0.5&#39;</span><span class="p">])</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">hspace</span> <span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_133_0.svg" />
​    </p>
<h3 id="463">练习4.6.3<a class="headerlink" href="#463" title="Permanent link">⚓︎</a></h3>
<p>当使用或不使用暂退法时，每个隐藏层中激活值的方差是多少？绘制一个曲线图，以显示这两个模型的每个隐藏层中激活值的方差是如何随时间变化的。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp; 使用暂退法,每个中间活性值<span class="arithmatex">\(h\)</span>以<em>暂退概率</em><span class="arithmatex">\(p\)</span>由随机变量<span class="arithmatex">\(h'\)</span>替换,如下所示：</p>
<div class="arithmatex">\[
\begin{aligned}
h' =
\begin{cases}
    0 &amp; \text{ 概率为 } p \\
    \frac{h}{1-p} &amp; \text{ 其他情况}
\end{cases}
\end{aligned}
\]</div>
<p>&emsp;&emsp;其期望值保持不变，即<span class="arithmatex">\(E[h'] = h\)</span>。它的方差 <span class="arithmatex">\(D(h')=E\left((h'-E(h'))^2\right)=E\left(h'^2\right)-E^2\left(h'\right)=\displaystyle \frac{h^2}{\left(1-p\right)}-h\)</span></p>
<div class="highlight"><pre><span></span><code><span class="c1">#import见4.6.1</span>
<span class="k">def</span> <span class="nf">dropout_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">dropout</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="c1"># 在本情况中，所有元素都被丢弃</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># 在本情况中，所有元素都被保留</span>
    <span class="k">if</span> <span class="n">dropout</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">X</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">dropout</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">dropout</span><span class="p">)</span>
<span class="c1"># X= torch.arange(16, dtype = torch.float32).reshape((2, 8))</span>
<span class="n">dropout0</span><span class="p">,</span><span class="n">dropout0d5</span><span class="p">,</span><span class="n">var_dropout0d5</span><span class="p">,</span><span class="n">var_dropout0</span><span class="o">=</span><span class="n">dropout_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">0</span><span class="p">),</span><span class="n">dropout_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#torch.var(dropout_layer(torch.ones(1,dtype = torch.float32), 0.5))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">dropout0d5</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">dropout0d5</span><span class="p">,</span><span class="n">dropout_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">)])</span>
    <span class="n">dropout0</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">dropout0</span><span class="p">,</span><span class="n">dropout_layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="mi">0</span><span class="p">)])</span>

    <span class="n">var_dropout0d5</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">var_dropout0d5</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dropout0d5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>
    <span class="n">var_dropout0</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">var_dropout0</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dropout0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span>

<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1003</span><span class="p">)[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">50</span><span class="p">],</span> <span class="p">[</span><span class="n">var_dropout0</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">50</span><span class="p">],</span><span class="n">var_dropout0d5</span><span class="o">.</span><span class="n">detach</span><span class="p">()[</span><span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">50</span><span class="p">]],</span>
         <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;dropout=0&#39;</span><span class="p">,</span><span class="s1">&#39;dropout=0.5&#39;</span><span class="p">])</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">);</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;var&quot;</span><span class="p">);</span>

<span class="c1">#, figsize=(4.5, 2.5)</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_139_0.svg" />
​    </p>
<h3 id="464">练习4.6.4<a class="headerlink" href="#464" title="Permanent link">⚓︎</a></h3>
<p>为什么在测试时通常不使用暂退法？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;训练时使用暂退法是为了防止模型过拟合，提高网络泛化能力，而测试时我们希望可以用上所有的参数，减少参数反而会影响网络稳定性。</p>
<h3 id="465">练习4.6.5<a class="headerlink" href="#465" title="Permanent link">⚓︎</a></h3>
<p>以本节中的模型为例，比较使用暂退法和权重衰减的效果。如果同时使用暂退法和权重衰减，会发生什么情况？结果是累加的吗？收益是否减少（或者说更糟）？它们互相抵消了吗？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;同时使用暂退法和权重衰减结果好于只使用使用暂退法或者权重衰减。暂退法和权重衰减使用不同的方式防止模型过拟合，同时使用用累加的效果。下表是某次实验的结果 由于训练存在随机性所以结果可能会不同
| method | <span class="arithmatex">\(\lambda\)</span> |  dropout1  | dropout2 | train loss | train_acc | test acc  |
| ---------- | ---------- | :--: | ----------- | -------- | --------- | ----------- |
| dropout       | \        | 0.2  | 0.5          |0.3475  |0.8727  | 0.8491   |
| dropout and weight decay        | 0.0001        | 0.2  | 0.5        |0.3523  | 0.8707   | 0.8538   |
|decay    |0.0001         | \ | \        | 0.3224   |  0.8797     |  0.8008 |</p>
<div class="highlight"><pre><span></span><code><span class="c1">#只用暂退法</span>
<span class="n">train_loss1</span><span class="p">,</span><span class="n">train_acc1</span><span class="p">,</span><span class="n">test_acc1</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">show</span><span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">9</span> <span class="k">else</span> <span class="kc">True</span>
    <span class="n">train_losslist1</span><span class="p">,</span><span class="n">train_acclist1</span><span class="p">,</span><span class="n">test_acclist1</span><span class="o">=</span><span class="n">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">],</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">)</span>
    <span class="n">train_loss1</span><span class="o">+=</span><span class="n">train_losslist1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
    <span class="n">train_acc1</span><span class="o">+=</span><span class="n">train_acclist1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
    <span class="n">test_acc1</span><span class="o">+=</span><span class="n">test_acclist1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;only dorpout train loss </span><span class="si">{:.4f}</span><span class="s2"> train acc </span><span class="si">{:.4f}</span><span class="s2"> test acc </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_loss1</span><span class="p">,</span><span class="n">train_acc1</span><span class="p">,</span><span class="n">test_acc1</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>only dorpout train loss 0.3475 train acc 0.8727 test acc 0.8491
</code></pre></div>
<p><img alt="svg" src="../output_146_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="c1">#暂退法加梯度衰减</span>
<span class="n">train_loss2</span><span class="p">,</span><span class="n">train_acc2</span><span class="p">,</span><span class="n">test_acc2</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">show</span><span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">9</span> <span class="k">else</span> <span class="kc">True</span>
    <span class="n">train_losslist2</span><span class="p">,</span><span class="n">train_acclist2</span><span class="p">,</span><span class="n">test_acclist2</span><span class="o">=</span><span class="n">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">],</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">],</span><span class="n">wd</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="n">show</span><span class="p">)</span>
    <span class="n">train_loss2</span><span class="o">+=</span><span class="n">train_losslist2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
    <span class="n">train_acc2</span><span class="o">+=</span><span class="n">train_acclist2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
    <span class="n">test_acc2</span><span class="o">+=</span><span class="n">test_acclist2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mf">10.0</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dorpout and weight decay  train loss </span><span class="si">{:.4f}</span><span class="s2"> train acc </span><span class="si">{:.4f}</span><span class="s2"> test acc </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_loss2</span><span class="p">,</span><span class="n">train_acc2</span><span class="p">,</span><span class="n">test_acc2</span><span class="p">)</span> <span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>dorpout and weight decay  train loss 0.3523 train acc 0.8707 test acc 0.8538
</code></pre></div>
<p><img alt="svg" src="../output_147_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="c1">#只有梯度衰减</span>
<span class="n">train_losslist3</span><span class="p">,</span><span class="n">train_acclist3</span><span class="p">,</span><span class="n">test_acclist3</span><span class="o">=</span><span class="n">changedropout</span><span class="p">(</span><span class="n">dropout1list</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">dropout2list</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">wd</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;weight decay  train loss </span><span class="si">{:.4f}</span><span class="s2"> train acc </span><span class="si">{:.4f}</span><span class="s2"> test acc </span><span class="si">{:.4f}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_losslist3</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">train_acclist3</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">test_acclist3</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>weight decay  train loss 0.3224 train acc 0.8797 test acc 0.8008
</code></pre></div>
<p><img alt="svg" src="../output_148_1.svg" /></p>
<h3 id="467">练习4.6.7<a class="headerlink" href="#467" title="Permanent link">⚓︎</a></h3>
<p>如果我们将暂退法应用到权重矩阵的各个权重，而不是激活值，会发生什么？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;把dropout放在激活层之前，可能导致dropout失去作用，因为很多激活函数对于0的值不为零，所以即使有一些神经元被取为0值，我们仍然有梯度更新他们的参数。</p>
<p>&emsp;&emsp;以下展示dropout前置结果</p>
<div class="highlight"><pre><span></span><code><span class="n">dropout1</span><span class="o">=</span><span class="mf">0.2</span><span class="p">;</span><span class="n">dropout2</span><span class="o">=</span><span class="mf">0.5</span><span class="p">;</span><span class="n">num_inputs</span><span class="o">=</span><span class="mi">784</span><span class="p">;</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">10</span><span class="p">;</span> <span class="n">num_hiddens1</span><span class="o">=</span><span class="mi">256</span><span class="p">;</span> <span class="n">num_hiddens2</span><span class="o">=</span><span class="mi">256</span><span class="p">;</span><span class="n">num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">;</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout1</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout2</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>


<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span><span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>


<span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">);</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">)</span>
    <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>


<span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_153_0.svg" />
​    </p>
<h3 id="468">练习4.6.8<a class="headerlink" href="#468" title="Permanent link">⚓︎</a></h3>
<p>开发另一种用于在每一层注入随机噪声的技术，该技术不同于标准的暂退法技术。尝试开发一种在Fashion-MNIST数据集（对于固定架构）上性能优于暂退法的方法。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;对每一个relu输出加上一个高斯噪声</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">noise_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">+</span><span class="n">rate</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> 
<span class="k">class</span> <span class="nc">Net4_6_8</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">,</span>
                 <span class="n">is_training</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net4_6_8</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">is_training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens2</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">H1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span><span class="p">))))</span>
        <span class="c1"># 只有在训练模型时才使用dropout</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>

            <span class="n">H1</span> <span class="o">=</span> <span class="n">noise_layer</span><span class="p">(</span><span class="n">H1</span><span class="p">)</span>
        <span class="n">H2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin2</span><span class="p">(</span><span class="n">H1</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>

            <span class="n">H2</span> <span class="o">=</span> <span class="n">noise_layer</span><span class="p">(</span><span class="n">H2</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin3</span><span class="p">(</span><span class="n">H2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>


<span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span> <span class="o">=</span> <span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net4_6_8</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_hiddens1</span><span class="p">,</span> <span class="n">num_hiddens2</span><span class="p">)</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">256</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_fashion_mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch3</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_157_0.svg" />
​    </p>
<h2 id="47">4.7 前向传播、反向传播和计算图<a class="headerlink" href="#47" title="Permanent link">⚓︎</a></h2>
<h3 id="471">练习4.7.1<a class="headerlink" href="#471" title="Permanent link">⚓︎</a></h3>
<p>假设一些标量函数<span class="arithmatex">\(\mathbf{X}\)</span>的输入<span class="arithmatex">\(\mathbf{X}\)</span>是<span class="arithmatex">\(n \times m\)</span>矩阵。<span class="arithmatex">\(f\)</span>相对于<span class="arithmatex">\(\mathbf{X}\)</span>的梯度维数是多少？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;<span class="arithmatex">\(n \times m\)</span> 维</p>
<h3 id="472">练习4.7.2<a class="headerlink" href="#472" title="Permanent link">⚓︎</a></h3>
<p>向本节中描述的模型的隐藏层添加偏置项（不需要在正则化项中包含偏置项）。</p>
<ol>
<li>画出相应的计算图。</li>
<li>推导正向和反向传播方程。</li>
</ol>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;
1. <img alt="计算图" src="../../images/ch04-7-2-Computational-Graph-of-Forward-Propagation.png" /></p>
<p>&emsp;&emsp;
2. 正向传播方程 只要我们沿着计算图逐项计算就可以得到</p>
<div class="arithmatex">\[
\mathbf{z^\prime}=\mathbf{W}^{(1)} \mathbf{x},\mathbf{z}=\mathbf{b}^{(1)}+ \mathbf{z^\prime},\mathbf{h}=\mathbf{\phi} (\mathbf{z}),\mathbf{o^\prime}=\mathbf{W}^{(2)} \mathbf{h},\mathbf{o}=\mathbf{b}^{(2)}+ \mathbf{o^\prime},L=l(\mathbf{o}, y),s=\frac{\lambda}{2}\left(\left\|\mathbf{W}^{(1)}\right\|_F^2+\left\|\mathbf{W}^{(2)}\right\|_F^2\right),J=L+s
\]</div>
<p>&emsp;&emsp;&emsp;&emsp;反向传播方程</p>
<p>&emsp;&emsp;&emsp;&emsp;反向传播的目的是计算梯度<span class="arithmatex">\(\displaystyle\frac{\partial J}{\partial \mathbf{W}^{(1)}} \text { , }\displaystyle \frac{\partial J}{\partial \mathbf{W}^{(2)}}\text{,} \displaystyle\frac{\partial J}{\partial \mathbf{b}^{(1)}} \text { , }\displaystyle \frac{\partial J}{\partial \mathbf{b}^{(2)}}\)</span></p>
<p>&emsp;&emsp;&emsp;&emsp;前两个式子和本章文中相同
$$
\frac{\partial J}{\partial \mathbf{W}^{(1)}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{z}}, \frac{\partial \mathbf{z}}{\partial \mathbf{W}^{(1)}}\right) + \text{prod}\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial \mathbf{W}^{(1)}}\right)
= \frac{\partial J}{\partial \mathbf{z}} \mathbf{x}^\top + \lambda \mathbf{W}^{(1)}.
$$</p>
<p>$$
\frac{\partial J}{\partial \mathbf{W}^{(2)}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{o}}, \frac{\partial \mathbf{o}}{\partial \mathbf{W}^{(2)}}\right) + \text{prod}\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial \mathbf{W}^{(2)}}\right)
= \frac{\partial J}{\partial \mathbf{o}} \mathbf{h}^\top + \lambda \mathbf{W}^{(2)}.
$$
&emsp;&emsp;&emsp;&emsp;可以参考原文</p>
<blockquote>
<p>第一步是计算目标函数<span class="arithmatex">\(J=L+s\)</span>相对于损失项<span class="arithmatex">\(L\)</span>和正则项<span class="arithmatex">\(s\)</span>的梯度。</p>
<div class="arithmatex">\[\frac{\partial J}{\partial L} = 1 \; \text{and} \; \frac{\partial J}{\partial s} = 1.\]</div>
<p>接下来，我们根据链式法则计算目标函数关于输出层变量<span class="arithmatex">\(\mathbf{o}\)</span>的梯度：</p>
<div class="arithmatex">\[
\frac{\partial J}{\partial \mathbf{o}}
= \text{prod}\left(\frac{\partial J}{\partial L}, \frac{\partial L}{\partial \mathbf{o}}\right)
= \frac{\partial L}{\partial \mathbf{o}}
\in \mathbb{R}^q.
\]</div>
<p>接下来，我们计算正则化项相对于两个参数的梯度：</p>
<div class="arithmatex">\[\frac{\partial s}{\partial \mathbf{W}^{(1)}} = \lambda \mathbf{W}^{(1)}
\; \text{and} \;
\frac{\partial s}{\partial \mathbf{W}^{(2)}} = \lambda \mathbf{W}^{(2)}.\]</div>
<p>现在我们可以计算最接近输出层的模型参数的梯度
<span class="arithmatex">\(\partial J/\partial \mathbf{W}^{(2)} \in \mathbb{R}^{q \times h}\)</span>。
使用链式法则得出：</p>
<div class="arithmatex">\[\frac{\partial J}{\partial \mathbf{W}^{(2)}}= \text{prod}\left(\frac{\partial J}{\partial \mathbf{o}}, \frac{\partial \mathbf{o}}{\partial \mathbf{W}^{(2)}}\right) + \text{prod}\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial \mathbf{W}^{(2)}}\right)= \frac{\partial J}{\partial \mathbf{o}} \mathbf{h}^\top + \lambda \mathbf{W}^{(2)}.\]</div>
<p>为了获得关于<span class="arithmatex">\(\mathbf{W}^{(1)}\)</span>的梯度，我们需要继续沿着输出层到隐藏层反向传播。
关于隐藏层输出的梯度<span class="arithmatex">\(\partial J/\partial \mathbf{h} \in \mathbb{R}^h\)</span>由下式给出：</p>
<div class="arithmatex">\[
\frac{\partial J}{\partial \mathbf{h}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{o}}, \frac{\partial \mathbf{o}}{\partial \mathbf{h}}\right)
= {\mathbf{W}^{(2)}}^\top \frac{\partial J}{\partial \mathbf{o}}.
\]</div>
<p>由于激活函数<span class="arithmatex">\(\phi\)</span>是按元素计算的，
计算中间变量<span class="arithmatex">\(\mathbf{z}\)</span>的梯度<span class="arithmatex">\(\partial J/\partial \mathbf{z} \in \mathbb{R}^h\)</span>
需要使用按元素乘法运算符，我们用<span class="arithmatex">\(\odot\)</span>表示：</p>
<div class="arithmatex">\[
\frac{\partial J}{\partial \mathbf{z}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{h}}, \frac{\partial \mathbf{h}}{\partial \mathbf{z}}\right)
= \frac{\partial J}{\partial \mathbf{h}} \odot \phi'\left(\mathbf{z}\right).
\]</div>
<p>最后，我们可以得到最接近输入层的模型参数的梯度
<span class="arithmatex">\(\partial J/\partial \mathbf{W}^{(1)} \in \mathbb{R}^{h \times d}\)</span>。
根据链式法则，我们得到：</p>
<div class="arithmatex">\[
\frac{\partial J}{\partial \mathbf{W}^{(1)}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{z}}, \frac{\partial \mathbf{z}}{\partial \mathbf{W}^{(1)}}\right) + \text{prod}\left(\frac{\partial J}{\partial s}, \frac{\partial s}{\partial \mathbf{W}^{(1)}}\right)
= \frac{\partial J}{\partial \mathbf{z}} \mathbf{x}^\top + \lambda \mathbf{W}^{(1)}.
\]</div>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;根据链式子法则，后面两个式子的结果为：
$$
\frac{\partial J}{\partial \mathbf{b}^{(1)}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{h}}, \frac{\partial \mathbf{h}}{\partial \mathbf{b}^{(2)}}\right) 
= \frac{\partial J}{\partial \mathbf{h}}.
$$</p>
<div class="arithmatex">\[
\frac{\partial J}{\partial \mathbf{b}^{(1)}}
= \text{prod}\left(\frac{\partial J}{\partial \mathbf{o}}, \frac{\partial \mathbf{o}}{\partial \mathbf{b}^{(2)}}\right) 
= \frac{\partial J}{\partial \mathbf{o}}.
\]</div>
<h3 id="473">练习4.7.3<a class="headerlink" href="#473" title="Permanent link">⚓︎</a></h3>
<p>计算本节所描述的模型，用于训练和预测的内存空间。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;训练需要存储的参数：<span class="arithmatex">\(x,z,h,o,y,W^{(1)},W^{(2)}, \displaystyle\frac{\partial J}{\partial \mathbf{W}^{(1)}} ，\displaystyle \frac{\partial J}{\partial \mathbf{W}^{(2)}}\)</span></p>
<p>&emsp;&emsp;假设输入数据为n维<span class="arithmatex">\(W^{(1)}\)</span>和<span class="arithmatex">\(\displaystyle\frac{\partial J}{\partial \mathbf{W}^{(1)}}\)</span>为<span class="arithmatex">\(𝑛×𝑚\)</span>维,则<span class="arithmatex">\(z\)</span>和<span class="arithmatex">\(h\)</span>为<span class="arithmatex">\(m\)</span>维。<span class="arithmatex">\(W^{(2)}\)</span>和<span class="arithmatex">\(\displaystyle\frac{\partial J}{\partial \mathbf{W}^{(2)}}\)</span>为<span class="arithmatex">\(m×k\)</span>维,则<span class="arithmatex">\(o\)</span>和有为<span class="arithmatex">\(k\)</span>维 。 网络参数为浮点小数，通常用float单精度表示，单精度float占32位/4个字节。那么占用总字节数为<span class="arithmatex">\((n+n×m×2+2×m+m×k×2+k×2)×4B\)</span></p>
<p>&emsp;&emsp;预测需要存储的参数：<span class="arithmatex">\(x,z,h,o,y,W^{(1)},W^{(2)}\)</span>可以估计出占用内存总字节数为<span class="arithmatex">\((n+n×m+2×m+m×k+k×2)×4B\)</span></p>
<h3 id="474">练习4.7.4<a class="headerlink" href="#474" title="Permanent link">⚓︎</a></h3>
<p>假设想计算二阶导数。计算图发生了什么？预计计算需要多长时间？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp; 需要在构造一个以一阶导数为正向传播的计算图，然后再反向传播求导。可能会花费相对与计算一阶导数时两倍的时间。</p>
<h3 id="475">练习4.7.5<a class="headerlink" href="#475" title="Permanent link">⚓︎</a></h3>
<p>假设计算图对当前拥有的GPU来说太大了。</p>
<ol>
<li>请试着把它划分到多个GPU上。</li>
<li>与小批量训练相比，有哪些优点和缺点？</li>
</ol>
<p><strong>解答：</strong></p>
<ol>
<li>我们可以把网络按三种方式把它划分到GPU上,网络并行、分层并行、数据并行。网络并行把每层网络的计算划分到不同的GPU。分层并行把每层内的计算划分到不同的GPU,比如把全连接层输出单元拆分到不同gpu上计算。数据并行把数据拆分分别在不同gpu上计算同样的网络然后汇总各个gpu上更新参数。</li>
<li>优点是多个GPU集群可以训练较大的模型（前两种划分方法可以）以及更快的训练模型（第三种划分），但是缺点是可能会因为节点间通信的限制导致速度不够快。</li>
</ol>
<h2 id="48">4.8 数值稳定性和模型初始化<a class="headerlink" href="#48" title="Permanent link">⚓︎</a></h2>
<h3 id="481">练习4.8.1<a class="headerlink" href="#481" title="Permanent link">⚓︎</a></h3>
<p>除了多层感知机的排列对称性之外，还能设计出其他神经网络可能会表现出对称性且需要被打破的情况吗？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;卷积神经网络卷积层的多个输出通道具有对称性，需要在初始化时保证他们不是相同值。</p>
<h3 id="482">练习4.8.2<a class="headerlink" href="#482" title="Permanent link">⚓︎</a></h3>
<p>我们是否可以将线性回归或softmax回归中的所有权重参数初始化为相同的值？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;当所有权重参数具有相同的初始值时，模型在进行反向传播和参数更新时，每个权重都会以相同的方式更新。这种情况下，每个特征在模型中的作用是相同的，无法体现特征之间的差异和重要性。这可能导致模型的学习能力受限，难以捕捉到数据中的复杂关系。</p>
<p>相反，使用不同的初始值可以帮助模型在训练过程中探索不同的权重组合，以更好地适应数据。常用的初始化方法包括随机初始化（如从均匀分布或正态分布中随机采样）和Xavier初始化（根据输入和输出维度自适应地选择合适的初始范围）。</p>
<p>因此，为了有效地训练线性回归或softmax回归模型，通常建议对权重参数进行适当的初始化，以便在训练过程中提供足够的表达能力和灵活性。</p>
<h3 id="483">练习4.8.3<a class="headerlink" href="#483" title="Permanent link">⚓︎</a></h3>
<p>在相关资料中查找两个矩阵乘积特征值的解析界。这对确保梯度条件合适有什么启示？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;<span class="arithmatex">\(\boldsymbol{A}, \boldsymbol{B}\)</span> 为 <span class="arithmatex">\(n\)</span> 阶实对称不定矩阵 <span class="arithmatex">\(\boldsymbol{A B}=\boldsymbol{B A}\)</span>, 矩阵 <span class="arithmatex">\(\boldsymbol{A}\)</span> 的 <span class="arithmatex">\(n\)</span> 个特征值为 <span class="arithmatex">\(\lambda_1 \leqslant \lambda_2 \leqslant \cdots\)</span> <span class="arithmatex">\(\leqslant \lambda_n\)</span>, 矩阵 <span class="arithmatex">\(\boldsymbol{B}\)</span> 的 <span class="arithmatex">\(n\)</span> 个特征值为 <span class="arithmatex">\(\mu_1 \leqslant \mu_2 \leqslant \cdots \leqslant \mu_n\)</span> 则矩阵 <span class="arithmatex">\(\boldsymbol{A B}\)</span> 的特征值 <span class="arithmatex">\(\min \left\{\lambda_1 \mu_n, \lambda_n \mu_1\right\} \leqslant \lambda \leqslant\)</span> <span class="arithmatex">\(\max \left\{\lambda_1 \mu_1, \lambda_n \mu_n\right\}\)</span> 。当考虑梯度爆炸问题时我们应该爆炸计算梯度的矩阵最大特征值尽量小，当考虑梯度消失问题时计算梯度矩阵最小特征值尽量大。</p>
<h3 id="484">练习4.8.4<a class="headerlink" href="#484" title="Permanent link">⚓︎</a></h3>
<p>如果我们知道某些项是发散的，我们能在事后修正吗？可以参考关于按层自适应速率缩放的论文[190]。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;原问题应该是我们知道模型的某一层会发散，我们能事后修正吗？
 我们可以通过计算每层权重的范数和梯度范数的比值来衡量训练稳定性并以此为依据调节每一层的学习率，如下式所示：
$$ \lambda^l=\eta \times \frac{\left|w^l\right|}{\left|\nabla L\left(w^l\right)\right|}$$
<span class="arithmatex">\(l\)</span>表示第几层网络 <span class="arithmatex">\(L\)</span>表示损失函数 <span class="arithmatex">\(\eta\)</span>表示你对用权重的范数和梯度范数的比值来衡量学习率的信任程度。</p>
<h2 id="49">4.9 环境和分布偏移<a class="headerlink" href="#49" title="Permanent link">⚓︎</a></h2>
<h3 id="491">练习4.9.1<a class="headerlink" href="#491" title="Permanent link">⚓︎</a></h3>
<p>当我们改变搜索引擎的行为时会发生什么？用户可能会做什么？广告商呢？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;当改变搜索引擎的行为时，可能会发生以下情况：</p>
<ol>
<li>
<p>用户的反应：用户可能会对搜索引擎行为的改变做出不同的反应。一些用户可能会适应并接受这些变化，继续使用搜索引擎进行他们的查询。其他用户可能会感到不满意或困惑，因为他们习惯了特定的搜索结果和功能。这可能导致他们寻找替代的搜索引擎或采取其他方式来获取所需信息。</p>
</li>
<li>
<p>用户行为的变化：如果搜索引擎的行为发生显著变化，用户可能会调整他们的搜索策略。他们可能会更改搜索关键词的选择、尝试不同的搜索策略或使用高级搜索选项来获得更精确的结果。一些用户可能会更多地依赖其他信息来源，如社交媒体、专业网站或应用程序。</p>
</li>
<li>
<p>广告商的反应：搜索引擎行为的改变可能会对广告商产生影响。广告商通常依赖搜索引擎为他们的广告投放提供曝光和流量。如果搜索引擎的行为发生变化，广告商可能需要重新评估他们的广告策略和投放方式，以确保他们的广告仍然能够有效地触达目标受众。</p>
</li>
<li>
<p>广告排名和竞争：搜索引擎行为的改变可能会对广告排名和竞争产生影响。如果搜索引擎调整了广告排名算法或显示广告的方式，广告商可能需要重新评估他们的广告优化策略和预算分配，以适应这些变化。竞争激烈的行业可能会看到广告竞价的变化和竞争格局的调整。</p>
</li>
</ol>
<p>需要注意的是，具体情况会根据搜索引擎的改变方式、用户群体和广告市场的特点而有所不同。搜索引擎的行为改变可能是出于改善搜索结果质量、提供更相关的信息或应对不断变化的用户需求等目的。</p>
<h3 id="492">练习4.9.2<a class="headerlink" href="#492" title="Permanent link">⚓︎</a></h3>
<p>实现一个协变量偏移检测器。提示：构建一个分类器。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;为了构造协变量偏移的场景我们使用<a href="https://www.kaggle.com/competitions/dogs-vs-cats/data?select=train.zip">kaggle的dogvscat训练数据集</a>选取一部分动漫化处理(处理方法见这个<a href="https://github.com/bryandlee/animegan2-pytorch">github地址</a>),然后构成一个cartoonvsnormal数据集（存放在../data/ch04-4-9-2and4-9-3/cartoonvsnormal），用已经预训练好的resnet50模型加一个全连接层(这部分会在后面的章节学到，你可以把这部分认为是本章提到的exp(h(x))的h函数)来实现分类器的效果。</p>
<p>&emsp;&emsp;要分类的数据集（不过值得一提的是我找到的卡通化方法不是非常有效,一些图片没有很好实现卡通化的效果，不过还是足够做为协变量偏移的例子来学习）
|<img alt="cat" src="../data/ch04-4-9-2and4-9-3/dogvscat/train/cats/cat.125.jpg" />| <img alt="cat" src="../data/ch04-4-9-2and4-9-3/dogvscat/testcartoon/cats/cat.10.jpg" />|
|:---: |:---:|
|normal|cartoon|</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span> 
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span><span class="n">models</span><span class="p">,</span><span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">gc</span> 
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="c1">#清理内存</span>
<span class="c1">#加载函数</span>
<span class="k">def</span> <span class="nf">getmean_str</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span><span class="n">name</span><span class="p">):</span>
    <span class="n">data_trainsforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="p">])</span>
    <span class="n">image_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
                          <span class="n">transform</span><span class="o">=</span><span class="n">data_trainsforms</span><span class="p">)</span>
    <span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">image_datasets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">mean</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">+=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">d</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            <span class="n">std</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">+=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">d</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">mean</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">))</span>
    <span class="n">std</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">name</span> <span class="p">,</span><span class="s2">&quot; mean:&quot;</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="s2">&quot;std:&quot;</span><span class="p">,</span><span class="n">std</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()),</span> <span class="nb">list</span><span class="p">(</span><span class="n">std</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span><span class="n">meanlist</span><span class="p">,</span> <span class="n">stdlist</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span> 
    <span class="n">data_trainsforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">meanlist</span><span class="p">,</span> <span class="n">stdlist</span><span class="p">),</span>
    <span class="p">])</span>
    <span class="c1">#拼接路径</span>
    <span class="n">image_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
                          <span class="n">transform</span><span class="o">=</span><span class="n">data_trainsforms</span><span class="p">)</span>
    <span class="c1">#数据加载器</span>
    <span class="n">data_iter</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">data_iter</span><span class="p">,</span><span class="n">image_datasets</span><span class="p">)</span><span class="c1">#(train_iter,test_iter,image_train_datasets,image_test_datasets)</span>
<span class="c1">#训练函数</span>
<span class="k">def</span> <span class="nf">train_epoch_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">Use_gpu</span><span class="p">,</span><span class="n">detector</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> 
    <span class="n">train_acc</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="n">train_loss</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span><span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">,</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span>
            <span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span><span class="n">Variable</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">Variable</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">detector</span><span class="o">!=</span><span class="kc">None</span><span class="p">:</span>

                <span class="n">beta</span><span class="o">=</span> <span class="n">detector</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
                    <span class="n">beta</span><span class="o">=</span><span class="n">Variable</span><span class="p">(</span><span class="n">beta</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="n">detector</span><span class="o">==</span><span class="kc">None</span> <span class="k">else</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span><span class="c1">#反向传播</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span><span class="c1">#优化</span>
            <span class="n">_</span><span class="p">,</span><span class="n">pred</span> <span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">train_acc</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">l</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">batch</span><span class="o">%</span><span class="mi">200</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch:</span><span class="si">{}</span><span class="s2">,Train Loss:</span><span class="si">{:.4f}</span><span class="s2">,Train ACC:</span><span class="si">{:.4f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span><span class="n">train_loss</span><span class="o">/</span><span class="n">batch</span><span class="p">,</span><span class="mi">100</span><span class="o">*</span><span class="n">train_acc</span><span class="o">/</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span><span class="o">*</span><span class="n">batch</span><span class="p">)))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">train_loss</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">))),(</span><span class="n">train_acc</span><span class="o">/</span><span class="p">((</span><span class="n">batch_size</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_iter</span><span class="p">)))</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="c1">#评价函数</span>
<span class="k">def</span> <span class="nf">evaluate_accuracy_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">Use_gpu</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
    <span class="c1">#metric = d2l.Accumulator(2)  # 正确预测数、预测总数</span>
    <span class="n">test_acc</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="n">number</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">data</span>
            <span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span><span class="c1">#有gpu在gpu下评估</span>
                <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span><span class="n">Variable</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">Variable</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="c1">#metric.add(d2l.accuracy(net(X), y), y.numel())</span>
            <span class="n">_</span><span class="p">,</span><span class="n">pred</span> <span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">test_acc</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">number</span><span class="o">+=</span><span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="n">test_acc</span><span class="o">=</span><span class="p">((</span><span class="n">test_acc</span> <span class="o">/</span> <span class="n">number</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>    
    <span class="k">return</span> <span class="n">test_acc</span>
<span class="c1">#训练函数</span>
<span class="k">def</span> <span class="nf">train_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">,</span><span class="n">test_iter2</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">savename</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/covariate_shift_detectormodel.pth&#39;</span><span class="p">,</span><span class="n">detector</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">test_iter2</span><span class="o">==</span><span class="kc">None</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test acc&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train loss&#39;</span><span class="p">,</span> <span class="s1">&#39;train acc&#39;</span><span class="p">,</span> <span class="s1">&#39;test cartoon acc&#39;</span><span class="p">,</span><span class="s1">&#39;test normal acc &#39;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">train_epoch_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">,</span><span class="n">detector</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">evaluate_accuracy_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">test_iter2</span><span class="o">!=</span><span class="kc">None</span><span class="p">:</span>
            <span class="n">test_acc2</span> <span class="o">=</span> <span class="n">evaluate_accuracy_ch4_9</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">test_iter2</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">)</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,</span><span class="n">test_acc2</span><span class="p">,))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch</span><span class="si">{}</span><span class="s2"> Loss:</span><span class="si">{:.4f}</span><span class="s2"> Train Acc:</span><span class="si">{:.4f}</span><span class="s2">% Test Cartoon Acc:</span><span class="si">{:.4f}</span><span class="s2">% Test Normal Acc:</span><span class="si">{:.4f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">train_metrics</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">100</span><span class="o">*</span><span class="n">test_acc</span><span class="p">,</span><span class="mi">100</span><span class="o">*</span><span class="n">test_acc2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span> <span class="o">+</span> <span class="p">(</span><span class="n">test_acc</span><span class="p">,))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch</span><span class="si">{}</span><span class="s2"> Loss:</span><span class="si">{:.4f}</span><span class="s2"> Train Acc:</span><span class="si">{:.4f}</span><span class="s2">% Test  Acc:</span><span class="si">{:.4f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_metrics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">100</span><span class="o">*</span><span class="n">train_metrics</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">100</span><span class="o">*</span><span class="n">test_acc</span><span class="p">))</span>

    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_metrics</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span><span class="n">savename</span><span class="p">)</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;save&quot;</span><span class="p">,</span><span class="n">savename</span><span class="p">,</span><span class="s2">&quot;over&quot;</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">train_loss</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">train_loss</span>
    <span class="k">assert</span> <span class="n">train_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">train_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">train_acc</span>
    <span class="k">assert</span> <span class="n">test_acc</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">test_acc</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">test_acc</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1">#数据加载</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/ch04-4-9-2and4-9-3/cartoonvsnormal&quot;</span>
<span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">mean_test_list</span><span class="p">,</span><span class="n">std_test_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">cartoon_num</span><span class="o">=</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="s1">&#39;cartoon&#39;</span><span class="p">)))</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="s1">&#39;cartoon&#39;</span><span class="p">))))</span>
<span class="n">normal_num</span><span class="o">=</span><span class="mf">1.0</span><span class="o">*</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span><span class="s1">&#39;normal&#39;</span><span class="p">)))</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">,</span><span class="s1">&#39;normal&#39;</span><span class="p">))))</span>
<span class="n">train_iter</span><span class="p">,</span><span class="n">image_train_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_iter</span><span class="p">,</span><span class="n">image_test_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="n">mean_test_list</span><span class="p">,</span><span class="n">std_test_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">index_classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">image_test_datasets</span><span class="o">.</span><span class="n">class_to_idx</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;类别一 </span><span class="si">{}</span><span class="s2">，数量</span><span class="si">{}</span><span class="s2">，类别二 </span><span class="si">{}</span><span class="s2"> 数量</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">cartoon_num</span><span class="p">,</span><span class="n">index_classes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">normal_num</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;类别一 </span><span class="si">{}</span><span class="s2">，数量</span><span class="si">{}</span><span class="s2">，类别二 </span><span class="si">{}</span><span class="s2"> 数量</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">cartoon_num</span><span class="p">,</span><span class="n">index_classes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">normal_num</span><span class="p">))</span>
<span class="c1">#加载模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">for</span> <span class="n">parma</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">parma</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="c1">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span>
<span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>


<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1">#损失函数和优化器</span>
<span class="n">weight</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">normal_num</span><span class="p">,</span><span class="n">cartoon_num</span><span class="p">])</span>
<span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">if</span> <span class="n">Use_gpu</span> <span class="k">else</span> <span class="n">weight</span>
<span class="n">loss_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span><span class="c1">#不同类别数据量不同 添加权重来平衡</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">)</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_ch4_9</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span> <span class="n">loss_f</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">)</span>
<span class="c1">#清除内存</span>
<span class="k">del</span> <span class="n">model</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epoch15 Loss:0.1816 Train Acc:96.2050% Test  Acc:95.6800%
save ../data/ch04-4-9-2and4-9-3/covariate_shift_detectormodel.pth over
</code></pre></div>
<p><img alt="svg" src="../output_205_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span>  <span class="nf">covariate_shift_detector</span><span class="p">(</span><span class="n">input_image</span><span class="p">,</span><span class="n">model_pth</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/covariate_shift_detectormodel.pth&#39;</span><span class="p">):</span>
    <span class="n">softmax</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_pth</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">beta</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nb">min</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">output</span><span class="o">=</span><span class="n">beta</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">input_image</span><span class="p">)))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">beta</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">)))),</span><span class="n">input_image</span> <span class="p">)))</span>
        <span class="k">del</span> <span class="n">model</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">random</span>
<span class="c1">#test_iter,image_test_datasets=load_data_cartoonvsnormal(os.path.join(data_dir, &#39;test&#39;),batch_size)</span>
<span class="n">testnum</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">image_test_datasets</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">index_classes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">image_test_datasets</span><span class="o">.</span><span class="n">class_to_idx</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">input_image</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">image_test_datasets</span><span class="p">[</span><span class="n">testnum</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="mi">0</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">input_image</span><span class="o">=</span><span class="n">input_image</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">output</span><span class="o">=</span><span class="n">index_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">covariate_shift_detector</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span><span class="o">&gt;=</span><span class="mi">1</span> <span class="k">else</span> <span class="n">index_classes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;testnum &quot;</span><span class="p">,</span><span class="n">testnum</span><span class="p">,</span><span class="s2">&quot; 推断类别：&quot;</span><span class="p">,</span><span class="n">output</span><span class="p">,</span><span class="s2">&quot;实际类别：&quot;</span><span class="p">,</span><span class="n">index_classes</span><span class="p">[</span><span class="n">image_test_datasets</span><span class="p">[</span><span class="n">testnum</span><span class="p">][</span><span class="mi">1</span><span class="p">]])</span>
<span class="k">del</span> <span class="n">input_image</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>testnum  3182  推断类别： normal 实际类别： normal
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;clear&#39;</span><span class="p">)</span>
<span class="n">input_image</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">image_test_datasets</span><span class="p">]</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">image_test_datasets</span><span class="p">]</span>
<span class="n">output</span><span class="o">=</span><span class="n">covariate_shift_detector</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
<span class="n">test_label</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">image_test_datasets</span><span class="p">])</span>
<span class="n">cartoonacc</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span><span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span> <span class="p">,</span><span class="n">output</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">test_label</span><span class="p">))))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_label</span><span class="p">)</span><span class="o">-</span><span class="n">test_label</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">normalacc</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="mi">0</span><span class="o">&lt;</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span> <span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">test_label</span><span class="p">))))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">/</span><span class="p">(</span><span class="n">test_label</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;卡通图片预测正确率:</span><span class="si">{:.4f}</span><span class="s1">% ,正常图片预测正确率:</span><span class="si">{:.4f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">cartoonacc</span><span class="p">,</span><span class="mi">100</span><span class="o">*</span><span class="n">normalacc</span><span class="p">))</span>
<span class="k">del</span> <span class="n">input_image</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>clear
卡通图片预测正确率:92.7000% ,正常图片预测正确率:96.4250%
</code></pre></div>
<h3 id="493">练习4.9.3<a class="headerlink" href="#493" title="Permanent link">⚓︎</a></h3>
<p>实现协变量偏移纠正。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;首先展示没有使用分类器来训练模型的结果，可以看到训练的后期，即使各个数据曲线已经趋平，训练准确率仍然高于测试准确率。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import库 以及 用到的函数定义见4.9.2</span>
<span class="c1">#数据加载</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span>
<span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="s1">&#39;testcartoon&#39;</span><span class="p">)</span>
<span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="s1">&#39;testnormal&#39;</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span><span class="n">image_train_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">image_testcartoon_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testnormal_iter</span><span class="p">,</span><span class="n">image_testnormal_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="c1">#加载模型</span>
<span class="n">model_no_detector</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="k">for</span> <span class="n">parma</span> <span class="ow">in</span> <span class="n">model_no_detector</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">parma</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="c1">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span>
<span class="n">model_no_detector</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">model_no_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">);</span>


<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="n">model_no_detector</span> <span class="o">=</span> <span class="n">model_no_detector</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1">#损失函数和优化器</span>
<span class="n">loss_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_no_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span> <span class="o">=</span>  <span class="mf">1e-4</span><span class="p">)</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_ch4_9</span><span class="p">(</span><span class="n">model_no_detector</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">testcartoon_iter</span><span class="p">,</span> <span class="n">loss_f</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">,</span><span class="n">test_iter2</span><span class="o">=</span><span class="n">testnormal_iter</span><span class="p">,</span><span class="n">savename</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/dogvscatwithoutdetectormodel.pth&#39;</span><span class="p">)</span>
<span class="c1">#清除内存</span>
<span class="k">del</span> <span class="n">model_no_detector</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epoch10 Loss:0.1253 Train Acc:97.0950% Test Cartoon Acc:89.8000% Test Normal Acc:97.5200%
save ../data/ch04-4-9-2and4-9-3/dogvscatwithoutdetectormodel.pth over
</code></pre></div>
<p><img alt="svg" src="../output_212_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="c1">#内存清理</span>
<span class="c1">#数据加载</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span>
<span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="s1">&#39;testcartoon&#39;</span><span class="p">)</span>
<span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="s1">&#39;testnormal&#39;</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span><span class="n">image_train_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">image_testcartoon_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testnormal_iter</span><span class="p">,</span><span class="n">image_testnormal_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="c1">#加载模型</span>
<span class="n">model_detector</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="c1">#del modelwithoutdetector</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;clear&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">parma</span> <span class="ow">in</span> <span class="n">model_detector</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">parma</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="c1">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span>
<span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">);</span> 


<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="n">model_detector</span> <span class="o">=</span> <span class="n">model_detector</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1">#损失函数和优化器</span>
<span class="k">def</span> <span class="nf">myloss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">):</span>
    <span class="n">loss_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">loss_f</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> 


<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span> <span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span> 

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_ch4_9</span><span class="p">(</span><span class="n">model_detector</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">myloss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">,</span><span class="n">test_iter2</span><span class="o">=</span><span class="n">testnormal_iter</span><span class="p">,</span><span class="n">savename</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth&#39;</span><span class="p">,</span><span class="n">detector</span><span class="o">=</span><span class="n">covariate_shift_detector</span><span class="p">)</span>
<span class="c1">#清除内存</span>
<span class="k">del</span> <span class="n">model_detector</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epoch10 Loss:0.0668 Train Acc:90.6500% Test Cartoon Acc:83.6000% Test Normal Acc:90.9200%
save ../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth over
</code></pre></div>
<p><img alt="svg" src="../output_213_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span><span class="c1">#内存清理</span>
<span class="c1">#数据加载</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span>
<span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="s1">&#39;testcartoon&#39;</span><span class="p">)</span>
<span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="s1">&#39;testnormal&#39;</span><span class="p">)</span>
<span class="n">train_iter</span><span class="p">,</span><span class="n">image_train_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">),</span><span class="n">mean_train_list</span><span class="p">,</span><span class="n">std_train_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">image_testcartoon_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">testnormal_iter</span><span class="p">,</span><span class="n">image_testnormal_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">),</span><span class="n">mean_testnormal_list</span><span class="p">,</span><span class="n">std_testnormal_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="c1">#加载模型</span>
<span class="n">model_detector</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="c1">#del modelwithoutdetector</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;clear&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">parma</span> <span class="ow">in</span> <span class="n">model_detector</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">parma</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span><span class="c1">#屏蔽预训练模型的权重，只训练最后一层的全连接的权重</span>
<span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">);</span> 


<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="n">model_detector</span> <span class="o">=</span> <span class="n">model_detector</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1">#损失函数和优化器</span>
<span class="k">def</span> <span class="nf">myloss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">beta</span><span class="p">):</span>
    <span class="n">loss_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">l</span><span class="o">=</span><span class="n">loss_f</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">25</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span><span class="n">l</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1">#直接使用beta计算结果 并没有改善 这可能是因为beta小于1 使loss变小 导致更新梯度以后 变化不大 所以乘以一个数 以改善这种情况</span>


<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span><span class="n">lr</span> <span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span> 

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_ch4_9</span><span class="p">(</span><span class="n">model_detector</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">myloss</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span><span class="n">optimizer</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">,</span><span class="n">test_iter2</span><span class="o">=</span><span class="n">testnormal_iter</span><span class="p">,</span><span class="n">savename</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth&#39;</span><span class="p">,</span><span class="n">detector</span><span class="o">=</span><span class="n">covariate_shift_detector</span><span class="p">)</span>
<span class="c1">#清除内存</span>
<span class="k">del</span> <span class="n">model_detector</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>epoch10 Loss:0.4316 Train Acc:98.0200% Test Cartoon Acc:92.3600% Test Normal Acc:97.9600%
save ../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth over
</code></pre></div>
<p><img alt="svg" src="../output_214_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">Use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="k">if</span> <span class="n">Use_gpu</span><span class="p">:</span>
    <span class="c1">#del modelwithoutdetector</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;clear&#39;</span><span class="p">)</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/ch04-4-9-2and4-9-3/dogvscat&quot;</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
<span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="o">=</span><span class="n">getmean_str</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="s1">&#39;testcartoon&#39;</span><span class="p">)</span>
<span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">image_testcartoon_datasets</span><span class="o">=</span><span class="n">load_data_cartoonvsnormal</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;testcartoon&#39;</span><span class="p">),</span><span class="n">mean_testcartoon_list</span><span class="p">,</span><span class="n">std_testcartoon_list</span><span class="p">,</span><span class="n">batch_size</span><span class="p">)</span>
<span class="c1">#加载模型</span>
<span class="n">model_detector</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">model_detector</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model_detector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/dogvscatwithdetectormodel.pth&#39;</span><span class="p">))</span>
<span class="c1">#加载模型\</span>
<span class="n">model_no_detector</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">models</span><span class="o">.</span><span class="n">ResNet50_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">model_no_detector</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model_no_detector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;../data/ch04-4-9-2and4-9-3/dogvscatwithoutdetectormodel.pth&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;没使用分类器测试准确率：</span><span class="si">{:.4f}</span><span class="s2">%,使用分类器测试准确率：</span><span class="si">{:.4f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">evaluate_accuracy_ch4_9</span><span class="p">(</span><span class="n">model_no_detector</span><span class="p">,</span><span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">),</span><span class="mi">100</span><span class="o">*</span><span class="n">evaluate_accuracy_ch4_9</span><span class="p">(</span><span class="n">model_detector</span><span class="p">,</span> <span class="n">testcartoon_iter</span><span class="p">,</span><span class="n">Use_gpu</span><span class="p">)))</span>
<span class="c1">#清除内存</span>
<span class="k">del</span> <span class="n">model_no_detector</span>
<span class="k">del</span> <span class="n">model_detector</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>clear
testcartoon  mean: tensor([0.4168, 0.3945, 0.3463]) std: tensor([0.2118, 0.2033, 0.1590])
没使用分类器测试准确率：89.8000%,使用分类器测试准确率：92.3600%
</code></pre></div>
<h3 id="494">练习4.9.4<a class="headerlink" href="#494" title="Permanent link">⚓︎</a></h3>
<p>除了分布偏移，还有什么会影响经验风险接近真实风险的程度？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;除了分布偏移之外，还有以下因素可能会影响经验风险接近真实风险的程度：</p>
<ol>
<li>
<p>样本大小：经验风险的准确性通常随着样本大小的增加而增加。较大的样本量提供了更多的信息，使得估计的风险更加可靠。</p>
</li>
<li>
<p>特征选择：选择恰当的特征可以减少噪声和冗余信息的影响，从而提高对真实风险的估计。良好的特征选择有助于提高模型的泛化能力。</p>
</li>
<li>
<p>模型复杂度：模型的复杂度与其在训练数据上的表现以及对真实风险的估计密切相关。过于简单的模型可能无法捕捉到数据中的复杂关系，而过于复杂的模型可能过度拟合训练数据，导致经验风险与真实风险之间的差距增大。</p>
</li>
<li>
<p>数据质量：数据质量对于经验风险的准确性至关重要。低质量的数据、含有错误或缺失值的数据可能导致错误的模型训练和风险估计。</p>
</li>
<li>
<p>样本选择偏差：如果样本选择不恰当或存在偏差，例如采样方式不随机或样本并非代表总体，那么经验风险可能无法准确地估计真实风险。</p>
</li>
<li>
<p>噪声和异常值：数据中的噪声和异常值可能对经验风险的估计造成干扰。这些异常值可能使模型过度拟合，并导致对真实风险的估计不准确。</p>
</li>
</ol>
<p>请注意，这些因素的影响程度可能因具体情况而异，取决于数据集和建模方法的特点。</p>
<h2 id="410-kaggle">4.10 实战Kaggle比赛：预测房价<a class="headerlink" href="#410-kaggle" title="Permanent link">⚓︎</a></h2>
<h3 id="4102">练习4.10.2<a class="headerlink" href="#4102" title="Permanent link">⚓︎</a></h3>
<p>能通过直接最小化价格的对数来改进模型吗？如果试图预测价格的对数而不是价格，会发生什么？</p>
<p><strong>解答：</strong> </p>
<p>&emsp;&emsp;直接预测对数价格结果不太好，为了避免数值稳定性我们把网络线性层得到的小于1的值置为1，这可能会导致这部分数据没有梯度 无法更新参数从而影响结果。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;kaggle_house_train&#39;</span><span class="p">))</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;kaggle_house_test&#39;</span><span class="p">))</span>
<span class="n">all_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
<span class="c1"># 若无法获得测试数据，则可根据训练数据计算均值和标准差</span>
<span class="n">numeric_features</span> <span class="o">=</span> <span class="n">all_features</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">all_features</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">!=</span> <span class="s1">&#39;object&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">all_features</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_features</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
<span class="c1"># 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0</span>
<span class="n">all_features</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_features</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">all_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">all_features</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="n">train_data</span><span class="o">.</span><span class="n">SalePrice</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">in_features</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">losslogtestfunc</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">m</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span><span class="n">num_outputs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">H1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin1</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_inputs</span><span class="p">)))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">clipped_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">out</span>
<span class="k">def</span> <span class="nf">get_net</span><span class="p">():</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span>
<span class="k">def</span> <span class="nf">log_rmse</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="c1"># 为了在取对数时进一步稳定该值，将小于1的值设置为1</span>
    <span class="n">clipped_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
    <span class="n">rmse</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">clipped_preds</span><span class="p">),</span>
                           <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">rmse</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">l</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">,</span>
          <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">testfunc</span><span class="o">=</span><span class="n">log_rmse</span><span class="p">):</span>
    <span class="n">train_ls</span><span class="p">,</span> <span class="n">test_ls</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="c1"># 这里使用的是Adam优化算法</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                 <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">,</span>
                                 <span class="n">weight_decay</span> <span class="o">=</span> <span class="n">weight_decay</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">ll</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">y</span><span class="p">)</span><span class="c1">#loss(torch.log(torch.clamp(net(X), 1, float(&#39;inf&#39;))),torch.log(y))#计算logy 和log\hat{y}</span>
            <span class="n">ll</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="n">train_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">testfunc</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span><span class="n">train_labels</span><span class="p">))</span><span class="c1">#(log_rmse(net, train_features, train_labels))</span>

        <span class="k">if</span> <span class="n">test_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="n">test_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">testfunc</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">))</span><span class="c1">#(log_rmse(net, test_features, test_labels))</span>
    <span class="k">return</span> <span class="n">train_ls</span><span class="p">,</span> <span class="n">test_ls</span>
<span class="k">def</span> <span class="nf">get_k_fold_data</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="mi">1</span>
    <span class="n">fold_size</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">k</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">j</span> <span class="o">*</span> <span class="n">fold_size</span><span class="p">,</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">fold_size</span><span class="p">)</span>
        <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
            <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span>
        <span class="k">elif</span> <span class="n">X_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X_part</span><span class="p">,</span> <span class="n">y_part</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_part</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_part</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span>
<span class="k">def</span> <span class="nf">k_fold</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="n">net</span><span class="p">,</span><span class="n">k</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span>
           <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">testfunc</span><span class="o">=</span><span class="n">log_rmse</span><span class="p">):</span>
    <span class="n">train_l_sum</span><span class="p">,</span> <span class="n">valid_l_sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">get_k_fold_data</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
        <span class="n">train_ls</span><span class="p">,</span> <span class="n">valid_ls</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">l</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span>
                                   <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">testfunc</span><span class="o">=</span><span class="n">log_rmse</span><span class="p">)</span>
        <span class="n">train_l_sum</span> <span class="o">+=</span> <span class="n">train_ls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">valid_l_sum</span> <span class="o">+=</span> <span class="n">valid_ls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">show</span><span class="o">==</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span> <span class="p">[</span><span class="n">train_ls</span><span class="p">,</span> <span class="n">valid_ls</span><span class="p">],</span>
                     <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span>
                     <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;valid&#39;</span><span class="p">],</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;折</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">，训练log rmse</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_ls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
              <span class="sa">f</span><span class="s1">&#39;验证log rmse</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_ls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_l_sum</span> <span class="o">/</span> <span class="n">k</span><span class="p">,</span> <span class="n">valid_l_sum</span> <span class="o">/</span> <span class="n">k</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">Net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span>  <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">train_labels</span><span class="p">),</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">testfunc</span><span class="o">=</span><span class="n">losslogtestfunc</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
      <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>折1，训练log rmse0.193160, 验证log rmse0.193856
折2，训练log rmse2.486527, 验证log rmse2.486790
折3，训练log rmse2.486307, 验证log rmse2.487668
折4，训练log rmse0.177956, 验证log rmse0.175148
折5，训练log rmse2.486396, 验证log rmse2.487313
5-折验证: 平均训练log rmse: 1.566069, 平均验证log rmse: 1.566155
</code></pre></div>
<p><img alt="svg" src="../output_224_1.svg" /></p>
<h3 id="4103">练习4.10.3<a class="headerlink" href="#4103" title="Permanent link">⚓︎</a></h3>
<p>用平均值替换缺失值总是好主意吗？提示：能构造一个不随机丢失值的情况吗？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;当缺失值太多且我们有用数据的均值和方差来标准化数据时会导致数据中有太多的零出现，从而可能的丢弃了缺失值过多特征的信息。我们可以对缺失的数据用前后值或者插值法填充。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import库 以及 用到的函数定义见4.9.2</span>
<span class="n">all_features2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
<span class="n">numeric_features2</span> <span class="o">=</span> <span class="n">all_features2</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">all_features2</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">!=</span> <span class="s1">&#39;object&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

<span class="n">all_features2</span><span class="p">[</span><span class="n">numeric_features2</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_features</span><span class="p">[</span><span class="n">numeric_features2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
     <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
<span class="c1"># # 在标准化数据之后，我们用插值法替换缺失值</span>
<span class="n">all_features2</span><span class="p">[</span><span class="n">numeric_features2</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_features2</span><span class="p">[</span><span class="n">numeric_features2</span><span class="p">]</span><span class="o">.</span><span class="n">interpolate</span><span class="p">()</span>
<span class="n">all_features2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">all_features2</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">train_features2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features2</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">test_features2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features2</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">train_labels2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">SalePrice</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">in_features2</span> <span class="o">=</span> <span class="n">train_features2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features2</span><span class="p">,</span> <span class="n">train_labels2</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
      <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>折1，训练log rmse0.170187, 验证log rmse0.156665
折2，训练log rmse0.162936, 验证log rmse0.192074
折3，训练log rmse0.163925, 验证log rmse0.168308
折4，训练log rmse0.168358, 验证log rmse0.154775
折5，训练log rmse0.163274, 验证log rmse0.183363
5-折验证: 平均训练log rmse: 0.165736, 平均验证log rmse: 0.171037
</code></pre></div>
<p><img alt="svg" src="../output_228_1.svg" /></p>
<h3 id="4104">练习4.10.4<a class="headerlink" href="#4104" title="Permanent link">⚓︎</a></h3>
<p>通过<span class="arithmatex">\(K\)</span>折交叉验证调整超参数，从而提高Kaggle的得分。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;取num_epochs, lr, batch_size,weight_decay  = 100, 15, 31,0 提交结果可以得到0.1504分值</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import库 以及 用到的函数定义见4.10.2</span>
<span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">animator_lr</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;lr=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_lr</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_232_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>  <span class="mi">64</span>
<span class="n">animator_wd</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$\lambda$ lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1"> batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">weight_decay</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weight_decay=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">   </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_wd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_233_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span>  <span class="mi">64</span> <span class="c1">#为了使得 weight_decay起作用我们选一个较大的num_epochs</span>
<span class="n">animator_wd</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$\lambda$ lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1"> batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>
<span class="n">findmin</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">:</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">)</span> <span class="k">if</span> <span class="n">y2</span><span class="o">&gt;=</span><span class="n">y1</span> <span class="k">else</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">)</span>
<span class="n">weight_decay_get</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">weight_decay</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">weight_decay</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">l</span><span class="o">=</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span> <span class="n">valid_l</span><span class="p">)</span>
    <span class="n">weight_decay_get</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="n">findmin</span><span class="p">(</span> <span class="n">weight_decay_get</span><span class="p">,</span><span class="n">weight_decay</span><span class="p">,</span><span class="n">l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span> <span class="n">valid_l</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weight_decay=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_wd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weight_decay_get:</span><span class="si">{</span><span class="n">weight_decay_get</span><span class="si">}</span><span class="s1">,loss: </span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>weight_decay_get:0,loss: 0.14212286472320557
</code></pre></div>
<p><img alt="svg" src="../output_234_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span>  <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">0</span>
<span class="n">animator_batch_size</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;batch_size lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">201</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>
<span class="n">findmin</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span><span class="n">x2</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">y2</span><span class="p">:</span> <span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">)</span> <span class="k">if</span> <span class="n">y2</span><span class="o">&gt;=</span><span class="n">y1</span> <span class="k">else</span> <span class="p">(</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">)</span>
<span class="n">batch_size_get</span><span class="o">=</span><span class="mi">1</span>
<span class="k">for</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">202</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">batch_size</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">l</span><span class="o">=</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span> <span class="n">valid_l</span><span class="p">)</span>
    <span class="n">batch_size_get</span><span class="p">,</span><span class="n">l</span><span class="o">=</span><span class="n">findmin</span><span class="p">(</span><span class="n">batch_size_get</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="n">l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span> <span class="n">valid_l</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_batch_size</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;batch_get:</span><span class="si">{</span><span class="n">batch_size_get</span><span class="si">}</span><span class="s1">,loss: </span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>batch_get:31,loss: 0.13678632006049157
</code></pre></div>
<p><img alt="svg" src="../output_235_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span>  <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">batch_size_get</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">0</span>
<span class="n">animator_num_epochs</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;num_epochs batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1"> lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">200</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">num_epochs</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">210</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;num_epochs=</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_num_epochs</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_236_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span>  <span class="mi">31</span>
<span class="n">animator_wd</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$\lambda$ lr=</span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s1"> batch_size=</span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
                        <span class="n">legend</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;train &#39;</span><span class="p">,</span> <span class="s1">&#39;valid &#39;</span><span class="p">,</span><span class="s1">&#39;mean(train+valid)&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">weight_decay</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;weight_decay=</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">  </span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
            <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">animator_wd</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">weight_decay</span><span class="p">,</span> <span class="p">(</span><span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span><span class="p">,</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">train_l</span><span class="o">+</span><span class="n">valid_l</span><span class="p">)))</span>
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_237_0.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_and_pred</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span>
                   <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;submission.csv&#39;</span><span class="p">,</span><span class="n">f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()):</span>
    <span class="c1">#net = get_net()</span>
    <span class="n">train_ls</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="n">train_ls</span><span class="p">],</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
             <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;log rmse&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">],</span> <span class="n">yscale</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;训练log rmse：</span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_ls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="c1"># 将网络应用于测试集。</span>
    <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">test_features</span><span class="p">))</span>
    <span class="c1"># 将其重新格式化以导出到Kaggle</span>
    <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;Id&#39;</span><span class="p">],</span> <span class="n">test_data</span><span class="p">[</span><span class="s1">&#39;SalePrice&#39;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">weight_decay</span>  <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span><span class="mi">0</span>
<span class="n">train_and_pred</span><span class="p">(</span><span class="n">get_net</span><span class="p">(),</span><span class="n">loss</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span>
                   <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="s1">&#39;../data/ch04-4-10-4-submission.csv&#39;</span><span class="p">)</span>
<span class="c1">#提交结果0.1504比原始好一些</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>训练log rmse：0.125820
</code></pre></div>
<p><img alt="svg" src="../output_238_1.svg" /></p>
<h3 id="4105">练习4.10.5<a class="headerlink" href="#4105" title="Permanent link">⚓︎</a></h3>
<p>通过改进模型（例如，层、权重衰减和dropout）来提高分数。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;构造一个3层的网络每层的隐藏单元数分别为165，82，41，并对最后两层分别取dropout为0.2，0.4，学习率为0.0001，训练轮次为100,batchsize为32的模型。提交计算的分数为0.14961。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import库 以及 用到的函数定义见4.9.2</span>
<span class="k">def</span> <span class="nf">mynet</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">):</span>
    <span class="n">net</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span><span class="n">in_features</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                       <span class="c1">#nn.Dropout(dropout1),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">)),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout1</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">)),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout2</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">),</span>
                       <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span>
<span class="n">k</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">0.0001</span>
<span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">mynet</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">),</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span>  <span class="n">train_labels</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">show</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>折1，训练log rmse0.139646, 验证log rmse0.141831
折2，训练log rmse0.136683, 验证log rmse0.150859
折3，训练log rmse0.136523, 验证log rmse0.146661
折4，训练log rmse0.141830, 验证log rmse0.139160
折5，训练log rmse0.136660, 验证log rmse0.169688





(0.13826846182346345, 0.14963960349559785)
</code></pre></div>
<p>​  <br />
<img alt="svg" src="../output_242_2.svg" />
​    </p>
<div class="highlight"><pre><span></span><code><span class="n">k</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">,</span><span class="n">num_epochs</span><span class="p">,</span><span class="n">lr</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="mf">0.5</span><span class="o">*</span><span class="n">in_features</span><span class="p">),</span><span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mf">0.0001</span>

<span class="n">train_and_pred</span><span class="p">(</span><span class="n">mynet</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">),</span><span class="n">dropout1</span><span class="p">,</span><span class="n">dropout2</span><span class="p">),</span><span class="n">loss</span><span class="p">,</span><span class="n">train_features</span><span class="p">,</span> <span class="n">test_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span>
                   <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;../data/ch04-4-10-5-submission.csv&#39;</span><span class="p">)</span>
<span class="c1">#得分0.14961</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>训练log rmse：0.135433
</code></pre></div>
<p><img alt="svg" src="../output_243_1.svg" /></p>
<h3 id="4106">练习4.10.6<a class="headerlink" href="#4106" title="Permanent link">⚓︎</a></h3>
<p>如果我们没有像本节所做的那样标准化连续的数值特征，会发生什么？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;会导致计算时候，模型对数值比较大的特征和数值比较小的特征关注度不一致，无法公平对待每一个特征，同时也可能导致数值不稳定无法训练。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#import库 以及 用到的函数定义见4.9.2</span>
<span class="n">all_features3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">train_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">test_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
<span class="n">numeric_features3</span> <span class="o">=</span> <span class="n">all_features3</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">all_features3</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">!=</span> <span class="s1">&#39;object&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>

<span class="n">all_features3</span><span class="p">[</span><span class="n">numeric_features3</span><span class="p">]</span> <span class="o">=</span> <span class="n">all_features3</span><span class="p">[</span><span class="n">numeric_features3</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">all_features3</span><span class="p">[</span><span class="n">numeric_features3</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">all_features3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">all_features3</span><span class="p">,</span> <span class="n">dummy_na</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">train_features3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features3</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">test_features3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_features3</span><span class="p">[</span><span class="n">n_train</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">train_labels3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">SalePrice</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="n">in_features3</span> <span class="o">=</span> <span class="n">train_features3</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">def</span> <span class="nf">get_net</span><span class="p">():</span>
    <span class="n">net</span><span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">net</span>
<span class="n">k</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">64</span>
<span class="n">train_l</span><span class="p">,</span> <span class="n">valid_l</span> <span class="o">=</span> <span class="n">k_fold</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="n">get_net</span><span class="p">(),</span><span class="n">k</span><span class="p">,</span> <span class="n">train_features3</span><span class="p">,</span> <span class="n">train_labels3</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span>
                          <span class="n">weight_decay</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">-折验证: 平均训练log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">train_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">, &#39;</span>
      <span class="sa">f</span><span class="s1">&#39;平均验证log rmse: </span><span class="si">{</span><span class="nb">float</span><span class="p">(</span><span class="n">valid_l</span><span class="p">)</span><span class="si">:</span><span class="s1">f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>折1，训练log rmse0.290396, 验证log rmse0.270101
折2，训练log rmse0.402531, 验证log rmse0.412767
折3，训练log rmse3.897535, 验证log rmse3.313591
折4，训练log rmse0.691012, 验证log rmse0.280185
折5，训练log rmse0.435814, 验证log rmse0.310328
5-折验证: 平均训练log rmse: 1.143458, 平均验证log rmse: 0.917394
</code></pre></div>
<p><img alt="svg" src="../output_247_1.svg" /></p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../../ch03/ch03/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 第3章 线性神经网络">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                第3章 线性神经网络
              </div>
            </div>
          </a>
        
        
          
          <a href="../../ch05/ch05/" class="md-footer__link md-footer__link--next" aria-label="下一页: 第5章 深度学习计算">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                第5章 深度学习计算
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>