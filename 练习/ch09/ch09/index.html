
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E7%BB%83%E4%B9%A0/ch09/ch09/">
      
      
        <link rel="prev" href="../../ch08/ch08/">
      
      
        <link rel="next" href="../../ch10/ch10/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>第9章 现代循环神经网络 - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#9" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              第9章 现代循环神经网络
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E6%95%99%E7%A8%8B/" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E6%95%99%E7%A8%8B/_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/09-recurrent-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/12-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/13-computational-performance/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E6%95%99%E7%A8%8B/contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch04/ch04/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch05/ch05/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_9" checked>
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            Ch09
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    第9章 现代循环神经网络
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    第9章 现代循环神经网络
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#91-gru" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 门控循环单元（GRU）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.1 门控循环单元（GRU）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#911" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#912" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#913" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#914" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#92-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 长短期记忆网络（LSTM）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.2 长短期记忆网络（LSTM）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#921" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#922" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#923" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#924" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#925" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#93" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 深度循环神经网络
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.3 深度循环神经网络">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#931" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#932" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#933" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#934" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#94" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 双向循环神经网络
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.4 双向循环神经网络">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#941" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#942" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#943" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#95" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 机器翻译与数据集
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.5 机器翻译与数据集">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#951" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#952" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.5.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#96-" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 编码器-解码器架构
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.6 编码器-解码器架构">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#961" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#962" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.6.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#97-seq2seq" class="md-nav__link">
    <span class="md-ellipsis">
      9.7 序列到序列的学习（seq2seq）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.7 序列到序列的学习（seq2seq）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#971" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#972" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#973" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#974" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#975" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#976" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#98" class="md-nav__link">
    <span class="md-ellipsis">
      9.8 束搜索
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.8 束搜索">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#981" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#982" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#983" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#91-gru" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 门控循环单元（GRU）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.1 门控循环单元（GRU）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#911" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#912" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#913" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#914" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.1.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#92-lstm" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 长短期记忆网络（LSTM）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.2 长短期记忆网络（LSTM）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#921" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#922" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#923" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#924" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#925" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.2.5
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#93" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 深度循环神经网络
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.3 深度循环神经网络">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#931" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#932" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#933" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#934" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.3.4
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#94" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 双向循环神经网络
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.4 双向循环神经网络">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#941" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#942" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#943" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.4.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#95" class="md-nav__link">
    <span class="md-ellipsis">
      9.5 机器翻译与数据集
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.5 机器翻译与数据集">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#951" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.5.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#952" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.5.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#96-" class="md-nav__link">
    <span class="md-ellipsis">
      9.6 编码器-解码器架构
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.6 编码器-解码器架构">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#961" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.6.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#962" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.6.2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#97-seq2seq" class="md-nav__link">
    <span class="md-ellipsis">
      9.7 序列到序列的学习（seq2seq）
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.7 序列到序列的学习（seq2seq）">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#971" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#972" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#973" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.3
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#974" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.4
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#975" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#976" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.7.6
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#98" class="md-nav__link">
    <span class="md-ellipsis">
      9.8 束搜索
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9.8 束搜索">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#981" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#982" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#983" class="md-nav__link">
    <span class="md-ellipsis">
      练习 9.8.3
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch09/ch09.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/练习/ch09/ch09.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="9">第9章 现代循环神经网络<a class="headerlink" href="#9" title="Permanent link">⚓︎</a></h1>
<h2 id="91-gru">9.1 门控循环单元（GRU）<a class="headerlink" href="#91-gru" title="Permanent link">⚓︎</a></h2>
<h3 id="911">练习 9.1.1<a class="headerlink" href="#911" title="Permanent link">⚓︎</a></h3>
<p>假设我们只想使用时间步<span class="arithmatex">\(t'\)</span>的输入来预测时间步<span class="arithmatex">\(t &gt; t'\)</span>的输出。对于每个时间步，重置门和更新门的最佳值是什么？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;如果只想采用时间步<span class="arithmatex">\(t'\)</span>的输出来预测时间步<span class="arithmatex">\(t\)</span>的输出，则意味着模型需要减少之前时间步在计算中做出的贡献，根据候选隐状态计算公式：<br />
<span class="arithmatex">\(<span class="arithmatex">\(\tilde{H}_t = tanh(X_tW_{xh}+(R_t \odot H_{t-1})W_{hh}+b_r)\)</span>\)</span>
因此需要令重置门的值趋向于0，减少过去状态的影响，令模型只考虑当前时间步<span class="arithmatex">\(t'\)</span>所做出的贡献。<br />
&emsp;&emsp;在确定候选隐状态后，需要结合更新门进一步确定新的隐状态<span class="arithmatex">\(H_t\)</span>受过去隐状态<span class="arithmatex">\(H_{t-1}\)</span>和候选隐状态<span class="arithmatex">\(\tilde{H}_t\)</span>的影响程度，而在只考虑时间步<span class="arithmatex">\(t'\)</span>的输入时，需要抛弃过去隐状态<span class="arithmatex">\(H_{t-1}\)</span>，来跳过过去时间步。因此根据最终更新公式：<br />
<span class="arithmatex">\(<span class="arithmatex">\(H_t = Z_t \odot H_{t-1} + (1-Z_t) \odot \tilde{H}_t\)</span>\)</span>
需要更新门的值也趋向于0，使得新的隐状态更接近于候选隐状态。<br />
&emsp;&emsp;因此，只想使用时间步<span class="arithmatex">\(t'\)</span>的输入来预测时间步<span class="arithmatex">\(t\)</span>的输出时，对于每个时间步，重置门和更新门的最佳值都应为0。</p>
<h3 id="912">练习 9.1.2<a class="headerlink" href="#912" title="Permanent link">⚓︎</a></h3>
<p>调整和分析超参数对运行时间、困惑度和输出顺序的影响。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;修改模型超参数，代码及对应结果如下：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># [迭代周期，隐藏单元数，批量大小，小批量数据时间步数，学习率]</span>
<span class="n">hyper_0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">250</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_5</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]</span>
<span class="n">hyper_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyper_0</span><span class="p">,</span> <span class="n">hyper_1</span><span class="p">,</span> <span class="n">hyper_2</span><span class="p">,</span> <span class="n">hyper_3</span><span class="p">,</span> <span class="n">hyper_4</span><span class="p">,</span> <span class="n">hyper_5</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
              <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;训练模型（定义见第8章）&quot;&quot;&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="c1"># animator = d2l.Animator(xlabel=&#39;epoch&#39;, ylabel=&#39;perplexity&#39;,</span>
    <span class="c1">#                         legend=[&#39;train&#39;], xlim=[10, num_epochs])</span>
    <span class="c1"># 初始化</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">prefix</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_ch8</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="c1"># 训练和预测</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">ppl</span><span class="p">,</span> <span class="n">speed</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">)</span>
        <span class="c1"># if (epoch + 1) % 10 == 0:</span>
        <span class="c1">#     animator.add(epoch + 1, [ppl])</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">ppl</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">perplexity</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyper_params</span><span class="p">)):</span>
    <span class="n">num_epochs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">gru_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">gru_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
    <span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
    <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">value</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">perplexity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;hyper[</span><span class="si">%d</span><span class="s1">]: Timer:</span><span class="si">%.2f</span><span class="s1">, perplexity:</span><span class="si">%.1f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">times</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">perplexity</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>time traveller came back andfilby s anecdote collapsedthe thing 
hyper[0]: Timer:20.63, perplexity:1.0
time traveller smiled along the time dimension of so along there
hyper[1]: Timer:10.33, perplexity:2.3
time traveller came back andfilby s anecdote collapsedthe thing 
hyper[2]: Timer:12.56, perplexity:1.1
time traveller smiled round at us then still smiling faintlyand 
hyper[3]: Timer:57.04, perplexity:1.0
time traveller came back andfilby s anecdote collapsedthe thing 
hyper[4]: Timer:35.33, perplexity:1.0
time traveller   t  t  t  t  t  t  t  t  t  t  t  t  t  t  t  t 
hyper[5]: Timer:22.51, perplexity:16.7
</code></pre></div>
<p>&emsp;&emsp;对比hyper[0]中的默认超参数配置，我们可以发现
- hyper[1]中缩小迭代周期，导致模型无法完全收敛，导致困惑度增大；
- hyper[2]中减少了隐藏层单元数，使得模型在很短时间内完成收敛，并且因为数据集较为简单的原因，困惑度也降低为1;
- hyper[3]中减小了批量大小，这使得模型的训练时间开销显著增加;
- hyper[4]中将小批量时间步的跨度缩小，虽然也造成了时间开销的增加，但少于批量减少带来的时间增长;
- hyper[5]中则对学习率进行了修改，可以发现过低的学习率会使得模型收敛的非常慢，造成困惑度暴涨。
&emsp;&emsp;综上可以发现，迭代周期和学习率的缩小会导致模型无法在对应周期内完成收敛，导致模型训练不完全，困惑度显著增加。批量大小即时间步跨度的降低则会导致模型每次加载少量数据，变相造成时间开销的增大；而对于简单的数据，采用一个简单的模型既可以降低时间开销，也可以使得模型很好收敛，确保性能。</p>
<h3 id="913">练习 9.1.3<a class="headerlink" href="#913" title="Permanent link">⚓︎</a></h3>
<p>比较<code>rnn.RNN</code>和<code>rnn.GRU</code>的不同实现对运行时间、困惑度和输出字符串的影响。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># RNN</span>
<span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">time_rnn</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;time_rnn:</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time_rnn</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.3, 397371.0 tokens/sec on cuda:0
time travellerit loug the wole coume snor if in if in in i move 
traveller of grecivension our cintsice ard here arenreats a
time_rnn:16.20
</code></pre></div>
<p><img alt="svg" src="../output_16_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">num_inputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">gru_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">gru_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">time_gru</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;time_gru:</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time_gru</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 358084.5 tokens/sec on cuda:0
time traveller for so it will be convenient to speak of himwas e
travelleryou can show black is white by argument said filby
time_gru:17.35
</code></pre></div>
<p><img alt="svg" src="../output_17_1.svg" /></p>
<p>&emsp;&emsp;相较于RNN，GRU在重置门和更新门的计算，以及计算候选隐状态和确定最终隐状态的过程中增加了大量矩阵运算，这些新增的矩阵运算会使得模型的训练时间出现增加。但是得益于GRU中重置门与更新门的结构优势，GRU生成结果的困惑度仅为1.0，低于RNN中的1.3困惑度，输出字符串也更好。</p>
<h3 id="914">练习 9.1.4<a class="headerlink" href="#914" title="Permanent link">⚓︎</a></h3>
<p>如果仅仅实现门控循环单元的一部分，例如，只有一个重置门或一个更新门会怎样？</p>
<p><strong>练习：</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 仅重置门</span>
<span class="k">def</span> <span class="nf">get_params_R</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>

    <span class="k">def</span> <span class="nf">three</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">normal</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
                <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

    <span class="c1"># W_xz, W_hz, b_z = three()  # 更新门参数</span>
    <span class="n">W_xr</span><span class="p">,</span> <span class="n">W_hr</span><span class="p">,</span> <span class="n">b_r</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 重置门参数</span>
    <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 候选隐状态参数</span>
    <span class="c1"># 输出层参数</span>
    <span class="n">W_hq</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
    <span class="n">b_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 附加梯度</span>
    <span class="c1"># params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W_xr</span><span class="p">,</span> <span class="n">W_hr</span><span class="p">,</span> <span class="n">b_r</span><span class="p">,</span> <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">init_gru_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="p">)</span>

<span class="k">def</span> <span class="nf">gru</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">W_xr</span><span class="p">,</span> <span class="n">W_hr</span><span class="p">,</span> <span class="n">b_r</span><span class="p">,</span> <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">H</span><span class="p">,</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="c1"># Z = torch.sigmoid((X @ W_xz) + (H @ W_hz) + b_z)</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hr</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_r</span><span class="p">)</span>
        <span class="n">H_tilda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xh</span><span class="p">)</span> <span class="o">+</span> <span class="p">((</span><span class="n">R</span> <span class="o">*</span> <span class="n">H</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_hh</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_h</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">H_tilda</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">H</span> <span class="o">@</span> <span class="n">W_hq</span> <span class="o">+</span> <span class="n">b_q</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModelScratch</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">get_params_R</span><span class="p">,</span>
                            <span class="n">init_gru_state</span><span class="p">,</span> <span class="n">gru</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 82887.9 tokens/sec on cuda:0
time travelleryou can show black is white by argument said filby
traveller with a slight accession ofcheerfulness really thi
</code></pre></div>
<p><img alt="svg" src="../output_23_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_params_Z</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">*</span><span class="mf">0.01</span>

    <span class="k">def</span> <span class="nf">three</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">normal</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
                <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

    <span class="n">W_xz</span><span class="p">,</span> <span class="n">W_hz</span><span class="p">,</span> <span class="n">b_z</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 更新门参数</span>
    <span class="c1"># W_xr, W_hr, b_r = three()  # 重置门参数</span>
    <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span> <span class="o">=</span> <span class="n">three</span><span class="p">()</span>  <span class="c1"># 候选隐状态参数</span>
    <span class="c1"># 输出层参数</span>
    <span class="n">W_hq</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
    <span class="n">b_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 附加梯度</span>
    <span class="c1"># params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W_xz</span><span class="p">,</span> <span class="n">W_hz</span><span class="p">,</span> <span class="n">b_z</span><span class="p">,</span> <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">init_gru_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="p">)</span>

<span class="k">def</span> <span class="nf">gru</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="n">W_xz</span><span class="p">,</span> <span class="n">W_hz</span><span class="p">,</span> <span class="n">b_z</span><span class="p">,</span> <span class="n">W_xh</span><span class="p">,</span> <span class="n">W_hh</span><span class="p">,</span> <span class="n">b_h</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">H</span><span class="p">,</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xz</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hz</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_z</span><span class="p">)</span>
        <span class="c1">#R = torch.sigmoid((X @ W_xr) + (H @ W_hr) + b_r)</span>
        <span class="n">H_tilda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">((</span><span class="n">X</span> <span class="o">@</span> <span class="n">W_xh</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">W_hh</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_h</span><span class="p">)</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">Z</span> <span class="o">*</span> <span class="n">H</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Z</span><span class="p">)</span> <span class="o">*</span> <span class="n">H_tilda</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">H</span> <span class="o">@</span> <span class="n">W_hq</span> <span class="o">+</span> <span class="n">b_q</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">H</span><span class="p">,)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModelScratch</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">get_params_Z</span><span class="p">,</span>
                            <span class="n">init_gru_state</span><span class="p">,</span> <span class="n">gru</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.1, 73438.9 tokens/sec on cuda:0
time traveller for so it will be convenient to speak of himwas e
traveller with a slight accession ofcheerfulness really thi
</code></pre></div>
<p><img alt="svg" src="../output_26_1.svg" /></p>
<p>&emsp;&emsp;门控循环单元（GRU）是一种递归神经网络，具有两个门控制状态的更新和重置，这些门可以控制输入的流入和隐藏状态的保留程度。如果仅实现其中一个门，则将无法实现完整的GRU模型。<br />
&emsp;&emsp;如果只实现了一个重置门，那么模型将只能重置隐藏状态，而无法更新其状态。这会导致模型无法学习长期依赖性并且可能无法产生准确的输出。而如果只实现了一个更新门，则模型可以更新其隐藏状态，但是无法选择要丢弃的信息，这也可能会导致模型无法正确地处理长期依赖性。<br />
&emsp;&emsp;因此，为了实现GRU模型，需要同时实现更新门和重置门。这样，模型就能够更新其隐藏状态并选择要保留和丢弃的信息，从而使其能够正确地处理长期依赖性。</p>
<h2 id="92-lstm">9.2 长短期记忆网络（LSTM）<a class="headerlink" href="#92-lstm" title="Permanent link">⚓︎</a></h2>
<h3 id="921">练习 9.2.1<a class="headerlink" href="#921" title="Permanent link">⚓︎</a></h3>
<p>调整和分析超参数对运行时间、困惑度和输出顺序的影响。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># [迭代周期，隐藏单元数，批量大小，小批量数据时间步数，学习率]</span>
<span class="n">hyper_0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">250</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_4</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hyper_5</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]</span>
<span class="n">hyper_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyper_0</span><span class="p">,</span> <span class="n">hyper_1</span><span class="p">,</span> <span class="n">hyper_2</span><span class="p">,</span> <span class="n">hyper_3</span><span class="p">,</span> <span class="n">hyper_4</span><span class="p">,</span> <span class="n">hyper_5</span><span class="p">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">perplexity</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hyper_params</span><span class="p">)):</span>
    <span class="n">num_epochs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">hyper_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="c1">#</span>
    <span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
    <span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
    <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">value</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
    <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
    <span class="n">perplexity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;hyper[</span><span class="si">%d</span><span class="s1">]: Timer:</span><span class="si">%.2f</span><span class="s1">, perplexity:</span><span class="si">%.1f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">times</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">perplexity</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>time traveller proceeded anyreal body must have extension in fou
hyper[0]: Timer:26.65, perplexity:1.0
time traveller smiled and herent and therens of the trought to e
hyper[1]: Timer:13.33, perplexity:3.2
time traveller came back andfilby s anecdote collapsedthe thing 
hyper[2]: Timer:14.68, perplexity:1.1
time traveller smiled round at us then still smiling faintlyand 
hyper[3]: Timer:75.33, perplexity:1.0
time traveller came back andfilby s anecdote collapsedthe thing 
hyper[4]: Timer:44.26, perplexity:1.0
time traveller                                                  
hyper[5]: Timer:27.23, perplexity:17.4
</code></pre></div>
<p>&emsp;&emsp;结果与GRU结果类似，对比hyper[0]中的默认超参数配置，我们可以发现
- hyper[1]中缩小迭代周期虽然减少了训练时间，但是导致模型无法完全收敛，导致困惑度增大；
- hyper[2]中减半了隐藏层单元数，使得模型在很短时间内完成收敛，困惑度也降低为1.1;
- hyper[3]中减小了批量大小，虽然困惑度为1，但是模型的训练时间开销显著增加;
- hyper[4]中将小批量时间步的跨度缩小，虽然也造成了时间开销的增加，但少于批量减少带来的时间增长;
- hyper[5]中则对学习率进行了修改，过低的学习率会使得模型训练无法在有限周期内完成训练，造成困惑度暴涨。</p>
<p>&emsp;&emsp;综上可以发现，迭代周期和学习率的缩小会导致模型无法在对应周期内完成收敛，导致模型训练不完全，困惑度显著增加。批量大小即时间步跨度的降低则会导致模型每次加载少量数据，变相造成时间开销的增大；而对于简单的数据，采用一个简单的模型既可以降低时间开销，也可以使得模型很好收敛，确保性能。</p>
<h3 id="922">练习 9.2.2<a class="headerlink" href="#922" title="Permanent link">⚓︎</a></h3>
<p>如何更改模型以生成适当的单词，而不是字符序列？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;将文本的生成方式由字符序列改为单词，具体可采用以下方式：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</code></pre></div>
<ol>
<li>词元化处理时采用单词级别的词元化处理，使得模型学会单词间的关系而非字符间的关系。</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">load_corpus_time_machine</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1">#@save</span>
<span class="w">   </span><span class="sd">&quot;&quot;&quot;返回时光机器数据集的词元索引列表和词表&quot;&quot;&quot;</span>
   <span class="n">lines</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">read_time_machine</span><span class="p">()</span>
   <span class="n">tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="s1">&#39;word&#39;</span><span class="p">)</span>
   <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
   <span class="c1"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，</span>
   <span class="c1"># 所以将所有文本行展平到一个列表中</span>
   <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
   <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
       <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>
   <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span>

<span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus_time_machine</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>(32775, 4580)
</code></pre></div>
<ol>
<li>
<p>使用双向语言模型，将前后文的单词序列纳入考虑范围，实现根据上下文预测单词，获得更准确的输出。<br />
&emsp;&emsp;<code>lstm_layer = nn.LSTM(num_inputs, num_hiddens, bidirectional=True)</code></p>
</li>
<li>
<p>使用WordEmbedding取代One-hot，将单词映射到向量空间，保留了近义词之间的相关性，可以学习单词间的语义关系，更准确的生成单词。</p>
</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RNNModel_Embedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The RNN model.</span>
<span class="sd">    Defined in :numref:`sec_rnn-concise`&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel_Embedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="c1"># If the RNN is bidirectional (to be introduced later),</span>
        <span class="c1"># `num_directions` should be 2, else it should be 1.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># X = F.one_hot(inputs.T.long(), self.vocab_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">Y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="c1"># The fully connected layer will first change the shape of `Y` to</span>
        <span class="c1"># (`num_steps` * `batch_size`, `num_hiddens`). Its output shape is</span>
        <span class="c1"># (`num_steps` * `batch_size`, `vocab_size`).</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">begin_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
            <span class="c1"># `nn.GRU` takes a tensor as hidden state</span>
            <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
                                 <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># `nn.LSTM` takes a tuple of hidden states</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SeqDataLoader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An iterator to load sequence data.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Defined in :numref:`sec_language_model`&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">use_random_iter</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">seq_data_iter_random</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">seq_data_iter_sequential</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus_time_machine</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span>
                           <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return the iterator and the vocabulary of the time machine dataset.</span>

<span class="sd">    Defined in :numref:`sec_language_model`&quot;&quot;&quot;</span>
    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">SeqDataLoader</span><span class="p">(</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">vocab</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

<span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">512</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RNNModel_Embedding</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_word</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate new words following the `prefix`.</span>
<span class="sd">    Defined in :numref:`sec_rnn_scratch`&quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">prefix</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
    <span class="n">get_input</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">prefix</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>  <span class="c1"># Warm-up period</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_preds</span><span class="p">):</span>  <span class="c1"># Predict `num_preds` steps</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">word_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">word_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">word</span> <span class="o">==</span> <span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">:</span>  <span class="c1"># 跳过未知单词</span>
            <span class="k">continue</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>  <span class="c1"># 如果预测的单词以空格结尾，则停止</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
              <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a model (defined in Chapter 8).</span>

<span class="sd">    Defined in :numref:`sec_rnn_scratch`&quot;&quot;&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;perplexity&#39;</span><span class="p">,</span>
                            <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>
    <span class="c1"># Initialize</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">updater</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">predict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">prefix</span><span class="p">:</span> <span class="n">predict_word</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="c1"># Train and predict</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">ppl</span><span class="p">,</span> <span class="n">speed</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">train_epoch_ch8</span><span class="p">(</span>
            <span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">))</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">ppl</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;perplexity </span><span class="si">{</span><span class="n">ppl</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">speed</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> tokens/sec on </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;traveller&#39;</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 14706.3 tokens/sec on cuda:0
tim&lt;unk&gt;&lt;unk&gt;t&lt;unk&gt;av&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;andafainterfaintertomorrowthelaboratoryseemedseemedtofalltofallawayfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfromfrom
t&lt;unk&gt;av&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;&lt;unk&gt;andthentheothersoftsoftsoftsofthairlessandyetandyetasitasitasifitifitifitifitifitifitifitifitifitifitifitifitifitifitifitifit
</code></pre></div>
<p><img alt="svg" src="../output_47_1.svg" /></p>
<h3 id="923">练习 9.2.3<a class="headerlink" href="#923" title="Permanent link">⚓︎</a></h3>
<p>在给定隐藏层维度的情况下，比较门控循环单元、长短期记忆网络和常规循环神经网络的计算成本。要特别注意训练和推断成本。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;将隐藏层维度统一设置为256</p>
<div class="highlight"><pre><span></span><code><span class="c1"># [迭代周期，隐藏单元数，批量大小，小批量数据时间步数，学习率]</span>
<span class="n">num_epochs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># RNN</span>
<span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">rnn_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>

<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">rnn</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Timer: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.3, 389218.2 tokens/sec on cuda:0
time traveller smiled round fore is that is just where hrong the
traveller aboek the permeo saing tras ixins of thitence tim
Timer: 16.08
</code></pre></div>
<p><img alt="svg" src="../output_52_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="c1"># GRU</span>
<span class="n">gru_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">gru</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">gru_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">gru</span> <span class="o">=</span> <span class="n">gru</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>

<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">gru</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Timer: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 358070.8 tokens/sec on cuda:0
time traveller came back andfilby s anecdote collapsedthe thing 
traveller came back andfilby s anecdote collapsedthe thing 
Timer: 16.96
</code></pre></div>
<p><img alt="svg" src="../output_53_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="c1"># LSTM</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
<span class="n">lstm</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">lstm</span> <span class="o">=</span> <span class="n">lstm</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>

<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Timer: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.1, 331550.9 tokens/sec on cuda:0
time traveller proceeded anyreal body must have extension in fou
traveller came back andfilby s anecdote collapsedthe thing 
Timer: 18.11
</code></pre></div>
<p><img alt="svg" src="../output_54_1.svg" /></p>
<p>&emsp;&emsp;可以看到结构最简单的RNN所需计算成本最低，运行时间最短。GRU在RNN基础上增加了更新门和重置门两个门控单元，结构复杂，参数量也有所增加，所需的计算成本要大于RNN，运行时间也更长，但困惑度有随之降低，模型准确度更高。而LSTM内含输入门、输出门以及遗忘门3个门，结构进一步复杂化，计算成本也是三个模型中最高的。</p>
<h3 id="924">练习 9.2.4<a class="headerlink" href="#924" title="Permanent link">⚓︎</a></h3>
<p>既然候选记忆元通过使用<span class="arithmatex">\(\tanh\)</span>函数来确保值范围在<span class="arithmatex">\((-1,1)\)</span>之间，那么为什么隐状态需要再次使用<span class="arithmatex">\(\tanh\)</span>函数来确保输出值范围在<span class="arithmatex">\((-1,1)\)</span>之间呢？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在整个LSTM计算中，候选记忆元<span class="arithmatex">\(\tilde{C}_t\)</span>的计算公式如下：
<span class="arithmatex">\(<span class="arithmatex">\(\tilde{C}_t=tanh(X_tW_{xc}+H_{t-1}W_{hc}+b_c)\)</span>\)</span>
&emsp;&emsp;此时<span class="arithmatex">\(\tanh\)</span>为激活函数，确保<span class="arithmatex">\(\tilde{C}_t\)</span>的值域在<span class="arithmatex">\((-1,1)\)</span>之间。
&emsp;&emsp;而在计算记忆元<span class="arithmatex">\(C_t\)</span>时，存在输入门和遗忘门对记忆元的值进行影响，具体计算公式如下：
<span class="arithmatex">\(<span class="arithmatex">\(C_t=F_t \odot C_{t-1}+I_t \odot \tilde{C}_t\)</span>\)</span>
&emsp;&emsp;上述公式中，输入门和遗忘门的值域为<span class="arithmatex">\((0,1)\)</span>，因此当<span class="arithmatex">\(F_t,I_t\)</span>的值均为<span class="arithmatex">\(1\)</span>，且<span class="arithmatex">\(C_{t-1},\tilde{C}_t\)</span>的值也均为<span class="arithmatex">\(1\)</span>时，整个记忆元的最终输出结果为<span class="arithmatex">\(2\)</span>。此时对于整个隐状态而言，由于输出门的值域也为<span class="arithmatex">\((0,1)\)</span>，因此隐状态值很有可能超过<span class="arithmatex">\(1\)</span>，因此需要对记忆元通过<span class="arithmatex">\(\tanh\)</span>函数来进行约束取值范围，以此确保输出值范围在<span class="arithmatex">\((-1,1)\)</span>之间。</p>
<h3 id="925">练习 9.2.5<a class="headerlink" href="#925" title="Permanent link">⚓︎</a></h3>
<p>实现一个能够基于时间序列进行预测而不是基于字符序列进行预测的长短期记忆网络模型。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;这里使用<a href="https://zh.d2l.ai/chapter_recurrent-neural-networks/sequence.html#id11">8.1.序列模型</a>中的序列数据</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">T</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># 总共产生1000个点</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.01</span> <span class="o">*</span> <span class="n">time</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="p">(</span><span class="n">T</span><span class="p">,))</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</code></pre></div>
<p><img alt="svg" src="../output_62_0.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">tau</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span> <span class="o">-</span> <span class="n">tau</span><span class="p">,</span> <span class="n">tau</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tau</span><span class="p">):</span>
    <span class="n">features</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">T</span> <span class="o">-</span> <span class="n">tau</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">tau</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">batch_size</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">600</span>
<span class="c1"># 只有前n_train个样本用于训练</span>
<span class="n">train_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">((</span><span class="n">features</span><span class="p">[:</span><span class="n">n_train</span><span class="p">],</span> <span class="n">labels</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]),</span>
                            <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lstm_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">input_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>LSTM(
  (lstm): LSTM(4, 200)
  (linear): Linear(in_features=200, out_features=1, bias=True)
)
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch [</span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">], Loss: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Epoch [1/50], Loss: 0.0619
Epoch [2/50], Loss: 0.0811
Epoch [3/50], Loss: 0.0292
Epoch [4/50], Loss: 0.0745
Epoch [5/50], Loss: 0.0158
Epoch [6/50], Loss: 0.0509
Epoch [7/50], Loss: 0.0541
Epoch [8/50], Loss: 0.0551
Epoch [9/50], Loss: 0.0285
Epoch [10/50], Loss: 0.0694
Epoch [11/50], Loss: 0.0379
Epoch [12/50], Loss: 0.0965
Epoch [13/50], Loss: 0.0415
Epoch [14/50], Loss: 0.0442
Epoch [15/50], Loss: 0.0511
Epoch [16/50], Loss: 0.0339
Epoch [17/50], Loss: 0.0150
Epoch [18/50], Loss: 0.0351
Epoch [19/50], Loss: 0.0383
Epoch [20/50], Loss: 0.0879
Epoch [21/50], Loss: 0.0119
Epoch [22/50], Loss: 0.0794
Epoch [23/50], Loss: 0.0614
Epoch [24/50], Loss: 0.0757
Epoch [25/50], Loss: 0.0614
Epoch [26/50], Loss: 0.0382
Epoch [27/50], Loss: 0.0663
Epoch [28/50], Loss: 0.0411
Epoch [29/50], Loss: 0.0671
Epoch [30/50], Loss: 0.0249
Epoch [31/50], Loss: 0.0390
Epoch [32/50], Loss: 0.0181
Epoch [33/50], Loss: 0.0387
Epoch [34/50], Loss: 0.0564
Epoch [35/50], Loss: 0.0607
Epoch [36/50], Loss: 0.1232
Epoch [37/50], Loss: 0.0568
Epoch [38/50], Loss: 0.0555
Epoch [39/50], Loss: 0.0244
Epoch [40/50], Loss: 0.0494
Epoch [41/50], Loss: 0.0449
Epoch [42/50], Loss: 0.0307
Epoch [43/50], Loss: 0.0902
Epoch [44/50], Loss: 0.0928
Epoch [45/50], Loss: 0.0574
Epoch [46/50], Loss: 0.0590
Epoch [47/50], Loss: 0.0259
Epoch [48/50], Loss: 0.0387
Epoch [49/50], Loss: 0.0773
Epoch [50/50], Loss: 0.0299
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">onestep_preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">time</span><span class="p">,</span> <span class="n">time</span><span class="p">[</span><span class="n">tau</span><span class="p">:]],</span>
         <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">onestep_preds</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()],</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span>
         <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;1-step preds&#39;</span><span class="p">],</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>
         <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</code></pre></div>
<p><img alt="svg" src="../output_69_0.svg" /></p>
<h2 id="93">9.3 深度循环神经网络<a class="headerlink" href="#93" title="Permanent link">⚓︎</a></h2>
<h3 id="931">练习 9.3.1<a class="headerlink" href="#931" title="Permanent link">⚓︎</a></h3>
<p>基于我们在8.5节中讨论的单层实现，尝试从零开始实现两层循环神经网络。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义训练数据</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># 初始化模型参数</span>
<span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">num_inputs</span> <span class="o">=</span> <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">vocab_size</span>

    <span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>

    <span class="c1"># 第一层RNN参数</span>
    <span class="n">W_xh1</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="n">W_hh1</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="n">b_h1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 第二层RNN参数</span>
    <span class="n">W_hh2</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
    <span class="n">b_h2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 输出层参数</span>
    <span class="n">W_hq</span> <span class="o">=</span> <span class="n">normal</span><span class="p">((</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">))</span>
    <span class="n">b_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_outputs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># 附加梯度</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">W_xh1</span><span class="p">,</span> <span class="n">W_hh1</span><span class="p">,</span> <span class="n">b_h1</span><span class="p">,</span> <span class="n">W_hh2</span><span class="p">,</span> <span class="n">b_h2</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">init_rnn_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="c1"># 返回初始化的双层RNN状态</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</code></pre></div>
<p>&emsp;&emsp;定义一个双层RNN网络</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="c1"># inputs的形状：(时间步数量，批量大小，词表大小)</span>
    <span class="n">W_xh1</span><span class="p">,</span> <span class="n">W_hh1</span><span class="p">,</span> <span class="n">b_h1</span><span class="p">,</span> <span class="n">W_hh2</span><span class="p">,</span> <span class="n">b_h2</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">,</span> <span class="n">b_q</span> <span class="o">=</span> <span class="n">params</span>
    <span class="n">H1</span><span class="p">,</span> <span class="n">H2</span> <span class="o">=</span> <span class="n">state</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># X的形状：(批量大小，词表大小)</span>
    <span class="k">for</span> <span class="n">X</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
        <span class="n">H1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W_xh1</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="n">W_hh1</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_h1</span><span class="p">)</span>
        <span class="n">H2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="n">W_hh2</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_h2</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">H2</span><span class="p">,</span> <span class="n">W_hq</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_q</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="n">H2</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModelScratch</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">(),</span> <span class="n">get_params</span><span class="p">,</span>
                      <span class="n">init_rnn_state</span><span class="p">,</span> <span class="n">rnn</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 96257.3 tokens/sec on cuda:0
time traveller for so it will be convenient to speak of himwas e
traveller with a slight accession ofcheerfulness really thi
</code></pre></div>
<p><img alt="svg" src="../output_79_1.svg" /></p>
<h3 id="932">练习 9.3.2<a class="headerlink" href="#932" title="Permanent link">⚓︎</a></h3>
<p>在本节训练模型中，比较使用门控循环单元替换长短期记忆网络后模型的精确度和训练速度。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">num_inputs</span> <span class="o">=</span> <span class="n">vocab_size</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="o">*</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;LSTM_Timer: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 165471.8 tokens/sec on cuda:0
time traveller for so it will be convenient to speak of himwas e
traveller with a slight accession ofcheerfulness really thi
LSTM_Timer: 31.35
</code></pre></div>
<p><img alt="svg" src="../output_84_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">gru_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">model_gru</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">gru_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">model_gru</span> <span class="o">=</span> <span class="n">model_gru</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
<span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model_gru</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="o">*</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;GRU_Timer: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">time</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 186493.1 tokens/sec on cuda:0
time travelleryou can show black is white by argument said filby
travelleryou can show black is white by argument said filby
GRU_Timer: 29.00
</code></pre></div>
<p><img alt="svg" src="../output_86_1.svg" /></p>
<p>&emsp;&emsp;对比双层GRU与双层LSTM的结果可以发现，将LSTM替换为GRU后模型的训练速度有所提高，因为相较于LSTM，GRU只有两个门，具有更少的参数量，因此训练速度更快。精确度方面，由于文本量限制，二者都在该文本上达到了1.0的困惑度，并未出现明显差别。</p>
<h3 id="933">练习 9.3.3<a class="headerlink" href="#933" title="Permanent link">⚓︎</a></h3>
<p>如果增加训练数据，能够将困惑度降到多低？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;这里将该作者的另一篇文章《The War of the Worlds》与《The Time Machine》进行混合，将增加后的文本作为训练数据。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">re</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">read_Mix</span><span class="p">():</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;../../notebooks/data/Mix_data.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^A-Za-z]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">load_corpus_world</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="n">read_Mix</span><span class="p">()</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="s1">&#39;char&#39;</span><span class="p">)</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SeqDataLoader</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">use_random_iter</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">seq_data_iter_random</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">seq_data_iter_sequential</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus_world</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_mix_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">SeqDataLoader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">vocab</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_mix_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

<span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">2</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_ch8</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="o">*</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>perplexity 1.0, 168904.0 tokens/sec on cuda:0
time traveller for so it will be convenient to speak of himwas e
travelleryou can show black is white by argument said filby
</code></pre></div>
<p><img alt="svg" src="../output_95_1.svg" /></p>
<p>&emsp;&emsp;可以看到，增加数据后，困惑度仍可以降低到1</p>
<h3 id="934">练习 9.3.4<a class="headerlink" href="#934" title="Permanent link">⚓︎</a></h3>
<p>在为文本建模时，是否可以将不同作者的源数据合并？有何优劣呢？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在为文本建模时，将不同作者的源数据合并是可以的，但需要考虑一些因素。<br />
- 优点：
    - 增加训练数据量：将不同作者的源数据合并，可以增加训练数据量，从而更好地训练模型。<br />
    - 提高模型泛化能力：不同作者的风格、语言等可能不同，将这些数据合并可以让模型更好地学习到不同的文本特征，提高模型的泛化能力。  </p>
<ul>
<li>缺点：<ul>
<li>可能影响模型训练效果：合并不同作者的数据，可能会引入更多的噪音，使得模型更难学习到有用的信息，从而影响训练效果。  </li>
<li>可能会引入偏见：如果不同作者的数据不平衡，比如某一位作者的数据量比其他作者多很多，那么训练出来的模型可能会对该作者的文本表现更好，从而引入偏见。</li>
</ul>
</li>
</ul>
<p>&emsp;&emsp;综上所述，将不同作者的源数据合并在一起是可以的，但需要在合并前考虑好数据的平衡性和质量，并对数据进行适当的预处理，以确保训练出来的模型具有较好的泛化能力和稳定性。</p>
<h2 id="94">9.4 双向循环神经网络<a class="headerlink" href="#94" title="Permanent link">⚓︎</a></h2>
<h3 id="941">练习 9.4.1<a class="headerlink" href="#941" title="Permanent link">⚓︎</a></h3>
<p>如果不同方向使用不同数量的隐藏单位，<span class="arithmatex">\(\mathbf{H_t}\)</span>的形状会发生怎样的变化？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在双向循环神经网络中，最终隐藏状态<span class="arithmatex">\(H_t\)</span>的维度由前向循环神经网络和反向循环神经网络中的隐藏层进行Concat得来，而通常前向和反向循环神经网络均选用相同的隐藏层数量，即<span class="arithmatex">\(\overrightarrow{H_t}=\overleftarrow{H_t}\)</span>，因此直接进行翻倍，即可获得最终形状<span class="arithmatex">\(H_t=2 * \overrightarrow{H_t} = 2 * \overleftarrow{H_t}\)</span>。<br />
&emsp;&emsp;而当不同方向使用不同数量的隐藏单位时，此时前向和反向的隐藏单元数量不同，<span class="arithmatex">\(H_t\)</span>的维度并不等于前向或反向循环神经网络中隐藏层数量的<span class="arithmatex">\(2\)</span>倍，此时需要将前向和反向的隐藏层维度拼接相加，获得最终<span class="arithmatex">\(H_t\)</span>的维度，即<span class="arithmatex">\(H_t = \overrightarrow{H_t} + \overleftarrow{H_t}\)</span></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 定义一个隐藏单元数量不同的BiLSTM</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">BiLSTM</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_forward</span><span class="p">,</span> <span class="n">hidden_size_backward</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BiLSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 开启batch_size=True后，输出的形状由[seq_length, batch_size, feature_dim] -&gt; [batch_size, seq_length, feature_dim]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_forward</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_forward</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_backward</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_backward</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_lengths</span><span class="p">):</span>
        <span class="c1"># 前向部分</span>
        <span class="c1"># pack_padded_sequence() 负责将可变长度序列进行打包</span>
        <span class="c1"># pad_packed_sequence() 负责将填充的序列解包，以便在后续计算时去掉无用的填充部分</span>
        <span class="n">packed_x_forward</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">packed_h_forward</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_forward</span><span class="p">(</span><span class="n">packed_x_forward</span><span class="p">)</span>
        <span class="n">h_forward</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">packed_h_forward</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># 反向部分</span>
        <span class="n">packed_x_backward</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">x_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">packed_h_backward</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_backward</span><span class="p">(</span><span class="n">packed_x_backward</span><span class="p">)</span>
        <span class="n">h_backward</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">packed_h_backward</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">h_backward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">h_backward</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Concat</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">h_forward</span><span class="p">,</span> <span class="n">h_backward</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">h</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">seq_length</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hidden_size_forward</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hidden_size_backward</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1"># 构造输入序列</span>
<span class="n">x_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">x_lengths</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">input_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_sequence</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BiLSTM</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size_forward</span><span class="p">,</span> <span class="n">hidden_size_backward</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_lengths</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">h</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>BiLSTM(
  (lstm_forward): LSTM(2, 10, batch_first=True)
  (lstm_backward): LSTM(2, 8, batch_first=True)
)
torch.Size([3, 5, 18])
</code></pre></div>
<h3 id="942">练习 9.4.2<a class="headerlink" href="#942" title="Permanent link">⚓︎</a></h3>
<p>设计一个具有多个隐藏层的双向循环神经网络。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>

<span class="c1"># 加载数据</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
<span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_time_machine</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>

<span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">num_inputs</span> <span class="o">=</span> <span class="n">vocab_size</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">RNNModel</span><span class="p">(</span><span class="n">lstm_layer</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>RNNModel(
  (rnn): LSTM(28, 256, num_layers=4, bidirectional=True)
  (linear): Linear(in_features=512, out_features=28, bias=True)
)
</code></pre></div>
<p>&emsp;&emsp;在上述模型中，隐藏层的数量被设置为4，实现了一个四层的双向循环神经网络</p>
<h3 id="943">练习 9.4.3<a class="headerlink" href="#943" title="Permanent link">⚓︎</a></h3>
<p>在自然语言中一词多义很常见。例如，“bank”一词在不同的上下文“i went to the bank to deposit cash”和“i went to the bank to sit down”中有不同的含义。如何设计一个神经网络模型，使其在给定上下文序列和单词的情况下，返回该单词在此上下文中的向量表示？哪种类型的神经网络架构更适合处理一词多义？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;处理一词多义的常见方法是结合上下文信息来对该位置的单词意思进行确认，例如在神经网络中，可以采用双向循环神经网络模型或者Transformer，将上下文中的单词序列映射到单词的向量表示。这些模型可以学到上下文中单词的复杂交互，以此实现根据上下文内容来动态生成单词的对应向量表示。<br />
&emsp;&emsp;这些上下文感知的双向模型能够更好地捕捉单词在不同上下文中的含义。例如，在双向LSTM中，每个单词的向量表示取决于整个上下文序列，因此可以更好地捕捉单词在上下文中的含义。</p>
<h2 id="95">9.5 机器翻译与数据集<a class="headerlink" href="#95" title="Permanent link">⚓︎</a></h2>
<h3 id="951">练习 9.5.1<a class="headerlink" href="#951" title="Permanent link">⚓︎</a></h3>
<p>在<code>load_data_nmt</code>函数中尝试不同的<code>num_examples</code>参数值。这对源语言和目标语言的词表大小有何影响？</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="c1">#@save</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">DATA_HUB</span><span class="p">[</span><span class="s1">&#39;fra-eng&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">DATA_URL</span> <span class="o">+</span> <span class="s1">&#39;fra-eng.zip&#39;</span><span class="p">,</span>
                           <span class="s1">&#39;94646ad1522d915e7b0f9296181140edcf86a4f5&#39;</span><span class="p">)</span>

<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">read_data_nmt</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;载入“英语－法语”数据集&quot;&quot;&quot;</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">download_extract</span><span class="p">(</span><span class="s1">&#39;fra-eng&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;fra.txt&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span>
             <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;返回翻译数据集的迭代器和词表&quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">preprocess_nmt</span><span class="p">(</span><span class="n">read_data_nmt</span><span class="p">())</span>
    <span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tokenize_nmt</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)</span>
    <span class="n">src_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">])</span>
    <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Vocab</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">reserved_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;eos&gt;&#39;</span><span class="p">])</span>
    <span class="n">src_array</span><span class="p">,</span> <span class="n">src_valid_len</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">build_array_nmt</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">tgt_array</span><span class="p">,</span> <span class="n">tgt_valid_len</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">build_array_nmt</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
    <span class="n">data_arrays</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_array</span><span class="p">,</span> <span class="n">src_valid_len</span><span class="p">,</span> <span class="n">tgt_array</span><span class="p">,</span> <span class="n">tgt_valid_len</span><span class="p">)</span>
    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_array</span><span class="p">(</span><span class="n">data_arrays</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">num_examples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">]</span>
<span class="n">src</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tgt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">num_examples</span><span class="p">:</span>
    <span class="n">train_iter_2</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">src</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">))</span>
    <span class="n">tgt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[40, 69, 102, 130, 159, 184] [40, 67, 107, 125, 163, 201]
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;source&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">width</span><span class="o">=-</span><span class="mi">8</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;edge&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;target&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;num_examples&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="svg" src="../output_118_0.svg" /></p>
<p>&emsp;&emsp;在tokenize_nmt函数中，num_examples主要用于规定进行词元化的序列的长度，因此num_examples越大，所获得的词表越大。</p>
<h3 id="952">练习 9.5.2<a class="headerlink" href="#952" title="Permanent link">⚓︎</a></h3>
<p>某些语言（例如中文和日语）的文本没有单词边界指示符（例如空格）。对于这种情况，单词级词元化仍然是个好主意吗？为什么？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;以中文为例，中文中不存在类似空格这样的单词边界指示符，但是中文可采用基于词典、基于规则或者基于统计的分词方法，针对中文文本进行分词，以此实现中文的词元化处理。<br />
&emsp;&emsp;这种方法可以将中文文本划分为单独的词语，以实现对中文的精确处理。例如在词义消歧时，单词级的中文分词可以帮助我们更准确的确定词语的上下文，以此来确定歧义词的准确意义。并且在信息检索任务中，很多检索都是基于关键词展开的，对中文进行单词级词元化，可以便于在索引中进行文本匹配。因此，即便中文和日语这些语言中没有单词边界指示符，但在进行自然语言处理时，单词级的词元化仍是非常关键的一步。</p>
<h2 id="96-">9.6 编码器-解码器架构<a class="headerlink" href="#96-" title="Permanent link">⚓︎</a></h2>
<h3 id="961">练习 9.6.1<a class="headerlink" href="#961" title="Permanent link">⚓︎</a></h3>
<p>假设我们使用神经网络来实现“编码器－解码器”架构，那么编码器和解码器必须是同一类型的神经网络吗？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;不一定。虽然编码器和解码器通常是相同类型的神经网络，但它们可以是不同的网络架构。事实上，有些最先进的神经网络模型在编码器和解码器之间使用了不同的架构。例如，使用CNN作为编码器，然后使用RNN或Transformer作为解码器的架构在机器翻译任务中很常见。<br />
&emsp;&emsp;另外，编码器和解码器也可以在不同的领域应用不同类型的神经网络。例如，在图像到文本任务中，可以使用CNN作为编码器，将图像编码为特征向量，然后使用RNN或Transformer作为解码器生成相应的自然语言描述。因此，编码器和解码器可以是同一类型的神经网络，也可以是不同类型的神经网络，它实质上只是一种抽象的结构，该结构可以适用于多种神经网络，具体选择需要取决于具体的任务需求和设计思路。</p>
<h3 id="962">练习 9.6.2<a class="headerlink" href="#962" title="Permanent link">⚓︎</a></h3>
<p>除了机器翻译，还有其它可以适用于”编码器－解码器“架构的应用吗？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;目前，“编码器-解码器”结构已经在多种任务中取得了优秀的研究成果，并非仅仅局限于机器翻译一类任务中。例如语音识别任务，可以采用编码器接受音频信号，并将其编码为特征向量，再由解码器将其转化为文本内容；在图像生成任务中，编码器可以将输入的图像或文本内容进行编码，再由解码器根据编码的特征向量生成对应的图像；此外还有文本生成任务，编码器将输入文本进行编码后，再由解码器使用这些编码后的特征向量进行解码，生成与原始文本内容相似的文本。<br />
&emsp;&emsp;实际上，“编码器-解码器”是一个通用的抽象架构，其基本思想是将输入数据编码为一个便于神经网络学习和理解的中间表示，再由解码器将中间表示转换为所需要的输出。这种架构可以根据具体需求适用于不同的实际场景中。</p>
<h2 id="97-seq2seq">9.7 序列到序列的学习（seq2seq）<a class="headerlink" href="#97-seq2seq" title="Permanent link">⚓︎</a></h2>
<h3 id="971">练习 9.7.1<a class="headerlink" href="#971" title="Permanent link">⚓︎</a></h3>
<p>试着通过调整超参数来改善翻译效果。</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;尝试将隐藏层和Embedding层维度修改为256，同时将batch_size修改为256，学习率降低至0.001</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 广播context，使其具有与X相同的num_steps</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># output的形状:(batch_size,num_steps,vocab_size)</span>
        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>loss 0.017, 24766.6 tokens/sec on cuda:0
</code></pre></div>
<p><img alt="svg" src="../output_136_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s2">&quot;i lost .&quot;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_seq2seq</span><span class="p">(</span>
        <span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu </span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>go . =&gt; va !, bleu 1.000
i lost . =&gt; j&#39;ai perdu ., bleu 1.000
he&#39;s calm . =&gt; il est mouillé mouillé ., bleu 0.548
i&#39;m home . =&gt; je suis chez &lt;unk&gt; moi qui ai ai &lt;unk&gt; gagné, bleu 0.434
</code></pre></div>
<h3 id="972">练习 9.7.2<a class="headerlink" href="#972" title="Permanent link">⚓︎</a></h3>
<p>重新运行实验并在计算损失时不使用遮蔽，可以观察到什么结果？为什么会有这个结果？</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MaskedSoftmaxCELoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;带遮蔽的softmax交叉熵损失函数&quot;&quot;&quot;</span>
    <span class="c1"># pred的形状：(batch_size,num_steps,vocab_size)</span>
    <span class="c1"># label的形状：(batch_size,num_steps)</span>
    <span class="c1"># valid_len的形状：(batch_size,)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="c1"># weights = sequence_mask(weights, valid_len)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span>
        <span class="n">unweighted_loss</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MaskedSoftmaxCELoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
            <span class="n">pred</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">weighted_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">unweighted_loss</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weighted_loss</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">loss</span> <span class="o">=</span> <span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>
<span class="n">loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
     <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([2.3026, 2.3026, 2.3026])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">loss_s</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>
<span class="n">loss_s</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
     <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([2.3026, 1.1513, 0.0000])
</code></pre></div>
<p>&emsp;&emsp;观察上面两组值，我们可以发现，如果计算损失时不使用遮蔽，将会输出三个相同的序列损失值，而非出现第一个序列的损失为第二个序列的两倍，第三个序列的损失为零。<br />
&emsp;&emsp;出现这种情况的原因在于，注释掉遮蔽函数 <strong>sequence_mask()</strong> 后，无法再根据有效长度 <strong>valid_len</strong> 对权重 <strong>weights</strong> 进行遮蔽操作，使得所有位置的权重都将参与计算，而非仅限于有效长度内的位置。这可能会导致在计算损失时，对序列中无效的部分产生误差，影响模型的训练效果。</p>
<h3 id="973">练习 9.7.3<a class="headerlink" href="#973" title="Permanent link">⚓︎</a></h3>
<p>如果编码器和解码器的层数或者隐藏单元数不同，那么如何初始化解码器的隐状态？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;如果编码器和解码器的层数或隐藏单元数不同，可以采取以下方法来初始化解码器的隐状态：
- 使用编码器隐藏状态的线性变换：如果编码器和解码器的隐藏单元数不同，可以通过线性变换将编码器隐藏状态的维度调整为解码器隐藏状态所需的维度。可以使用全连接层或线性映射来实现这个变换。
- 使用零向量进行初始化：如果编码器和解码器的隐藏单元数差异较大，或者无法进行有效的维度变换，可以使用零向量来初始化解码器的隐状态。这种方法可能会导致一开始解码器的性能较差，但随着训练的进行，解码器可以逐渐学习到适应目标任务的隐状态表示。</p>
<p>&emsp;&emsp;下面是引入全连接层进行修改的示例：</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens_enc</span><span class="p">,</span> <span class="n">num_hiddens_dec</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens_dec</span><span class="p">,</span> <span class="n">num_hiddens_dec</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens_enc</span><span class="p">,</span> <span class="n">num_hiddens_dec</span><span class="p">)</span>  <span class="c1"># 添加全连接层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens_dec</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># 使用全连接层调整隐藏状态的维度</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size, num_steps, embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 广播context，使其具有与X相同的num_steps</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># output的形状: (batch_size, num_steps, vocab_size)</span>
        <span class="c1"># state的形状: (num_layers, batch_size, num_hiddens_dec)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([7, 4, 16])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens_enc</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_hiddens_dec</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>(torch.Size([4, 7, 10]), torch.Size([2, 4, 10]))
</code></pre></div>
<h3 id="974">练习 9.7.4<a class="headerlink" href="#974" title="Permanent link">⚓︎</a></h3>
<p>在训练中，如果用前一时间步的预测输入到解码器来代替强制教学，对性能有何影响？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在训练中，这种采用前一时间步的预测作为解码器输入的方法属于 <strong>自回归</strong> 方法，这种自回归的方法，对于性能会产生以下影响：
- 训练速度变慢：使用自回归训练方式会导致解码器逐步生成输出序列，而不是一次性使用整个目标序列。这会增加训练的时间，因为需要进行逐步的预测和反向传播。
- 累积误差：由于解码器的输入是前一时间步的预测结果，而不是真实目标序列，错误可能会逐步累积并扩大。这可能导致生成的序列与真实目标序列之间存在较大的差异。
- 降低训练稳定性：自回归训练方式可能会导致训练过程更不稳定，特别是在序列较长、任务复杂的情况下。错误的累积和误差传播可能会导致训练困难，并且模型可能会在某些时间步骤上产生不合理的输出。
- 降低性能：自回归训练方式可能会降低模型在测试集或实际应用中的性能。由于解码器在训练期间没有接触到真实的目标序列，它可能无法很好地适应真实数据的分布和模式。</p>
<p>&emsp;&emsp;即便如此，目前自回归方法仍被广泛应用于序列生成任务中，通过引入如注意力机制等改进方法后，模型可以有效提升性能，生成拟合度更好的序列。</p>
<div class="highlight"><pre><span></span><code><span class="c1">#@save</span>
<span class="k">def</span> <span class="nf">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;训练序列到序列模型&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">xavier_init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">_flat_weights_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;weight&quot;</span> <span class="ow">in</span> <span class="n">param</span><span class="p">:</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>

    <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">xavier_init_weights</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">MaskedSoftmaxCELoss</span><span class="p">()</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span>
                     <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">timer</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 训练损失总和，词元数量</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
            <span class="n">bos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">tgt_vocab</span><span class="p">[</span><span class="s1">&#39;&lt;bos&gt;&#39;</span><span class="p">]]</span> <span class="o">*</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                          <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="c1"># dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学</span>

            <span class="n">dec_input</span> <span class="o">=</span> <span class="n">bos</span>
            <span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">output_seq</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">Y_hat</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">,</span> <span class="n">X_valid_len</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>    <span class="c1"># 将&lt;bos&gt;输入，获得预测结果</span>
                <span class="n">dec_input</span> <span class="o">=</span> <span class="n">Y_hat</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 使用模型预测的结果作为下一个时间步的输入</span>
                <span class="n">output_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">)</span>
            <span class="n">output_seq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output_seq</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>       <span class="c1"># 拼接所有预测结果，获得完整序列</span>
            <span class="n">Y_hat</span> <span class="o">=</span> <span class="n">output_seq</span>

            <span class="c1"># Y_hat, _ = net(X, dec_input, X_valid_len)</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">Y_hat</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Y_valid_len</span><span class="p">)</span>
            <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>      <span class="c1"># 损失函数的标量进行“反向传播”</span>
            <span class="n">d2l</span><span class="o">.</span><span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">Y_valid_len</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">num_tokens</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">],))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;loss </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> &#39;</span>
        <span class="sa">f</span><span class="s1">&#39;tokens/sec on </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 广播context，使其具有与X相同的num_steps</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># output的形状:(batch_size,num_steps,vocab_size)</span>
        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>loss 0.064, 9132.0 tokens/sec on cuda:0
</code></pre></div>
<p><img alt="svg" src="../output_155_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s2">&quot;i lost .&quot;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_seq2seq</span><span class="p">(</span>
        <span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu </span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>go . =&gt; va va ne va ne trouve trouve trouve trouve trouve, bleu 0.000
i lost . =&gt; j&#39;ai je je tu tu tu tu tu tu tu, bleu 0.000
he&#39;s calm . =&gt; c&#39;est comme comme comme comme comme comme comme comme comme, bleu 0.000
i&#39;m home . =&gt; je je je je je je je je je je, bleu 0.000
</code></pre></div>
<h3 id="975">练习 9.7.5<a class="headerlink" href="#975" title="Permanent link">⚓︎</a></h3>
<p>用长短期记忆网络替换门控循环单元重新运行实验。</p>
<p><strong>解答：</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1">#@save</span>
<span class="k">class</span> <span class="nc">Seq2SeqEncoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Encoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;用于序列到序列学习的循环神经网络编码器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># 嵌入层</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># 在循环神经网络模型中，第一个轴对应于时间步</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 如果未提及状态，则默认为0</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># output的形状:(num_steps,batch_size,num_hiddens)</span>
        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([7, 4, 16])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>torch.Size([2, 4, 16])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">d2l</span><span class="o">.</span><span class="n">Decoder</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;用于序列到序列学习的循环神经网络解码器&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 广播context，使其具有与X相同的num_steps</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>    <span class="c1"># 在LSTM中，相较于隐藏状态，记忆元中存储了更多信息，有利于捕捉长期依赖关系，因此这里提取记忆元而非隐藏状态</span>
        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># output的形状:(batch_size,num_steps,vocab_size)</span>
        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">embed_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                         <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">decoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span> <span class="o">=</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>

<span class="n">train_iter</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">load_data_nmt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Seq2SeqEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">Seq2SeqDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tgt_vocab</span><span class="p">),</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
                        <span class="n">dropout</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">EncoderDecoder</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">)</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">train_seq2seq</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>loss 0.018, 19088.3 tokens/sec on cuda:0
</code></pre></div>
<p><img alt="svg" src="../output_164_1.svg" /></p>
<div class="highlight"><pre><span></span><code><span class="n">engs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;go .&#39;</span><span class="p">,</span> <span class="s2">&quot;i lost .&quot;</span><span class="p">,</span> <span class="s1">&#39;he</span><span class="se">\&#39;</span><span class="s1">s calm .&#39;</span><span class="p">,</span> <span class="s1">&#39;i</span><span class="se">\&#39;</span><span class="s1">m home .&#39;</span><span class="p">]</span>
<span class="n">fras</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;va !&#39;</span><span class="p">,</span> <span class="s1">&#39;j</span><span class="se">\&#39;</span><span class="s1">ai perdu .&#39;</span><span class="p">,</span> <span class="s1">&#39;il est calme .&#39;</span><span class="p">,</span> <span class="s1">&#39;je suis chez moi .&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">eng</span><span class="p">,</span> <span class="n">fra</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">engs</span><span class="p">,</span> <span class="n">fras</span><span class="p">):</span>
    <span class="n">translation</span><span class="p">,</span> <span class="n">attention_weight_seq</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">predict_seq2seq</span><span class="p">(</span>
        <span class="n">net</span><span class="p">,</span> <span class="n">eng</span><span class="p">,</span> <span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">eng</span><span class="si">}</span><span class="s1"> =&gt; </span><span class="si">{</span><span class="n">translation</span><span class="si">}</span><span class="s1">, bleu </span><span class="si">{</span><span class="n">d2l</span><span class="o">.</span><span class="n">bleu</span><span class="p">(</span><span class="n">translation</span><span class="p">,</span><span class="w"> </span><span class="n">fra</span><span class="p">,</span><span class="w"> </span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>go . =&gt; va !, bleu 1.000
i lost . =&gt; j&#39;ai perdu ., bleu 1.000
he&#39;s calm . =&gt; il est calme ., bleu 1.000
i&#39;m home . =&gt; je suis chez moi ., bleu 1.000
</code></pre></div>
<h3 id="976">练习 9.7.6<a class="headerlink" href="#976" title="Permanent link">⚓︎</a></h3>
<p>有没有其他方法来设计解码器的输出层？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;可以在解码器的输出层应用注意力机制，通过计算注意力权重来对编码器的隐藏状态进行加权求和，从而生成输出。在类似机器翻译任务中，这种方法可以将解码器的注意力集中在输入序列的相关部分，有效捕捉重要信息。提高生成的准确性。</p>
<h2 id="98">9.8 束搜索<a class="headerlink" href="#98" title="Permanent link">⚓︎</a></h2>
<h3 id="981">练习 9.8.1<a class="headerlink" href="#981" title="Permanent link">⚓︎</a></h3>
<p>我们可以把穷举搜索看作一种特殊的束搜索吗？为什么？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;穷举与束搜索采用了不同的思路，并不能将其看作是特殊的束搜索。<br />
&emsp;&emsp;在进行穷举时，算法会对解空间中的所有解进行遍历搜索，然后计算出最优结果。因此导致计算量巨大。但是束搜索则是根据设置好的束宽<span class="arithmatex">\(K\)</span>来进行搜索，在每一步选择<span class="arithmatex">\(K\)</span>个最优结果，在保证找到最优解的前提下，尽量减少空间与时间复杂度。实际上，贪心和束搜索都属于启发式算法的一种，而穷举搜索并不包含任何启发式信息，因此不能看作是特殊的束搜搜。</p>
<h3 id="982">练习 9.8.2<a class="headerlink" href="#982" title="Permanent link">⚓︎</a></h3>
<p>在9.7节中的机器翻译问题中应用束搜索。束宽是如何影响预测的速度和结果的？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在机器翻译任务中，虽然应用束搜索可以有效提高预测的准确性，生成更加合理的翻译结果。但是束搜索也会通过束宽来影响模型的预测速度和结果。<br />
&emsp;&emsp;作为控制候选项数量的参数，束宽较小时会减少搜索空间，带来更快的预测速度。而在较大时会保留更多的候选项，虽然可以带来更加准确的结果，但是也会增加计算的复杂性和预测时间。因此在设置束宽时需要权衡预测速度和结果精度，根据实际需求和性能进行调整，以取得满意的翻译结果。</p>
<h3 id="983">练习 9.8.3<a class="headerlink" href="#983" title="Permanent link">⚓︎</a></h3>
<p>在8.5节中，我们基于用户提供的前缀，通过使用语言模型来生成文本。这个例子中使用了哪种搜索策略？可以改进吗？</p>
<p><strong>解答：</strong></p>
<p>&emsp;&emsp;在8.5节中，最后在生成文本时，在每一步预测中，使用 <strong>y.argmax(dim=1)</strong> 选择具有最高概率的字符作为下一个预测字符。这里的选择是基于当前时刻模型的输出概率最大化的策略，而没有考虑其他备选字符,这种搜索算法实质上属于贪心算法。<br />
&emsp;&emsp;可以通过修改策略来生成更具多样性的文本，例如通过束搜索的方式，在每一步选择多个候选字符，并根据概率得分进行排序。最终只保留得分最高的一部分候选字符，然后基于这些候选字符继续生成下一个字符。这种束搜索算法可以提供更好的生成文本质量和连贯性，但会增加计算复杂度。</p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../../ch08/ch08/" class="md-footer__link md-footer__link--prev" aria-label="上一页: 第8章 循环神经网络">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                第8章 循环神经网络
              </div>
            </div>
          </a>
        
        
          
          <a href="../../ch10/ch10/" class="md-footer__link md-footer__link--next" aria-label="下一页: 注意力机制">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                注意力机制
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>