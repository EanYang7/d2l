
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E6%95%99%E7%A8%8B/13-computational-performance/hardware/">
      
      
        <link rel="prev" href="../auto-parallelism/">
      
      
        <link rel="next" href="../hybridize/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Hardware - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#hardware" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Hardware
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../09-recurrent-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../12-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_16" checked>
        
          
          <label class="md-nav__link" for="__nav_2_16" id="__nav_2_16_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_16_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_16">
            <span class="md-nav__icon md-icon"></span>
            13 computational performance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Computational Performance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../async-computation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Asynchronous Computation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../auto-parallelism/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Automatic Parallelism
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Hardware
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Hardware
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computers" class="md-nav__link">
    <span class="md-ellipsis">
      Computers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory" class="md-nav__link">
    <span class="md-ellipsis">
      Memory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#storage" class="md-nav__link">
    <span class="md-ellipsis">
      Storage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Storage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hard-disk-drives" class="md-nav__link">
    <span class="md-ellipsis">
      Hard Disk Drives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solid-state-drives" class="md-nav__link">
    <span class="md-ellipsis">
      Solid State Drives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cloud-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud Storage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cpus" class="md-nav__link">
    <span class="md-ellipsis">
      CPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#microarchitecture" class="md-nav__link">
    <span class="md-ellipsis">
      Microarchitecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectorization" class="md-nav__link">
    <span class="md-ellipsis">
      Vectorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache" class="md-nav__link">
    <span class="md-ellipsis">
      Cache
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpus-and-other-accelerators" class="md-nav__link">
    <span class="md-ellipsis">
      GPUs and other Accelerators
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#networks-and-buses" class="md-nav__link">
    <span class="md-ellipsis">
      Networks and Buses
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#more-latency-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      More Latency Numbers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../hybridize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Compilers and Interpreters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../multiple-gpus-concise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Concise Implementation for Multiple GPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../multiple-gpus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training on Multiple GPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../parameterserver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parameter Servers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch04/ch04/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch05/ch05/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch09/ch09/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#computers" class="md-nav__link">
    <span class="md-ellipsis">
      Computers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory" class="md-nav__link">
    <span class="md-ellipsis">
      Memory
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#storage" class="md-nav__link">
    <span class="md-ellipsis">
      Storage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Storage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hard-disk-drives" class="md-nav__link">
    <span class="md-ellipsis">
      Hard Disk Drives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#solid-state-drives" class="md-nav__link">
    <span class="md-ellipsis">
      Solid State Drives
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cloud-storage" class="md-nav__link">
    <span class="md-ellipsis">
      Cloud Storage
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cpus" class="md-nav__link">
    <span class="md-ellipsis">
      CPUs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CPUs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#microarchitecture" class="md-nav__link">
    <span class="md-ellipsis">
      Microarchitecture
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vectorization" class="md-nav__link">
    <span class="md-ellipsis">
      Vectorization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cache" class="md-nav__link">
    <span class="md-ellipsis">
      Cache
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpus-and-other-accelerators" class="md-nav__link">
    <span class="md-ellipsis">
      GPUs and other Accelerators
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#networks-and-buses" class="md-nav__link">
    <span class="md-ellipsis">
      Networks and Buses
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#more-latency-numbers" class="md-nav__link">
    <span class="md-ellipsis">
      More Latency Numbers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/13-computational-performance/hardware.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/13-computational-performance/hardware.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="hardware">Hardware<a class="headerlink" href="#hardware" title="Permanent link">⚓︎</a></h1>
<p>:label:<code>sec_hardware</code></p>
<p>Building systems with great performance requires a good understanding of the algorithms and models to capture the statistical aspects of the problem. At the same time it is also indispensable to have at least a modicum of knowledge of the underlying hardware. The current section is no substitute for a proper course on hardware and system design. Instead, it might serve as a starting point for understanding why some algorithms are more efficient than others and how to achieve good throughput. A good design can easily make a difference of an order of magnitude and, in turn, this can make the difference between being able to train a network (e.g., in a week) and not at all (in 3 months, thus missing the deadline). 
We will start by looking at computers. Then we will zoom in to look more carefully at CPUs and GPUs. Lastly we zoom out to review how multiple computers are connected in a server center or in the cloud. </p>
<p><img alt="Latency Numbers that every programmer should know." src="../../img/latencynumbers.png" />
:label:<code>fig_latencynumbers</code></p>
<p>Impatient readers may be able to get by with :numref:<code>fig_latencynumbers</code>. It is taken from Colin Scott's <a href="https://people.eecs.berkeley.edu/%7Ercs/research/interactive_latency.html">interactive post</a> that gives a good overview of the progress over the past decade. The original numbers are due to Jeff Dean's <a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/Stanford-DL-Nov-2010.pdf">Stanford talk from 2010</a>.
The discussion below explains some of the rationale for these numbers and how they can guide us in designing algorithms. The discussion below is very high level and cursory. It is clearly <em>no substitute</em> for a proper course but rather just meant to provide enough information for a statistical modeler to make suitable design decisions. For an in-depth overview of computer architecture we refer the reader to :cite:<code>Hennessy.Patterson.2011</code> or a recent course on the subject, such as the one by <a href="http://inst.eecs.berkeley.edu/%7Ecs152/sp19/">Arste Asanovic</a>.</p>
<h2 id="computers">Computers<a class="headerlink" href="#computers" title="Permanent link">⚓︎</a></h2>
<p>Most deep learning researchers and practitioners have access to a computer with a fair amount of memory, computation, some form of an accelerator such as a GPU, or multiples thereof. A computer consists of the following key components:</p>
<ul>
<li>A processor (also referred to as a CPU) that is able to execute the programs we give it (in addition to running an operating system and many other things), typically consisting of 8 or more cores.</li>
<li>Memory (RAM) to store and retrieve the results from computation, such as weight vectors and activations, and training data.</li>
<li>An Ethernet network connection (sometimes multiple) with speeds ranging from 1 GB/s to 100 GB/s. On high end servers more advanced interconnects can be found.</li>
<li>A high speed expansion bus (PCIe) to connect the system to one or more GPUs. Servers have up to 8 accelerators, often connected in an advanced topology, while desktop systems have 1 or 2, depending on the budget of the user and the size of the power supply.</li>
<li>Durable storage, such as a magnetic hard disk drive, a solid state drive, in many cases connected using the PCIe bus. It provides efficient transfer of training data to the system and storage of intermediate checkpoints as needed.</li>
</ul>
<p><img alt="Connectivity of components of a computer." src="../../img/mobo-symbol.svg" />
:label:<code>fig_mobo-symbol</code></p>
<p>As :numref:<code>fig_mobo-symbol</code> indicates, most components (network, GPU, and storage) are connected to the CPU across the PCIe bus. It consists of multiple lanes that are directly attached to the CPU. For instance AMD's Threadripper 3 has 64 PCIe 4.0 lanes, each of which is capable 16 Gbit/s data transfer in both directions. The memory is directly attached to the CPU with a total bandwidth of up to 100 GB/s.</p>
<p>When we run code on a computer we need to shuffle data to the processors (CPUs or GPUs), perform computation, and then move the results off the processor back to RAM and durable storage. Hence, in order to get good performance we need to make sure that this works seamlessly without any one of the systems becoming a major bottleneck. For instance, if we cannot load images quickly enough the processor will not have any work to do. Likewise, if we cannot move matrices quickly enough to the CPU (or GPU), its processing elements will starve. Finally, if we want to synchronize multiple computers across the network, the latter should not slow down computation. One option is to interleave communication and computation. Let's have a look at the various components in more detail.</p>
<h2 id="memory">Memory<a class="headerlink" href="#memory" title="Permanent link">⚓︎</a></h2>
<p>At its most basic memory is used to store data that needs to be readily accessible. At present CPU RAM is typically of the <a href="https://en.wikipedia.org/wiki/DDR4_SDRAM">DDR4</a> variety, offering 20--25 GB/s bandwidth per module. Each module has a 64-bit-wide bus. Typically pairs of memory modules are used to allow for multiple channels. CPUs have between 2 and 4 memory channels, i.e., they have between 4 0GB/s and 100 GB/s peak memory bandwidth. Often there are two banks per channel. For instance AMD's Zen 3 Threadripper has 8 slots.</p>
<p>While these numbers are impressive, indeed, they only tell part of the story. When we want to read a portion from memory we first need to tell the memory module where the information can be found. That is, we first need to send the <em>address</em> to RAM. Once this is accomplished we can choose to read just a single 64 bit record or a long sequence of records. The latter is called <em>burst read</em>. In a nutshell, sending an address to memory and setting up the transfer takes approximately 100 ns (details depend on the specific timing coefficients of the memory chips used), every subsequent transfer takes only 0.2 ns. In short, the first read is 500 times as expensive as subsequent ones! Note that we could perform up to 10,000,000 random reads per second. This suggests that we avoid random memory access as far as possible and use burst reads (and writes) instead.</p>
<p>Matters are a bit more complex when we take into account that we have multiple <em>banks</em>. Each bank can read memory largely independently. This means two things. 
On the one hand, the effective number of random reads is up to 4 times higher, provided that they are spread evenly across memory. It also means that it is still a bad idea to perform random reads since burst reads are 4 times faster, too. On the other hand, due to memory alignment to 64 bit boundaries it is a good idea to align any data structures with the same boundaries. Compilers do this pretty much <a href="https://en.wikipedia.org/wiki/Data_structure_alignment">automatically</a> when the appropriate flags are set. Curious readers are encouraged to review a lecture on DRAMs such as the one by <a href="http://web.cecs.pdx.edu/%7Ezeshan/ece585_lec5.pdf">Zeshan Chishti</a>.</p>
<p>GPU memory is subject to even higher bandwidth requirements since they have many more processing elements than CPUs. By and large there are two options to address them. The first is to make the memory bus significantly wider. For instance, NVIDIA's RTX 2080 Ti has a 352-bit-wide bus. This allows for much more information to be transferred at the same time. Second, GPUs use specific high-performance memory. Consumer-grade devices, such as NVIDIA's RTX and Titan series typically use <a href="https://en.wikipedia.org/wiki/GDDR6_SDRAM">GDDR6</a> chips with over 500 GB/s aggregate bandwidth. An alternative is to use HBM (high bandwidth memory) modules. They use a very different interface and connect directly with GPUs on a dedicated silicon wafer. This makes them very expensive and their use is typically limited to high-end server chips, such as the NVIDIA Volta V100 series of accelerators. Quite unsurprisingly, GPU memory is generally <em>much</em> smaller than CPU memory due to the higher cost of the former. For our purposes, by and large their performance characteristics are similar, just a lot faster. We can safely ignore the details for the purpose of this book. They only matter when tuning GPU kernels for high throughput.</p>
<h2 id="storage">Storage<a class="headerlink" href="#storage" title="Permanent link">⚓︎</a></h2>
<p>We saw that some of the key characteristics of RAM are <em>bandwidth</em> and <em>latency</em>. The same is true for storage devices, just that the differences can be even more extreme.</p>
<h3 id="hard-disk-drives">Hard Disk Drives<a class="headerlink" href="#hard-disk-drives" title="Permanent link">⚓︎</a></h3>
<p><em>Hard disk drives</em> (HDDs) have been in use for over half a century. In a nutshell they contain a number of spinning platters with heads that can be positioned to read or write at any given track. High-end disks hold up to 16 TB on 9 platters. One of the key benefits of HDDs is that they are relatively inexpensive. One of their many downsides are their typically catastrophic failure modes and their relatively high read latency.</p>
<p>To understand the latter, consider the fact that HDDs spin at around 7,200 RPM (revolutions per minute). If they were much faster they would shatter due to the centrifugal force exerted on the platters. This has a major downside when it comes to accessing a specific sector on the disk: we need to wait until the platter has rotated in position (we can move the heads but not accelerate the actual disks). Hence it can take over 8 ms until the requested data is available. A common way this is expressed is to say that HDDs can operate at approximately 100 IOPs (input/output operations per second). This number has essentially remained unchanged for the past two decades. Worse still, it is equally difficult to increase bandwidth (it is in the order of 100--200 MB/s). After all, each head reads a track of bits, hence the bit rate only scales with the square root of the information density. As a result, HDDs are quickly becoming relegated to archival storage and low-grade storage for very large datasets.</p>
<h3 id="solid-state-drives">Solid State Drives<a class="headerlink" href="#solid-state-drives" title="Permanent link">⚓︎</a></h3>
<p>Solid state drives (SSDs) use flash memory to store information persistently. This allows for <em>much faster</em> access to stored records. Modern SSDs can operate at 100,000 to 500,000 IOPs, i.e., up to 3 orders of magnitude faster than HDDs. Furthermore, their bandwidth can reach 1--3GB/s, i.e., one order of magnitude faster than HDDs. These improvements sound almost too good to be true. Indeed, they come with the following caveats, due to the way SSDs are designed.</p>
<ul>
<li>SSDs store information in blocks (256 KB or larger). They can only be written as a whole, which takes significant time. Consequently bit-wise random writes on SSD have very poor performance. Likewise, writing data in general takes significant time since the block has to be read, erased and then rewritten with new information. By now SSD controllers and firmware have developed algorithms to mitigate this. Nonetheless, writes can be much slower, in particular for QLC (quad level cell) SSDs. The key for improved performance is to maintain a <em>queue</em> of operations, to prefer reads and to write in large blocks if possible.</li>
<li>The memory cells in SSDs wear out relatively quickly (often already after a few thousand writes). Wear-level protection algorithms are able to spread the degradation over many cells. That said, it is not recommended to use SSDs for swapping files or for large aggregations of log-files.</li>
<li>Lastly, the massive increase in bandwidth has forced computer designers to attach SSDs directly to the PCIe bus. The drives capable of handling this, referred to as NVMe (Non Volatile Memory enhanced), can use up to 4 PCIe lanes. This amounts to up to 8GB/s on PCIe 4.0.</li>
</ul>
<h3 id="cloud-storage">Cloud Storage<a class="headerlink" href="#cloud-storage" title="Permanent link">⚓︎</a></h3>
<p>Cloud storage provides a configurable range of performance. That is, the assignment of storage to virtual machines is dynamic, both in terms of quantity and in terms of speed, as chosen by users. We recommend that users increase the provisioned number of IOPs whenever latency is too high, e.g., during training with many small records.</p>
<h2 id="cpus">CPUs<a class="headerlink" href="#cpus" title="Permanent link">⚓︎</a></h2>
<p>Central processing units (CPUs) are the centerpiece of any computer. They consist of a number of key components: <em>processor cores</em> that are able to execute machine code, a <em>bus</em> connecting them (the specific topology differs significantly between processor models, generations, and vendors), and <em>caches</em> to allow for higher bandwidth and lower latency memory access than what is possible by reads from main memory. Lastly, almost all modern CPUs contain <em>vector processing units</em> to aid with high performance linear algebra and convolutions, as they are common in media processing and machine learning.</p>
<p><img alt="Intel Skylake consumer quad-core CPU." src="../../img/skylake.svg" />
:label:<code>fig_skylake</code></p>
<p>:numref:<code>fig_skylake</code> depicts an Intel Skylake consumer-grade quad-core CPU. It has an integrated GPU, caches, and a ringbus connecting the four cores. Peripherals, such as Ethernet, WiFi, Bluetooth, SSD controller, and USB, are either part of the chipset or directly attached (PCIe) to the CPU.</p>
<h3 id="microarchitecture">Microarchitecture<a class="headerlink" href="#microarchitecture" title="Permanent link">⚓︎</a></h3>
<p>Each of the processor cores consists of a rather sophisticated set of components. While details differ between generations and vendors, the basic functionality is pretty much standard. The front-end loads instructions and tries to predict which path will be taken (e.g., for control flow). Instructions are then decoded from assembly code to microinstructions. Assembly code is often not the lowest level code that a processor executes. Instead, complex instructions may be decoded into a set of more lower level operations. These are then processed by the actual execution core. Often the latter is capable of performing many operations simultaneously. For instance, the ARM Cortex A77 core of :numref:<code>fig_cortexa77</code> is able to perform up to 8 operations simultaneously.</p>
<p><img alt="ARM Cortex A77 Microarchitecture." src="../../img/a77.svg" />
:label:<code>fig_cortexa77</code></p>
<p>This means that efficient programs might be able to perform more than one instruction per clock cycle, provided that they can be carried out independently. Not all units are created equal. Some specialize in integer instructions whereas others are optimized for floating point performance. To increase throughput, the processor might also follow  multiple code paths simultaneously in a branching instruction and then discard the results of the branches not taken. This is why branch prediction units matter (on the front-end) such that only the most promising paths are pursued.</p>
<h3 id="vectorization">Vectorization<a class="headerlink" href="#vectorization" title="Permanent link">⚓︎</a></h3>
<p>Deep learning is extremely compute-hungry. Hence, to make CPUs suitable for machine learning, one needs to perform many operations in one clock cycle. This is achieved via vector units. They have different names: on ARM they are called NEON, on x86 they (a recent generation) are referred to as <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX2</a> units. A common aspect is that they are able to perform SIMD (single instruction multiple data) operations. :numref:<code>fig_neon128</code> shows how 8 short integers can be added in one clock cycle on ARM.</p>
<p><img alt="128 bit NEON vectorization." src="../../img/neon128.svg" />
:label:<code>fig_neon128</code></p>
<p>Depending on architecture choices, such registers are up to 512 bits long, allowing for the combination of up to 64 pairs of numbers. For instance, we might be multiplying two numbers and adding them to a third, which is also known as a fused multiply-add. Intel's <a href="https://01.org/openvinotoolkit">OpenVino</a> uses these to achieve respectable throughput for deep learning on server-grade CPUs. Note, though, that this number is entirely dwarfed by what GPUs are capable of achieving. For instance, NVIDIA's RTX 2080 Ti has 4,352 CUDA cores, each of which is capable of processing such an operation at any time.</p>
<h3 id="cache">Cache<a class="headerlink" href="#cache" title="Permanent link">⚓︎</a></h3>
<p>Consider the following situation: we have a modest CPU core with 4 cores as depicted in :numref:<code>fig_skylake</code> above, running at 2 GHz frequency.
Moreover, let's assume that we have an IPC (instructions per clock) count of 1 and that the units have AVX2 with 256-bit width enabled. Let's furthermore assume that at least one of the registers used for AVX2 operations needs to be retrieved from memory. This means that the CPU consumes <span class="arithmatex">\(4 \times 256 \textrm{ bit} = 128 \textrm{ bytes}\)</span> of data per clock cycle. Unless we are able to transfer <span class="arithmatex">\(2 \times 10^9 \times 128 = 256 \times 10^9\)</span> bytes to the processor per second the processing elements are going to starve. Unfortunately the memory interface of such a chip only supports 20--40 GB/s data transfer, i.e., one order of magnitude less. The fix is to avoid loading <em>new</em> data from memory as far as possible and rather to cache it locally on the CPU. This is where caches come in handy. Commonly the following names or concepts are used:</p>
<ul>
<li><strong>Registers</strong> are strictly speaking not part of the cache. They help stage instructions. That said, CPU registers are memory locations that a CPU can access at clock speed without any delay penalty. CPUs have tens of registers. It is up to the compiler (or programmer) to use registers efficiently. For instance the C programming language has a <code>register</code> keyword.</li>
<li><strong>L1 caches</strong> are the first line of defense against high memory bandwidth requirements. L1 caches are tiny (typical sizes might be 32--64 KB) and often split into data and instructions caches. When data is found in the L1 cache, access is very fast. If they cannot be found there, the search progresses down the cache hierarchy.</li>
<li><strong>L2 caches</strong> are the next stop. Depending on architecture design and processor size they might be exclusive. They might be accessible only by a given core or shared among multiple cores. L2 caches are larger (typically 256--512 KB per core) and slower than L1. Furthermore, to access something in L2 we first need to check to realize that the data is not in L1, which adds a small amount of extra latency.</li>
<li><strong>L3 caches</strong> are shared among multiple cores and can be quite large. AMD's Epyc 3 server CPUs have a whopping 256 MB of cache spread across multiple chiplets. More typical numbers are in the 4--8 MB range.</li>
</ul>
<p>Predicting which memory elements will be needed next is one of the key optimization parameters in chip design. For instance, it is advisable to traverse memory in a <em>forward</em> direction since most caching algorithms will try to <em>read ahead</em> rather than backwards. Likewise, keeping memory access patterns local is a good way of improving performance.</p>
<p>Adding caches is a double-edge sword. On the one hand they ensure that the processor cores do not starve of data. At the same time they increase chip size, using up area that otherwise could have been spent on increasing processing power. Moreover, <em>cache misses</em> can be expensive. Consider the worst case scenario, <em>false sharing</em>, as depicted in :numref:<code>fig_falsesharing</code>. A memory location is cached on processor 0 when a thread on processor 1 requests the data. To obtain it, processor 0 needs to stop what it is doing, write the information back to main memory and then let processor 1 read it from memory. During this operation both processors wait. Quite potentially such code runs <em>more slowly</em> on multiple processors when compared with an efficient single-processor implementation. This is one more reason for why there is a practical limit to cache sizes (besides their physical size).</p>
<p><img alt="False sharing (image courtesy of Intel)." src="../../img/falsesharing.svg" />
:label:<code>fig_falsesharing</code></p>
<h2 id="gpus-and-other-accelerators">GPUs and other Accelerators<a class="headerlink" href="#gpus-and-other-accelerators" title="Permanent link">⚓︎</a></h2>
<p>It is not an exaggeration to claim that deep learning would not have been successful without GPUs. By the same token, it is quite reasonable to argue that GPU manufacturers' fortunes have increased significantly due to deep learning. This co-evolution of hardware and algorithms has led to a situation where for better or worse deep learning is the preferable statistical modeling paradigm. Hence it pays to understand the specific benefits that GPUs and related accelerators such as the TPU :cite:<code>Jouppi.Young.Patil.ea.2017</code>.</p>
<p>Of note is a distinction that is often made in practice: accelerators are optimized either for training or inference. For the latter we only need to compute the forward propagation in a network. No storage of intermediate data is needed for backpropagation. Moreover, we may not need very precise computation (FP16 or INT8 typically suffice). On the other hand, during training all intermediate results need storage to compute gradients. Moreover, accumulating gradients requires higher precision to avoid numerical underflow (or overflow). This means that FP16 (or mixed precision with FP32) is the minimum requirement. All of this necessitates faster and larger memory (HBM2 vs. GDDR6) and more processing power. For instance, NVIDIA's <a href="https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/">Turing</a> T4 GPUs are optimized for inference whereas the V100 GPUs are preferable for training.</p>
<p>Recall vectorization as illustrated in :numref:<code>fig_neon128</code>. Adding vector units to a processor core allowed us to increase throughput significantly. For example, in the example in :numref:<code>fig_neon128</code> we were able to perform 16 operations simultaneously.
First,
what if we added operations that optimized not just operations between vectors but also between matrices? This strategy led to tensor cores (to be covered shortly). 
Second, what if we added many more cores? In a nutshell, these two strategies summarize the design decisions in GPUs. :numref:<code>fig_turing_processing_block</code> gives an overview of a basic processing block. It contains 16 integer and 16 floating point units. In addition to that, two tensor cores accelerate a narrow subset of additional operations relevant for deep learning. Each streaming multiprocessor consists of four such blocks.</p>
<p><img alt="NVIDIA Turing processing block (image courtesy of NVIDIA)." src="../../img/turing-processing-block.png" />
:width:<code>150px</code>
:label:<code>fig_turing_processing_block</code></p>
<p>Next, 12 streaming multiprocessors are grouped into graphics processing clusters which make up the high-end TU102 processors. Ample memory channels and an L2 cache complement the setup. :numref:<code>fig_turing</code> has the relevant details. One of the reasons for designing such a device is that individual blocks can be added or removed as needed to allow for more compact chips and to deal with yield issues (faulty modules might not be activated). Fortunately programming such devices is well hidden from the casual deep learning researcher beneath layers of CUDA and framework code. In particular, more than one of the programs might well be executed simultaneously on the GPU, provided that there are available resources. Nonetheless it pays to be aware of the limitations of the devices to avoid picking models that do not fit into device memory.</p>
<p><img alt="NVIDIA Turing architecture (image courtesy of NVIDIA)" src="../../img/turing.png" />
:width:<code>350px</code>
:label:<code>fig_turing</code></p>
<p>A last aspect that is worth mentioning in more detail are <em>tensor cores</em>. They are an example of a recent trend of adding more optimized circuits that are specifically effective for deep learning. For instance, the TPU added a systolic array :cite:<code>Kung.1988</code> for fast matrix multiplication. There the design was to support a very small number (one for the first generation of TPUs) of large operations. Tensor cores are at the other end. They are optimized for small operations involving between <span class="arithmatex">\(4 \times 4\)</span> and <span class="arithmatex">\(16 \times 16\)</span> matrices, depending on their numerical precision. :numref:<code>fig_tensorcore</code> gives an overview of the optimizations.</p>
<p><img alt="NVIDIA tensor cores in Turing (image courtesy of NVIDIA)." src="../../img/tensorcore.jpg" />
:width:<code>400px</code>
:label:<code>fig_tensorcore</code></p>
<p>Obviously when optimizing for computation we end up making certain compromises. One of them is that GPUs are not very good at handling interrupts and sparse data. While there are notable exceptions, such as <a href="https://github.com/gunrock/gunrock">Gunrock</a> :cite:<code>Wang.Davidson.Pan.ea.2016</code>, the access pattern of sparse matrices and vectors do not go well with the high bandwidth burst read operations where GPUs excel. Matching both goals is an area of active research. See e.g., <a href="http://dgl.ai">DGL</a>, a library tuned for deep learning on graphs.</p>
<h2 id="networks-and-buses">Networks and Buses<a class="headerlink" href="#networks-and-buses" title="Permanent link">⚓︎</a></h2>
<p>Whenever a single device is insufficient for optimization we need to transfer data to and from it to synchronize processing. This is where networks and buses come in handy. We have a number of design parameters: bandwidth, cost, distance, and flexibility.
On one end we have WiFi that has a pretty good range, is very easy to use (no wires, after all), cheap but it offers comparatively mediocre bandwidth and latency. No machine learning researcher within their right mind would use it to build a cluster of servers. In what follows we focus on interconnects that are suitable for deep learning.</p>
<ul>
<li><strong>PCIe</strong> is a dedicated bus for very high bandwidth point-to-point connections (up to 32 GB/s on PCIe 4.0 in a 16-lane slot) per lane. Latency is in the order of single-digit microseconds (5 μs). PCIe links are precious. Processors only have a limited number of them: AMD's EPYC 3 has 128 lanes, Intel's Xeon has up to 48 lanes per chip; on desktop-grade CPUs the numbers are 20 (Ryzen 9) and 16 (Core i9) respectively. Since GPUs have typically 16 lanes, this limits the number of GPUs that can connect to the CPU at full bandwidth. After all, they need to share the links with other high bandwidth peripherals such as storage and Ethernet. Just like with RAM access, large bulk transfers are preferable due to reduced packet overhead.</li>
<li><strong>Ethernet</strong> is the most commonly used way of connecting computers. While it is significantly slower than PCIe, it is very cheap and resilient to install and covers much longer distances. Typical bandwidth for low-grade servers is 1 GBit/s. Higher-end devices (e.g., <a href="https://aws.amazon.com/ec2/instance-types/c5/">C5 instances</a> in the cloud) offer between 10 and 100 GBit/s bandwidth. As in all previous cases data transmission has significant overheads. Note that we almost never use raw Ethernet directly but rather a protocol that is executed on top of the physical interconnect (such as UDP or TCP/IP). This adds further overhead. Like PCIe, Ethernet is designed to connect two devices, e.g., a computer and a switch.</li>
<li><strong>Switches</strong> allow us to connect multiple devices in a manner where any pair of them can carry out a (typically full bandwidth) point-to-point connection simultaneously. For instance, Ethernet switches might connect 40 servers at high cross-sectional bandwidth. Note that switches are not unique to traditional computer networks. Even PCIe lanes can be <a href="https://www.broadcom.com/products/pcie-switches-bridges/pcie-switches">switched</a>. This occurs, e.g., to connect a large number of GPUs to a host processor, as is the case for the <a href="https://aws.amazon.com/ec2/instance-types/p2/">P2 instances</a>.</li>
<li><strong>NVLink</strong> is an alternative to PCIe when it comes to very high bandwidth interconnects. It offers up to 300 Gbit/s data transfer rate per link. Server GPUs (Volta V100) have six links whereas consumer-grade GPUs (RTX 2080 Ti) have only one link, operating at a reduced 100 Gbit/s rate. We recommend to use <a href="https://github.com/NVIDIA/nccl">NCCL</a> to achieve high data transfer between GPUs.</li>
</ul>
<h2 id="more-latency-numbers">More Latency Numbers<a class="headerlink" href="#more-latency-numbers" title="Permanent link">⚓︎</a></h2>
<p>The summary in :numref:<code>table_latency_numbers</code> and :numref:<code>table_latency_numbers_tesla</code> are from <a href="https://gist.github.com/eshelman">Eliot Eshelman</a> who maintains an updated version of the numbers as a <a href="https://gist.github.com/eshelman/343a1c46cb3fba142c1afdcdeec17646">GitHub gist</a>.</p>
<p>:Common Latency Numbers.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Action</th>
<th style="text-align: right;">Time</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">L1 cache reference/hit</td>
<td style="text-align: right;">1.5 ns</td>
<td style="text-align: left;">4 cycles</td>
</tr>
<tr>
<td style="text-align: left;">Floating-point add/mult/FMA</td>
<td style="text-align: right;">1.5 ns</td>
<td style="text-align: left;">4 cycles</td>
</tr>
<tr>
<td style="text-align: left;">L2 cache reference/hit</td>
<td style="text-align: right;">5 ns</td>
<td style="text-align: left;">12 ~ 17 cycles</td>
</tr>
<tr>
<td style="text-align: left;">Branch mispredict</td>
<td style="text-align: right;">6 ns</td>
<td style="text-align: left;">15 ~ 20 cycles</td>
</tr>
<tr>
<td style="text-align: left;">L3 cache hit (unshared cache)</td>
<td style="text-align: right;">16 ns</td>
<td style="text-align: left;">42 cycles</td>
</tr>
<tr>
<td style="text-align: left;">L3 cache hit (shared in another core)</td>
<td style="text-align: right;">25 ns</td>
<td style="text-align: left;">65 cycles</td>
</tr>
<tr>
<td style="text-align: left;">Mutex lock/unlock</td>
<td style="text-align: right;">25 ns</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">L3 cache hit (modified in another core)</td>
<td style="text-align: right;">29 ns</td>
<td style="text-align: left;">75 cycles</td>
</tr>
<tr>
<td style="text-align: left;">L3 cache hit (on a remote CPU socket)</td>
<td style="text-align: right;">40 ns</td>
<td style="text-align: left;">100 ~ 300 cycles (40 ~ 116 ns)</td>
</tr>
<tr>
<td style="text-align: left;">QPI hop to a another CPU (per hop)</td>
<td style="text-align: right;">40 ns</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">64MB memory ref. (local CPU)</td>
<td style="text-align: right;">46 ns</td>
<td style="text-align: left;">TinyMemBench on Broadwell E5-2690v4</td>
</tr>
<tr>
<td style="text-align: left;">64MB memory ref. (remote CPU)</td>
<td style="text-align: right;">70 ns</td>
<td style="text-align: left;">TinyMemBench on Broadwell E5-2690v4</td>
</tr>
<tr>
<td style="text-align: left;">256MB memory ref. (local CPU)</td>
<td style="text-align: right;">75 ns</td>
<td style="text-align: left;">TinyMemBench on Broadwell E5-2690v4</td>
</tr>
<tr>
<td style="text-align: left;">Intel Optane random write</td>
<td style="text-align: right;">94 ns</td>
<td style="text-align: left;">UCSD Non-Volatile Systems Lab</td>
</tr>
<tr>
<td style="text-align: left;">256MB memory ref. (remote CPU)</td>
<td style="text-align: right;">120 ns</td>
<td style="text-align: left;">TinyMemBench on Broadwell E5-2690v4</td>
</tr>
<tr>
<td style="text-align: left;">Intel Optane random read</td>
<td style="text-align: right;">305 ns</td>
<td style="text-align: left;">UCSD Non-Volatile Systems Lab</td>
</tr>
<tr>
<td style="text-align: left;">Send 4KB over 100 Gbps HPC fabric</td>
<td style="text-align: right;">1 μs</td>
<td style="text-align: left;">MVAPICH2 over Intel Omni-Path</td>
</tr>
<tr>
<td style="text-align: left;">Compress 1KB with Google Snappy</td>
<td style="text-align: right;">3 μs</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Send 4KB over 10 Gbps ethernet</td>
<td style="text-align: right;">10 μs</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Write 4KB randomly to NVMe SSD</td>
<td style="text-align: right;">30 μs</td>
<td style="text-align: left;">DC P3608 NVMe SSD (QOS 99% is 500μs)</td>
</tr>
<tr>
<td style="text-align: left;">Transfer 1MB to/from NVLink GPU</td>
<td style="text-align: right;">30 μs</td>
<td style="text-align: left;">~33GB/s on NVIDIA 40GB NVLink</td>
</tr>
<tr>
<td style="text-align: left;">Transfer 1MB to/from PCI-E GPU</td>
<td style="text-align: right;">80 μs</td>
<td style="text-align: left;">~12GB/s on PCIe 3.0 x16 link</td>
</tr>
<tr>
<td style="text-align: left;">Read 4KB randomly from NVMe SSD</td>
<td style="text-align: right;">120 μs</td>
<td style="text-align: left;">DC P3608 NVMe SSD (QOS 99%)</td>
</tr>
<tr>
<td style="text-align: left;">Read 1MB sequentially from NVMe SSD</td>
<td style="text-align: right;">208 μs</td>
<td style="text-align: left;">~4.8GB/s DC P3608 NVMe SSD</td>
</tr>
<tr>
<td style="text-align: left;">Write 4KB randomly to SATA SSD</td>
<td style="text-align: right;">500 μs</td>
<td style="text-align: left;">DC S3510 SATA SSD (QOS 99.9%)</td>
</tr>
<tr>
<td style="text-align: left;">Read 4KB randomly from SATA SSD</td>
<td style="text-align: right;">500 μs</td>
<td style="text-align: left;">DC S3510 SATA SSD (QOS 99.9%)</td>
</tr>
<tr>
<td style="text-align: left;">Round trip within same data center</td>
<td style="text-align: right;">500 μs</td>
<td style="text-align: left;">One-way ping is ~250μs</td>
</tr>
<tr>
<td style="text-align: left;">Read 1MB sequentially from SATA SSD</td>
<td style="text-align: right;">2 ms</td>
<td style="text-align: left;">~550MB/s DC S3510 SATA SSD</td>
</tr>
<tr>
<td style="text-align: left;">Read 1MB sequentially from disk</td>
<td style="text-align: right;">5 ms</td>
<td style="text-align: left;">~200MB/s server HDD</td>
</tr>
<tr>
<td style="text-align: left;">Random Disk Access (seek+rotation)</td>
<td style="text-align: right;">10 ms</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Send packet CA-&gt;Netherlands-&gt;CA</td>
<td style="text-align: right;">150 ms</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">:label:<code>table_latency_numbers</code></td>
<td style="text-align: right;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>:Latency Numbers for NVIDIA Tesla GPUs.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Action</th>
<th style="text-align: right;">Time</th>
<th style="text-align: left;">Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GPU Shared Memory access</td>
<td style="text-align: right;">30 ns</td>
<td style="text-align: left;">30~90 cycles (bank conflicts add latency)</td>
</tr>
<tr>
<td style="text-align: left;">GPU Global Memory access</td>
<td style="text-align: right;">200 ns</td>
<td style="text-align: left;">200~800 cycles</td>
</tr>
<tr>
<td style="text-align: left;">Launch CUDA kernel on GPU</td>
<td style="text-align: right;">10 μs</td>
<td style="text-align: left;">Host CPU instructs GPU to start kernel</td>
</tr>
<tr>
<td style="text-align: left;">Transfer 1MB to/from NVLink GPU</td>
<td style="text-align: right;">30 μs</td>
<td style="text-align: left;">~33GB/s on NVIDIA 40GB NVLink</td>
</tr>
<tr>
<td style="text-align: left;">Transfer 1MB to/from PCI-E GPU</td>
<td style="text-align: right;">80 μs</td>
<td style="text-align: left;">~12GB/s on PCI-Express x16 link</td>
</tr>
<tr>
<td style="text-align: left;">:label:<code>table_latency_numbers_tesla</code></td>
<td style="text-align: right;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">⚓︎</a></h2>
<ul>
<li>Devices have overheads for operations. Hence it is important to aim for a small number of large transfers rather than many small ones. This applies to RAM, SSDs, networks and GPUs.</li>
<li>Vectorization is key for performance. Make sure you are aware of the specific abilities of your accelerator. E.g., some Intel Xeon CPUs are particularly good for INT8 operations, NVIDIA Volta GPUs excel at FP16 matrix-matrix operations and NVIDIA Turing shines at FP16, INT8, and INT4 operations.</li>
<li>Numerical overflow due to small data types can be a problem during training (and to a lesser extent during inference).</li>
<li>Aliasing can significantly degrade performance. For instance, memory alignment on 64 bit CPUs should be done with respect to 64 bit boundaries. On GPUs it is a good idea to keep convolution sizes aligned, e.g., to tensor cores.</li>
<li>Match your algorithms to the hardware (e.g., memory footprint, and bandwidth). Great speedup (orders of magnitude) can be achieved when fitting the parameters into caches.</li>
<li>We recommend that you sketch out the performance of a novel algorithm on paper before verifying the experimental results. Discrepancies of an order-of-magnitude or more are reasons for concern.</li>
<li>Use profilers to debug performance bottlenecks.</li>
<li>Training and inference hardware have different sweet spots in terms of price and performance.</li>
</ul>
<h2 id="exercises">Exercises<a class="headerlink" href="#exercises" title="Permanent link">⚓︎</a></h2>
<ol>
<li>Write C code to test whether there is any difference in speed between accessing memory aligned or misaligned relative to the external memory interface. Hint: be careful of caching effects.</li>
<li>Test the difference in speed between accessing memory in sequence or with a given stride.</li>
<li>How could you measure the cache sizes on a CPU?</li>
<li>How would you lay out data across multiple memory channels for maximum bandwidth? How would you lay it out if you had many small threads?</li>
<li>An enterprise-class HDD is spinning at 10,000 rpm. What is the absolutely minimum time an HDD needs to spend worst case before it can read data (you can assume that heads move almost instantaneously)? Why are 2.5" HDDs becoming popular for commercial servers (relative to 3.5" and 5.25" drives)?</li>
<li>Assume that an HDD manufacturer increases the storage density from 1 Tbit per square inch to 5 Tbit per square inch. How much information can you store on a ring on a 2.5" HDD? Is there a difference between the inner and outer tracks?</li>
<li>Going from 8 bit to 16 bit data types increases the amount of silicon approximately by four times. Why? Why might NVIDIA have added INT4 operations to their Turing GPUs?</li>
<li>How much faster is it to read forward through memory vs. reading backwards? Does this number differ between different computers and CPU vendors? Why? Write C code and experiment with it.</li>
<li>Can you measure the cache size of your disk? What is it for a typical HDD? Do SSDs need a cache?</li>
<li>Measure the packet overhead when sending messages across the Ethernet. Look up the difference between UDP and TCP/IP connections.</li>
<li>Direct memory access allows devices other than the CPU to write (and read) directly to (from) memory. Why is this a good idea?</li>
<li>Look at the performance numbers for the Turing T4 GPU. Why does the performance "only" double as you go from FP16 to INT8 and INT4?</li>
<li>What is the shortest time it should take for a packet on a round trip between San Francisco and Amsterdam? Hint: you can assume that the distance is 10,000 km.</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/363">Discussions</a></p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../auto-parallelism/" class="md-footer__link md-footer__link--prev" aria-label="上一页: Automatic Parallelism">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Automatic Parallelism
              </div>
            </div>
          </a>
        
        
          
          <a href="../hybridize/" class="md-footer__link md-footer__link--next" aria-label="下一页: Compilers and Interpreters">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Compilers and Interpreters
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>