
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E6%95%99%E7%A8%8B/09-recurrent-neural-networks/bptt/">
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../language-model/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Backpropagation Through Time - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#backpropagation-through-time" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Backpropagation Through Time
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_12" checked>
        
          
          <label class="md-nav__link" for="__nav_2_12" id="__nav_2_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_12_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_12">
            <span class="md-nav__icon md-icon"></span>
            09 recurrent neural networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Backpropagation Through Time
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Backpropagation Through Time
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#analysis-of-gradients-in-rnns" class="md-nav__link">
    <span class="md-ellipsis">
      Analysis of Gradients in RNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Analysis of Gradients in RNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#full-computation" class="md-nav__link">
    <span class="md-ellipsis">
      Full Computation ###
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#truncating-time-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Truncating Time Steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomized-truncation" class="md-nav__link">
    <span class="md-ellipsis">
      Randomized Truncation ###
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time-in-detail" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Through Time in Detail
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../language-model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../rnn-concise/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Concise Implementation of Recurrent Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../rnn-scratch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent Neural Network Implementation from Scratch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../rnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent Neural Networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../sequence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Working with Sequences
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../text-sequence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Converting Raw Text into Sequence Data
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../12-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../13-computational-performance/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch04/ch04/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch05/ch05/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch09/ch09/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#analysis-of-gradients-in-rnns" class="md-nav__link">
    <span class="md-ellipsis">
      Analysis of Gradients in RNNs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Analysis of Gradients in RNNs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#full-computation" class="md-nav__link">
    <span class="md-ellipsis">
      Full Computation ###
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#truncating-time-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Truncating Time Steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#randomized-truncation" class="md-nav__link">
    <span class="md-ellipsis">
      Randomized Truncation ###
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comparing-strategies" class="md-nav__link">
    <span class="md-ellipsis">
      Comparing Strategies
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backpropagation-through-time-in-detail" class="md-nav__link">
    <span class="md-ellipsis">
      Backpropagation Through Time in Detail
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/09-recurrent-neural-networks/bptt.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/09-recurrent-neural-networks/bptt.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="backpropagation-through-time">Backpropagation Through Time<a class="headerlink" href="#backpropagation-through-time" title="Permanent link">⚓︎</a></h1>
<p>:label:<code>sec_bptt</code></p>
<p>If you completed the exercises in :numref:<code>sec_rnn-scratch</code>,
you would have seen that gradient clipping is vital 
for preventing the occasional massive gradients
from destabilizing training.
We hinted that the exploding gradients
stem from backpropagating across long sequences.
Before introducing a slew of modern RNN architectures,
let's take a closer look at how <em>backpropagation</em>
works in sequence models in mathematical detail.
Hopefully, this discussion will bring some precision 
to the notion of <em>vanishing</em> and <em>exploding</em> gradients.
If you recall our discussion of forward and backward 
propagation through computational graphs
when we introduced MLPs in :numref:<code>sec_backprop</code>,
then forward propagation in RNNs
should be relatively straightforward.
Applying backpropagation in RNNs 
is called <em>backpropagation through time</em> :cite:<code>Werbos.1990</code>.
This procedure requires us to expand (or unroll) 
the computational graph of an RNN
one time step at a time.
The unrolled RNN is essentially 
a feedforward neural network 
with the special property 
that the same parameters 
are repeated throughout the unrolled network,
appearing at each time step.
Then, just as in any feedforward neural network,
we can apply the chain rule, 
backpropagating gradients through the unrolled net.
The gradient with respect to each parameter
must be summed across all places 
that the parameter occurs in the unrolled net.
Handling such weight tying should be familiar 
from our chapters on convolutional neural networks.</p>
<p>Complications arise because sequences
can be rather long.
It is not unusual to work with text sequences
consisting of over a thousand tokens. 
Note that this poses problems both from 
a computational (too much memory)
and optimization (numerical instability)
standpoint. 
Input from the first step passes through
over 1000 matrix products before arriving at the output, 
and another 1000 matrix products 
are required to compute the gradient. 
We now analyze what can go wrong and 
how to address it in practice.</p>
<h2 id="analysis-of-gradients-in-rnns">Analysis of Gradients in RNNs<a class="headerlink" href="#analysis-of-gradients-in-rnns" title="Permanent link">⚓︎</a></h2>
<p>:label:<code>subsec_bptt_analysis</code></p>
<p>We start with a simplified model of how an RNN works.
This model ignores details about the specifics 
of the hidden state and how it is updated.
The mathematical notation here
does not explicitly distinguish
scalars, vectors, and matrices.
We are just trying to develop some intuition.
In this simplified model,
we denote <span class="arithmatex">\(h_t\)</span> as the hidden state,
<span class="arithmatex">\(x_t\)</span> as input, and <span class="arithmatex">\(o_t\)</span> as output
at time step <span class="arithmatex">\(t\)</span>.
Recall our discussions in
:numref:<code>subsec_rnn_w_hidden_states</code>
that the input and the hidden state
can be concatenated before being multiplied 
by one weight variable in the hidden layer.
Thus, we use <span class="arithmatex">\(w_\textrm{h}\)</span> and <span class="arithmatex">\(w_\textrm{o}\)</span> to indicate the weights 
of the hidden layer and the output layer, respectively.
As a result, the hidden states and outputs 
at each time step are</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\begin{aligned}h_t &amp;= f(x_t, h_{t-1}, w_\textrm{h}),\\o_t &amp;= g(h_t, w_\textrm{o}),\end{aligned}\)</span>\)</span>
:eqlabel:<code>eq_bptt_ht_ot</code></p>
<p>where <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span> are transformations
of the hidden layer and the output layer, respectively.
Hence, we have a chain of values 
<span class="arithmatex">\(\{\ldots, (x_{t-1}, h_{t-1}, o_{t-1}), (x_{t}, h_{t}, o_t), \ldots\}\)</span> 
that depend on each other via recurrent computation.
The forward propagation is fairly straightforward.
All we need is to loop through the <span class="arithmatex">\((x_t, h_t, o_t)\)</span> triples one time step at a time.
The discrepancy between output <span class="arithmatex">\(o_t\)</span> and the desired target <span class="arithmatex">\(y_t\)</span> 
is then evaluated by an objective function 
across all the <span class="arithmatex">\(T\)</span> time steps as</p>
<div class="arithmatex">\[L(x_1, \ldots, x_T, y_1, \ldots, y_T, w_\textrm{h}, w_\textrm{o}) = \frac{1}{T}\sum_{t=1}^T l(y_t, o_t).\]</div>
<p>For backpropagation, matters are a bit trickier, 
especially when we compute the gradients 
with regard to the parameters <span class="arithmatex">\(w_\textrm{h}\)</span> of the objective function <span class="arithmatex">\(L\)</span>. 
To be specific, by the chain rule,</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\begin{aligned}\frac{\partial L}{\partial w_\textrm{h}}  &amp; = \frac{1}{T}\sum_{t=1}^T \frac{\partial l(y_t, o_t)}{\partial w_\textrm{h}}  \\&amp; = \frac{1}{T}\sum_{t=1}^T \frac{\partial l(y_t, o_t)}{\partial o_t} \frac{\partial g(h_t, w_\textrm{o})}{\partial h_t}  \frac{\partial h_t}{\partial w_\textrm{h}}.\end{aligned}\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_L_wh</code></p>
<p>The first and the second factors of the
product in :eqref:<code>eq_bptt_partial_L_wh</code>
are easy to compute.
The third factor <span class="arithmatex">\(\partial h_t/\partial w_\textrm{h}\)</span> is where things get tricky, 
since we need to recurrently compute the effect of the parameter <span class="arithmatex">\(w_\textrm{h}\)</span> on <span class="arithmatex">\(h_t\)</span>.
According to the recurrent computation
in :eqref:<code>eq_bptt_ht_ot</code>,
<span class="arithmatex">\(h_t\)</span> depends on both <span class="arithmatex">\(h_{t-1}\)</span> and <span class="arithmatex">\(w_\textrm{h}\)</span>,
where computation of <span class="arithmatex">\(h_{t-1}\)</span>
also depends on <span class="arithmatex">\(w_\textrm{h}\)</span>.
Thus, evaluating the total derivate of <span class="arithmatex">\(h_t\)</span> 
with respect to <span class="arithmatex">\(w_\textrm{h}\)</span> using the chain rule yields</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial h_t}{\partial w_\textrm{h}}= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}} +\frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial h_{t-1}} \frac{\partial h_{t-1}}{\partial w_\textrm{h}}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_ht_wh_recur</code></p>
<p>To derive the above gradient, assume that we have 
three sequences <span class="arithmatex">\(\{a_{t}\},\{b_{t}\},\{c_{t}\}\)</span> 
satisfying <span class="arithmatex">\(a_{0}=0\)</span> and <span class="arithmatex">\(a_{t}=b_{t}+c_{t}a_{t-1}\)</span> for <span class="arithmatex">\(t=1, 2,\ldots\)</span>.
Then for <span class="arithmatex">\(t\geq 1\)</span>, it is easy to show</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(a_{t}=b_{t}+\sum_{i=1}^{t-1}\left(\prod_{j=i+1}^{t}c_{j}\right)b_{i}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_at</code></p>
<p>By substituting <span class="arithmatex">\(a_t\)</span>, <span class="arithmatex">\(b_t\)</span>, and <span class="arithmatex">\(c_t\)</span> according to</p>
<div class="arithmatex">\[\begin{aligned}a_t &amp;= \frac{\partial h_t}{\partial w_\textrm{h}},\\
b_t &amp;= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}}, \\
c_t &amp;= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial h_{t-1}},\end{aligned}\]</div>
<p>the gradient computation in :eqref:<code>eq_bptt_partial_ht_wh_recur</code> satisfies
<span class="arithmatex">\(a_{t}=b_{t}+c_{t}a_{t-1}\)</span>.
Thus, per :eqref:<code>eq_bptt_at</code>, 
we can remove the recurrent computation 
in :eqref:<code>eq_bptt_partial_ht_wh_recur</code> with</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial h_t}{\partial w_\textrm{h}}=\frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}}+\sum_{i=1}^{t-1}\left(\prod_{j=i+1}^{t} \frac{\partial f(x_{j},h_{j-1},w_\textrm{h})}{\partial h_{j-1}} \right) \frac{\partial f(x_{i},h_{i-1},w_\textrm{h})}{\partial w_\textrm{h}}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_ht_wh_gen</code></p>
<p>While we can use the chain rule to compute <span class="arithmatex">\(\partial h_t/\partial w_\textrm{h}\)</span> recursively, 
this chain can get very long whenever <span class="arithmatex">\(t\)</span> is large.
Let's discuss a number of strategies for dealing with this problem.</p>
<h3 id="full-computation">Full Computation ###<a class="headerlink" href="#full-computation" title="Permanent link">⚓︎</a></h3>
<p>One idea might be to compute the full sum in :eqref:<code>eq_bptt_partial_ht_wh_gen</code>.
However, this is very slow and gradients can blow up,
since subtle changes in the initial conditions
can potentially affect the outcome a lot.
That is, we could see things similar to the butterfly effect,
where minimal changes in the initial conditions 
lead to disproportionate changes in the outcome.
This is generally undesirable.
After all, we are looking for robust estimators that generalize well. 
Hence this strategy is almost never used in practice.</p>
<h3 id="truncating-time-steps">Truncating Time Steps<a class="headerlink" href="#truncating-time-steps" title="Permanent link">⚓︎</a></h3>
<p>Alternatively,
we can truncate the sum in
:eqref:<code>eq_bptt_partial_ht_wh_gen</code>
after <span class="arithmatex">\(\tau\)</span> steps. 
This is what we have been discussing so far. 
This leads to an <em>approximation</em> of the true gradient,
simply by terminating the sum at <span class="arithmatex">\(\partial h_{t-\tau}/\partial w_\textrm{h}\)</span>. 
In practice this works quite well. 
It is what is commonly referred to as truncated 
backpropgation through time :cite:<code>Jaeger.2002</code>.
One of the consequences of this is that the model 
focuses primarily on short-term influence 
rather than long-term consequences. 
This is actually <em>desirable</em>, since it biases the estimate 
towards simpler and more stable models.</p>
<h3 id="randomized-truncation">Randomized Truncation ###<a class="headerlink" href="#randomized-truncation" title="Permanent link">⚓︎</a></h3>
<p>Last, we can replace <span class="arithmatex">\(\partial h_t/\partial w_\textrm{h}\)</span>
by a random variable which is correct in expectation 
but truncates the sequence.
This is achieved by using a sequence of <span class="arithmatex">\(\xi_t\)</span>
with predefined <span class="arithmatex">\(0 \leq \pi_t \leq 1\)</span>,
where <span class="arithmatex">\(P(\xi_t = 0) = 1-\pi_t\)</span> and 
<span class="arithmatex">\(P(\xi_t = \pi_t^{-1}) = \pi_t\)</span>, thus <span class="arithmatex">\(E[\xi_t] = 1\)</span>.
We use this to replace the gradient
<span class="arithmatex">\(\partial h_t/\partial w_\textrm{h}\)</span>
in :eqref:<code>eq_bptt_partial_ht_wh_recur</code>
with</p>
<div class="arithmatex">\[z_t= \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial w_\textrm{h}} +\xi_t \frac{\partial f(x_{t},h_{t-1},w_\textrm{h})}{\partial h_{t-1}} \frac{\partial h_{t-1}}{\partial w_\textrm{h}}.\]</div>
<p>It follows from the definition of <span class="arithmatex">\(\xi_t\)</span> 
that <span class="arithmatex">\(E[z_t] = \partial h_t/\partial w_\textrm{h}\)</span>.
Whenever <span class="arithmatex">\(\xi_t = 0\)</span> the recurrent computation
terminates at that time step <span class="arithmatex">\(t\)</span>.
This leads to a weighted sum of sequences of varying lengths,
where long sequences are rare but appropriately overweighted. 
This idea was proposed by 
:citet:<code>Tallec.Ollivier.2017</code>.</p>
<h3 id="comparing-strategies">Comparing Strategies<a class="headerlink" href="#comparing-strategies" title="Permanent link">⚓︎</a></h3>
<p><img alt="Comparing strategies for computing gradients in RNNs. From top to bottom: randomized truncation, regular truncation, and full computation." src="../../img/truncated-bptt.svg" />
:label:<code>fig_truncated_bptt</code></p>
<p>:numref:<code>fig_truncated_bptt</code> illustrates the three strategies 
when analyzing the first few characters of <em>The Time Machine</em> 
using backpropagation through time for RNNs:</p>
<ul>
<li>The first row is the randomized truncation that partitions the text into segments of varying lengths.</li>
<li>The second row is the regular truncation that breaks the text into subsequences of the same length. This is what we have been doing in RNN experiments.</li>
<li>The third row is the full backpropagation through time that leads to a computationally infeasible expression.</li>
</ul>
<p>Unfortunately, while appealing in theory, 
randomized truncation does not work 
much better than regular truncation, 
most likely due to a number of factors.
First, the effect of an observation
after a number of backpropagation steps 
into the past is quite sufficient 
to capture dependencies in practice. 
Second, the increased variance counteracts the fact 
that the gradient is more accurate with more steps. 
Third, we actually <em>want</em> models that have only 
a short range of interactions. 
Hence, regularly truncated backpropagation through time 
has a slight regularizing effect that can be desirable.</p>
<h2 id="backpropagation-through-time-in-detail">Backpropagation Through Time in Detail<a class="headerlink" href="#backpropagation-through-time-in-detail" title="Permanent link">⚓︎</a></h2>
<p>After discussing the general principle,
let's discuss backpropagation through time in detail.
In contrast to the analysis in :numref:<code>subsec_bptt_analysis</code>,
in the following we will show how to compute
the gradients of the objective function
with respect to all the decomposed model parameters.
To keep things simple, we consider 
an RNN without bias parameters,
whose activation function in the hidden layer
uses the identity mapping (<span class="arithmatex">\(\phi(x)=x\)</span>).
For time step <span class="arithmatex">\(t\)</span>, let the single example input 
and the target be <span class="arithmatex">\(\mathbf{x}_t \in \mathbb{R}^d\)</span> and <span class="arithmatex">\(y_t\)</span>, respectively. 
The hidden state <span class="arithmatex">\(\mathbf{h}_t \in \mathbb{R}^h\)</span> 
and the output <span class="arithmatex">\(\mathbf{o}_t \in \mathbb{R}^q\)</span>
are computed as</p>
<div class="arithmatex">\[\begin{aligned}\mathbf{h}_t &amp;= \mathbf{W}_\textrm{hx} \mathbf{x}_t + \mathbf{W}_\textrm{hh} \mathbf{h}_{t-1},\\
\mathbf{o}_t &amp;= \mathbf{W}_\textrm{qh} \mathbf{h}_{t},\end{aligned}\]</div>
<p>where <span class="arithmatex">\(\mathbf{W}_\textrm{hx} \in \mathbb{R}^{h \times d}\)</span>, <span class="arithmatex">\(\mathbf{W}_\textrm{hh} \in \mathbb{R}^{h \times h}\)</span>, and
<span class="arithmatex">\(\mathbf{W}_\textrm{qh} \in \mathbb{R}^{q \times h}\)</span>
are the weight parameters.
Denote by <span class="arithmatex">\(l(\mathbf{o}_t, y_t)\)</span>
the loss at time step <span class="arithmatex">\(t\)</span>. 
Our objective function,
the loss over <span class="arithmatex">\(T\)</span> time steps
from the beginning of the sequence is thus</p>
<div class="arithmatex">\[L = \frac{1}{T} \sum_{t=1}^T l(\mathbf{o}_t, y_t).\]</div>
<p>In order to visualize the dependencies among
model variables and parameters during computation
of the RNN,
we can draw a computational graph for the model,
as shown in :numref:<code>fig_rnn_bptt</code>.
For example, the computation of the hidden states of time step 3,
<span class="arithmatex">\(\mathbf{h}_3\)</span>, depends on the model parameters
<span class="arithmatex">\(\mathbf{W}_\textrm{hx}\)</span> and <span class="arithmatex">\(\mathbf{W}_\textrm{hh}\)</span>,
the hidden state of the previous time step <span class="arithmatex">\(\mathbf{h}_2\)</span>,
and the input of the current time step <span class="arithmatex">\(\mathbf{x}_3\)</span>.</p>
<p><img alt="Computational graph showing dependencies for an RNN model with three time steps. Boxes represent variables (not shaded) or parameters (shaded) and circles represent operators." src="../../img/rnn-bptt.svg" />
:label:<code>fig_rnn_bptt</code></p>
<p>As just mentioned, the model parameters in :numref:<code>fig_rnn_bptt</code> 
are <span class="arithmatex">\(\mathbf{W}_\textrm{hx}\)</span>, <span class="arithmatex">\(\mathbf{W}_\textrm{hh}\)</span>, and <span class="arithmatex">\(\mathbf{W}_\textrm{qh}\)</span>. 
Generally, training this model requires 
gradient computation with respect to these parameters
<span class="arithmatex">\(\partial L/\partial \mathbf{W}_\textrm{hx}\)</span>, <span class="arithmatex">\(\partial L/\partial \mathbf{W}_\textrm{hh}\)</span>, and <span class="arithmatex">\(\partial L/\partial \mathbf{W}_\textrm{qh}\)</span>.
According to the dependencies in :numref:<code>fig_rnn_bptt</code>,
we can traverse in the opposite direction of the arrows
to calculate and store the gradients in turn.
To flexibly express the multiplication of 
matrices, vectors, and scalars of different shapes
in the chain rule,
we continue to use the <span class="arithmatex">\(\textrm{prod}\)</span> operator 
as described in :numref:<code>sec_backprop</code>.</p>
<p>First of all, differentiating the objective function
with respect to the model output at any time step <span class="arithmatex">\(t\)</span>
is fairly straightforward:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial L}{\partial \mathbf{o}_t} =  \frac{\partial l (\mathbf{o}_t, y_t)}{T \cdot \partial \mathbf{o}_t} \in \mathbb{R}^q.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_L_ot</code></p>
<p>Now we can calculate the gradient of the objective 
with respect to the parameter <span class="arithmatex">\(\mathbf{W}_\textrm{qh}\)</span>
in the output layer:
<span class="arithmatex">\(\partial L/\partial \mathbf{W}_\textrm{qh} \in \mathbb{R}^{q \times h}\)</span>. 
Based on :numref:<code>fig_rnn_bptt</code>, 
the objective <span class="arithmatex">\(L\)</span> depends on <span class="arithmatex">\(\mathbf{W}_\textrm{qh}\)</span> 
via <span class="arithmatex">\(\mathbf{o}_1, \ldots, \mathbf{o}_T\)</span>. 
Using the chain rule yields</p>
<div class="arithmatex">\[
\frac{\partial L}{\partial \mathbf{W}_\textrm{qh}}
= \sum_{t=1}^T \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{o}_t}, \frac{\partial \mathbf{o}_t}{\partial \mathbf{W}_\textrm{qh}}\right)
= \sum_{t=1}^T \frac{\partial L}{\partial \mathbf{o}_t} \mathbf{h}_t^\top,
\]</div>
<p>where <span class="arithmatex">\(\partial L/\partial \mathbf{o}_t\)</span>
is given by :eqref:<code>eq_bptt_partial_L_ot</code>.</p>
<p>Next, as shown in :numref:<code>fig_rnn_bptt</code>,
at the final time step <span class="arithmatex">\(T\)</span>,
the objective function
<span class="arithmatex">\(L\)</span> depends on the hidden state <span class="arithmatex">\(\mathbf{h}_T\)</span> 
only via <span class="arithmatex">\(\mathbf{o}_T\)</span>.
Therefore, we can easily find the gradient 
<span class="arithmatex">\(\partial L/\partial \mathbf{h}_T \in \mathbb{R}^h\)</span>
using the chain rule:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial L}{\partial \mathbf{h}_T} = \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{o}_T}, \frac{\partial \mathbf{o}_T}{\partial \mathbf{h}_T} \right) = \mathbf{W}_\textrm{qh}^\top \frac{\partial L}{\partial \mathbf{o}_T}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_L_hT_final_step</code></p>
<p>It gets trickier for any time step <span class="arithmatex">\(t &lt; T\)</span>,
where the objective function <span class="arithmatex">\(L\)</span> depends on 
<span class="arithmatex">\(\mathbf{h}_t\)</span> via <span class="arithmatex">\(\mathbf{h}_{t+1}\)</span> and <span class="arithmatex">\(\mathbf{o}_t\)</span>.
According to the chain rule,
the gradient of the hidden state
<span class="arithmatex">\(\partial L/\partial \mathbf{h}_t \in \mathbb{R}^h\)</span>
at any time step <span class="arithmatex">\(t &lt; T\)</span> can be recurrently computed as:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial L}{\partial \mathbf{h}_t} = \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{h}_{t+1}}, \frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_t} \right) + \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{o}_t}, \frac{\partial \mathbf{o}_t}{\partial \mathbf{h}_t} \right) = \mathbf{W}_\textrm{hh}^\top \frac{\partial L}{\partial \mathbf{h}_{t+1}} + \mathbf{W}_\textrm{qh}^\top \frac{\partial L}{\partial \mathbf{o}_t}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_L_ht_recur</code></p>
<p>For analysis, expanding the recurrent computation
for any time step <span class="arithmatex">\(1 \leq t \leq T\)</span> gives</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\frac{\partial L}{\partial \mathbf{h}_t}= \sum_{i=t}^T {\left(\mathbf{W}_\textrm{hh}^\top\right)}^{T-i} \mathbf{W}_\textrm{qh}^\top \frac{\partial L}{\partial \mathbf{o}_{T+t-i}}.\)</span>\)</span>
:eqlabel:<code>eq_bptt_partial_L_ht</code></p>
<p>We can see from :eqref:<code>eq_bptt_partial_L_ht</code> 
that this simple linear example already
exhibits some key problems of long sequence models:
it involves potentially very large powers of <span class="arithmatex">\(\mathbf{W}_\textrm{hh}^\top\)</span>.
In it, eigenvalues smaller than 1 vanish
and eigenvalues larger than 1 diverge.
This is numerically unstable,
which manifests itself in the form of vanishing 
and exploding gradients.
One way to address this is to truncate the time steps
at a computationally convenient size 
as discussed in :numref:<code>subsec_bptt_analysis</code>. 
In practice, this truncation can also be effected 
by detaching the gradient after a given number of time steps.
Later on, we will see how more sophisticated sequence models 
such as long short-term memory can alleviate this further. </p>
<p>Finally, :numref:<code>fig_rnn_bptt</code> shows 
that the objective function <span class="arithmatex">\(L\)</span> 
depends on model parameters <span class="arithmatex">\(\mathbf{W}_\textrm{hx}\)</span> and <span class="arithmatex">\(\mathbf{W}_\textrm{hh}\)</span>
in the hidden layer via hidden states
<span class="arithmatex">\(\mathbf{h}_1, \ldots, \mathbf{h}_T\)</span>.
To compute gradients with respect to such parameters
<span class="arithmatex">\(\partial L / \partial \mathbf{W}_\textrm{hx} \in \mathbb{R}^{h \times d}\)</span> and <span class="arithmatex">\(\partial L / \partial \mathbf{W}_\textrm{hh} \in \mathbb{R}^{h \times h}\)</span>,
we apply the chain rule giving</p>
<div class="arithmatex">\[
\begin{aligned}
\frac{\partial L}{\partial \mathbf{W}_\textrm{hx}}
&amp;= \sum_{t=1}^T \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{h}_t}, \frac{\partial \mathbf{h}_t}{\partial \mathbf{W}_\textrm{hx}}\right)
= \sum_{t=1}^T \frac{\partial L}{\partial \mathbf{h}_t} \mathbf{x}_t^\top,\\
\frac{\partial L}{\partial \mathbf{W}_\textrm{hh}}
&amp;= \sum_{t=1}^T \textrm{prod}\left(\frac{\partial L}{\partial \mathbf{h}_t}, \frac{\partial \mathbf{h}_t}{\partial \mathbf{W}_\textrm{hh}}\right)
= \sum_{t=1}^T \frac{\partial L}{\partial \mathbf{h}_t} \mathbf{h}_{t-1}^\top,
\end{aligned}
\]</div>
<p>where <span class="arithmatex">\(\partial L/\partial \mathbf{h}_t\)</span>
which is recurrently computed by
:eqref:<code>eq_bptt_partial_L_hT_final_step</code>
and :eqref:<code>eq_bptt_partial_L_ht_recur</code>
is the key quantity that affects the numerical stability.</p>
<p>Since backpropagation through time is the application of backpropagation in RNNs,
as we have explained in :numref:<code>sec_backprop</code>,
training RNNs alternates forward propagation with
backpropagation through time.
Moreover, backpropagation through time
computes and stores the above gradients in turn.
Specifically, stored intermediate values
are reused to avoid duplicate calculations,
such as storing <span class="arithmatex">\(\partial L/\partial \mathbf{h}_t\)</span>
to be used in computation of both <span class="arithmatex">\(\partial L / \partial \mathbf{W}_\textrm{hx}\)</span> 
and <span class="arithmatex">\(\partial L / \partial \mathbf{W}_\textrm{hh}\)</span>.</p>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">⚓︎</a></h2>
<p>Backpropagation through time is merely an application of backpropagation to sequence models with a hidden state.
Truncation, such as regular or randomized, is needed for computational convenience and numerical stability.
High powers of matrices can lead to divergent or vanishing eigenvalues. This manifests itself in the form of exploding or vanishing gradients.
For efficient computation, intermediate values are cached during backpropagation through time.</p>
<h2 id="exercises">Exercises<a class="headerlink" href="#exercises" title="Permanent link">⚓︎</a></h2>
<ol>
<li>Assume that we have a symmetric matrix <span class="arithmatex">\(\mathbf{M} \in \mathbb{R}^{n \times n}\)</span> with eigenvalues <span class="arithmatex">\(\lambda_i\)</span> whose corresponding eigenvectors are <span class="arithmatex">\(\mathbf{v}_i\)</span> (<span class="arithmatex">\(i = 1, \ldots, n\)</span>). Without loss of generality, assume that they are ordered in the order <span class="arithmatex">\(|\lambda_i| \geq |\lambda_{i+1}|\)</span>. </li>
<li>Show that <span class="arithmatex">\(\mathbf{M}^k\)</span> has eigenvalues <span class="arithmatex">\(\lambda_i^k\)</span>.</li>
<li>Prove that for a random vector <span class="arithmatex">\(\mathbf{x} \in \mathbb{R}^n\)</span>, with high probability <span class="arithmatex">\(\mathbf{M}^k \mathbf{x}\)</span> will be very much aligned with the eigenvector <span class="arithmatex">\(\mathbf{v}_1\)</span> 
of <span class="arithmatex">\(\mathbf{M}\)</span>. Formalize this statement.</li>
<li>What does the above result mean for gradients in RNNs?</li>
<li>Besides gradient clipping, can you think of any other methods to cope with gradient explosion in recurrent neural networks?</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/334">Discussions</a></p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../" class="md-footer__link md-footer__link--prev" aria-label="上一页: Recurrent Neural Networks">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Recurrent Neural Networks
              </div>
            </div>
          </a>
        
        
          
          <a href="../language-model/" class="md-footer__link md-footer__link--next" aria-label="下一页: Language Models">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Language Models
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>