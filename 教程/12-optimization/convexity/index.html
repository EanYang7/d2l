
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《动手学深度学习》">
      
      
        <meta name="author" content="Ean Yang">
      
      
        <link rel="canonical" href="https://eanyang7.github.io/d2l/%E6%95%99%E7%A8%8B/12-optimization/convexity/">
      
      
        <link rel="prev" href="../adam/">
      
      
        <link rel="next" href="../gd/">
      
      
      <link rel="icon" href="../../../assets/favicon.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.12">
    
    
      
        <title>Convexity - 动手学深度学习 Dive into Deep Learning#</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.fad675c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#convexity" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-header__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            动手学深度学习 Dive into Deep Learning#
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Convexity
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="red" data-md-color-accent="deep-purple"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="red"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="分享" aria-label="分享" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
  教程

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-tabs__link">
          
  
  练习

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="动手学深度学习 Dive into Deep Learning#" class="md-nav__button md-logo" aria-label="动手学深度学习 Dive into Deep Learning#" data-md-component="logo">
      
  <img src="../../../assets/logo.jpg" alt="logo">

    </a>
    动手学深度学习 Dive into Deep Learning#
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/d2l" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
  </div>
  <div class="md-source__repository">
    github仓库
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    教程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            教程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../01-Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01-介绍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../_Notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    符号
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../02-preliminaries/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    02 preliminaries
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../03-linear-regression/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    03 linear regression
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../04-linear-classification/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    04 linear classification
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../05-multilayer-perceptrons/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    05 multilayer perceptrons
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../06-builders-guide/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    06 builders guide
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../07-convolutional-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    07 convolutional modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../08-convolutional-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    08 convolutional neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../09-recurrent-neural-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    09 recurrent neural networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../10-recurrent-modern/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    10 recurrent modern
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../11-attention-mechanisms-and-transformers/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    11 attention mechanisms and transformers
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_15" checked>
        
          
          <label class="md-nav__link" for="__nav_2_15" id="__nav_2_15_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    12 optimization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_15_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_15">
            <span class="md-nav__icon md-icon"></span>
            12 optimization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimization Algorithms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../adadelta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adadelta
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../adagrad/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adagrad
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../adam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adam
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Convexity
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Convexity
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#definitions" class="md-nav__link">
    <span class="md-ellipsis">
      Definitions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Definitions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convex-sets" class="md-nav__link">
    <span class="md-ellipsis">
      Convex Sets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convex-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Convex Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jensens-inequality" class="md-nav__link">
    <span class="md-ellipsis">
      Jensen's Inequality
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#properties" class="md-nav__link">
    <span class="md-ellipsis">
      Properties
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Properties">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#local-minima-are-global-minima" class="md-nav__link">
    <span class="md-ellipsis">
      Local Minima Are Global Minima
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#below-sets-of-convex-functions-are-convex" class="md-nav__link">
    <span class="md-ellipsis">
      Below Sets of Convex Functions Are Convex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convexity-and-second-derivatives" class="md-nav__link">
    <span class="md-ellipsis">
      Convexity and Second Derivatives
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#constraints" class="md-nav__link">
    <span class="md-ellipsis">
      Constraints
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Constraints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lagrangian" class="md-nav__link">
    <span class="md-ellipsis">
      Lagrangian
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#penalties" class="md-nav__link">
    <span class="md-ellipsis">
      Penalties
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#projections" class="md-nav__link">
    <span class="md-ellipsis">
      Projections
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../gd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradient Descent
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../lr-scheduler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning Rate Scheduling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../minibatch-sgd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Minibatch Stochastic Gradient Descent
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../momentum/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Momentum
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../optimization-intro/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimization and Deep Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../rmsprop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RMSProp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../sgd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stochastic Gradient Descent
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../13-computational-performance/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    13 computational performance
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../14-computer-vision/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    14 computer vision
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../15-natural-language-processing-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    15 natural language processing pretraining
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../16-natural-language-processing-applications/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    16 natural language processing applications
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../17-reinforcement-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    17 reinforcement learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../18-gaussian-processes/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    18 gaussian processes
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../19-hyperparameter-optimization/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    19 hyperparameter optimization
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../20-generative-adversarial-networks/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    20 generative adversarial networks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../21-recommender-systems/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    21 recommender systems
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../22-appendix-mathematics-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    22 appendix mathematics for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../23-appendix-tools-for-deep-learning/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    23 appendix tools for deep learning
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../contrib/fasttext-pretraining/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Contrib
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    练习
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            练习
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E7%BB%83%E4%B9%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    动手学深度学习习题解答
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch02
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch03/ch03/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch03
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch04/ch04/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch04
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch05/ch05/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch05
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch06/ch06/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch06
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch07/ch07/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch07
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch08/ch08/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch08
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch09/ch09/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch09
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch10/ch10/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch10
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch11/ch11/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch11
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch12/ch12/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch12
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch13/ch13/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch13
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch14/ch14/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch14
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/ch15/ch15/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Ch15
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    
  
  
    <a href="../../../%E7%BB%83%E4%B9%A0/notebooks/ch02/ch02/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    Notebooks
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#definitions" class="md-nav__link">
    <span class="md-ellipsis">
      Definitions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Definitions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#convex-sets" class="md-nav__link">
    <span class="md-ellipsis">
      Convex Sets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convex-functions" class="md-nav__link">
    <span class="md-ellipsis">
      Convex Functions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#jensens-inequality" class="md-nav__link">
    <span class="md-ellipsis">
      Jensen's Inequality
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#properties" class="md-nav__link">
    <span class="md-ellipsis">
      Properties
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Properties">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#local-minima-are-global-minima" class="md-nav__link">
    <span class="md-ellipsis">
      Local Minima Are Global Minima
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#below-sets-of-convex-functions-are-convex" class="md-nav__link">
    <span class="md-ellipsis">
      Below Sets of Convex Functions Are Convex
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convexity-and-second-derivatives" class="md-nav__link">
    <span class="md-ellipsis">
      Convexity and Second Derivatives
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#constraints" class="md-nav__link">
    <span class="md-ellipsis">
      Constraints
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Constraints">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#lagrangian" class="md-nav__link">
    <span class="md-ellipsis">
      Lagrangian
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#penalties" class="md-nav__link">
    <span class="md-ellipsis">
      Penalties
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#projections" class="md-nav__link">
    <span class="md-ellipsis">
      Projections
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercises" class="md-nav__link">
    <span class="md-ellipsis">
      Exercises
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/12-optimization/convexity.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/d2l/tree/main/docs/教程/12-optimization/convexity.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="convexity">Convexity<a class="headerlink" href="#convexity" title="Permanent link">⚓︎</a></h1>
<p>:label:<code>sec_convexity</code></p>
<p>Convexity plays a vital role in the design of optimization algorithms. 
This is largely due to the fact that it is much easier to analyze and test algorithms in such a context. 
In other words,
if the algorithm performs poorly even in the convex setting,
typically we should not hope to see great results otherwise. 
Furthermore, even though the optimization problems in deep learning are generally nonconvex, they often exhibit some properties of convex ones near local minima. This can lead to exciting new optimization variants such as :cite:<code>Izmailov.Podoprikhin.Garipov.ea.2018</code>.</p>
<div class="input highlight"><pre><span></span><code><span class="c1">#@tab mxnet</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">mxnet</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">np</span><span class="p">,</span> <span class="n">npx</span>
<span class="n">npx</span><span class="o">.</span><span class="n">set_np</span><span class="p">()</span>
</code></pre></div>
<div class="input highlight"><pre><span></span><code><span class="c1">#@tab pytorch</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>
<span class="kn">import</span> <span class="nn">torch</span>
</code></pre></div>
<div class="input highlight"><pre><span></span><code><span class="c1">#@tab tensorflow</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</code></pre></div>
<h2 id="definitions">Definitions<a class="headerlink" href="#definitions" title="Permanent link">⚓︎</a></h2>
<p>Before convex analysis,
we need to define <em>convex sets</em> and <em>convex functions</em>.
They lead to mathematical tools that are commonly applied to machine learning.</p>
<h3 id="convex-sets">Convex Sets<a class="headerlink" href="#convex-sets" title="Permanent link">⚓︎</a></h3>
<p>Sets are the basis of convexity. Simply put, a set <span class="arithmatex">\(\mathcal{X}\)</span> in a vector space is <em>convex</em> if for any <span class="arithmatex">\(a, b \in \mathcal{X}\)</span> the line segment connecting <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> is also in <span class="arithmatex">\(\mathcal{X}\)</span>. In mathematical terms this means that for all <span class="arithmatex">\(\lambda \in [0, 1]\)</span> we have</p>
<div class="arithmatex">\[\lambda  a + (1-\lambda)  b \in \mathcal{X} \textrm{ whenever } a, b \in \mathcal{X}.\]</div>
<p>This sounds a bit abstract. Consider :numref:<code>fig_pacman</code>. The first set is not convex since there exist line segments that are not contained in it.
The other two sets suffer no such problem.</p>
<p><img alt="The first set is nonconvex and the other two are convex." src="../../img/pacman.svg" />
:label:<code>fig_pacman</code></p>
<p>Definitions on their own are not particularly useful unless you can do something with them.
In this case we can look at intersections as shown in :numref:<code>fig_convex_intersect</code>.
Assume that <span class="arithmatex">\(\mathcal{X}\)</span> and <span class="arithmatex">\(\mathcal{Y}\)</span> are convex sets. Then <span class="arithmatex">\(\mathcal{X} \cap \mathcal{Y}\)</span> is also convex. To see this, consider any <span class="arithmatex">\(a, b \in \mathcal{X} \cap \mathcal{Y}\)</span>. Since <span class="arithmatex">\(\mathcal{X}\)</span> and <span class="arithmatex">\(\mathcal{Y}\)</span> are convex, the line segments connecting <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> are contained in both <span class="arithmatex">\(\mathcal{X}\)</span> and <span class="arithmatex">\(\mathcal{Y}\)</span>. Given that, they also need to be contained in <span class="arithmatex">\(\mathcal{X} \cap \mathcal{Y}\)</span>, thus proving our theorem.</p>
<p><img alt="The intersection between two convex sets is convex." src="../../img/convex-intersect.svg" />
:label:<code>fig_convex_intersect</code></p>
<p>We can strengthen this result with little effort: given convex sets <span class="arithmatex">\(\mathcal{X}_i\)</span>, their intersection <span class="arithmatex">\(\cap_{i} \mathcal{X}_i\)</span> is convex.
To see that the converse is not true, consider two disjoint sets <span class="arithmatex">\(\mathcal{X} \cap \mathcal{Y} = \emptyset\)</span>. Now pick <span class="arithmatex">\(a \in \mathcal{X}\)</span> and <span class="arithmatex">\(b \in \mathcal{Y}\)</span>. The line segment in :numref:<code>fig_nonconvex</code> connecting <span class="arithmatex">\(a\)</span> and <span class="arithmatex">\(b\)</span> needs to contain some part that is neither in <span class="arithmatex">\(\mathcal{X}\)</span> nor in <span class="arithmatex">\(\mathcal{Y}\)</span>, since we assumed that <span class="arithmatex">\(\mathcal{X} \cap \mathcal{Y} = \emptyset\)</span>. Hence the line segment is not in <span class="arithmatex">\(\mathcal{X} \cup \mathcal{Y}\)</span> either, thus proving that in general unions of convex sets need not be convex.</p>
<p><img alt="The union of two convex sets need not be convex." src="../../img/nonconvex.svg" />
:label:<code>fig_nonconvex</code></p>
<p>Typically the problems in deep learning are defined on convex sets. For instance, <span class="arithmatex">\(\mathbb{R}^d\)</span>,
the set of <span class="arithmatex">\(d\)</span>-dimensional vectors of real numbers,
is a convex set (after all, the line between any two points in <span class="arithmatex">\(\mathbb{R}^d\)</span> remains in <span class="arithmatex">\(\mathbb{R}^d\)</span>). In some cases we work with variables of bounded length, such as balls of radius <span class="arithmatex">\(r\)</span> as defined by <span class="arithmatex">\(\{\mathbf{x} | \mathbf{x} \in \mathbb{R}^d \textrm{ and } \|\mathbf{x}\| \leq r\}\)</span>.</p>
<h3 id="convex-functions">Convex Functions<a class="headerlink" href="#convex-functions" title="Permanent link">⚓︎</a></h3>
<p>Now that we have convex sets we can introduce <em>convex functions</em> <span class="arithmatex">\(f\)</span>.
Given a convex set <span class="arithmatex">\(\mathcal{X}\)</span>, a function <span class="arithmatex">\(f: \mathcal{X} \to \mathbb{R}\)</span> is <em>convex</em> if for all <span class="arithmatex">\(x, x' \in \mathcal{X}\)</span> and for all <span class="arithmatex">\(\lambda \in [0, 1]\)</span> we have</p>
<div class="arithmatex">\[\lambda f(x) + (1-\lambda) f(x') \geq f(\lambda x + (1-\lambda) x').\]</div>
<p>To illustrate this let's plot a few functions and check which ones satisfy the requirement.
Below we define a few functions, both convex and nonconvex.</p>
<div class="input highlight"><pre><span></span><code><span class="c1">#@tab all</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># Convex</span>
<span class="n">g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>  <span class="c1"># Nonconvex</span>
<span class="n">h</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>  <span class="c1"># Convex</span>

<span class="n">x</span><span class="p">,</span> <span class="n">segment</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span> <span class="n">d2l</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">use_svg_display</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">func</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">[</span><span class="n">f</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">]):</span>
    <span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">segment</span><span class="p">],</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">func</span><span class="p">(</span><span class="n">segment</span><span class="p">)],</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</code></pre></div>
<p>As expected, the cosine function is <em>nonconvex</em>, whereas the parabola and the exponential function are. Note that the requirement that <span class="arithmatex">\(\mathcal{X}\)</span> is a convex set is necessary for the condition to make sense. Otherwise the outcome of <span class="arithmatex">\(f(\lambda x + (1-\lambda) x')\)</span> might not be well defined.</p>
<h3 id="jensens-inequality">Jensen's Inequality<a class="headerlink" href="#jensens-inequality" title="Permanent link">⚓︎</a></h3>
<p>Given a convex function <span class="arithmatex">\(f\)</span>,
one of the most useful mathematical tools
is <em>Jensen's inequality</em>.
It amounts to a generalization of the definition of convexity:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\sum_i \alpha_i f(x_i)  \geq f\left(\sum_i \alpha_i x_i\right)    \textrm{ and }    E_X[f(X)]  \geq f\left(E_X[X]\right),\)</span>\)</span>
:eqlabel:<code>eq_jensens-inequality</code></p>
<p>where <span class="arithmatex">\(\alpha_i\)</span> are nonnegative real numbers such that <span class="arithmatex">\(\sum_i \alpha_i = 1\)</span> and <span class="arithmatex">\(X\)</span> is a random variable.
In other words, the expectation of a convex function is no less than the convex function of an expectation, where the latter is usually a simpler expression. 
To prove the first inequality we repeatedly apply the definition of convexity to one term in the sum at a time.</p>
<p>One of the common applications of Jensen's inequality is
to bound a more complicated expression by a simpler one.
For example,
its application can be
with regard to the log-likelihood of partially observed random variables. That is, we use</p>
<div class="arithmatex">\[E_{Y \sim P(Y)}[-\log P(X \mid Y)] \geq -\log P(X),\]</div>
<p>since <span class="arithmatex">\(\int P(Y) P(X \mid Y) dY = P(X)\)</span>.
This can be used in variational methods. Here <span class="arithmatex">\(Y\)</span> is typically the unobserved random variable, <span class="arithmatex">\(P(Y)\)</span> is the best guess of how it might be distributed, and <span class="arithmatex">\(P(X)\)</span> is the distribution with <span class="arithmatex">\(Y\)</span> integrated out. For instance, in clustering <span class="arithmatex">\(Y\)</span> might be the cluster labels and <span class="arithmatex">\(P(X \mid Y)\)</span> is the generative model when applying cluster labels.</p>
<h2 id="properties">Properties<a class="headerlink" href="#properties" title="Permanent link">⚓︎</a></h2>
<p>Convex functions have many useful properties. We describe a few commonly-used ones below.</p>
<h3 id="local-minima-are-global-minima">Local Minima Are Global Minima<a class="headerlink" href="#local-minima-are-global-minima" title="Permanent link">⚓︎</a></h3>
<p>First and foremost, the local minima of convex functions are also the global minima. 
We can prove it by contradiction as follows.</p>
<p>Consider a convex function <span class="arithmatex">\(f\)</span> defined on a convex set <span class="arithmatex">\(\mathcal{X}\)</span>.
Suppose that <span class="arithmatex">\(x^{\ast} \in \mathcal{X}\)</span> is a local minimum:
there exists a small positive value <span class="arithmatex">\(p\)</span> so that for <span class="arithmatex">\(x \in \mathcal{X}\)</span> that satisfies <span class="arithmatex">\(0 &lt; |x - x^{\ast}| \leq p\)</span> we have <span class="arithmatex">\(f(x^{\ast}) &lt; f(x)\)</span>.</p>
<p>Assume that the local minimum <span class="arithmatex">\(x^{\ast}\)</span>
is not the global minimum of <span class="arithmatex">\(f\)</span>:
there exists <span class="arithmatex">\(x' \in \mathcal{X}\)</span> for which <span class="arithmatex">\(f(x') &lt; f(x^{\ast})\)</span>. 
There also exists 
<span class="arithmatex">\(\lambda \in [0, 1)\)</span> such as <span class="arithmatex">\(\lambda = 1 - \frac{p}{|x^{\ast} - x'|}\)</span>
so that
<span class="arithmatex">\(0 &lt; |\lambda x^{\ast} + (1-\lambda) x' - x^{\ast}| \leq p\)</span>. </p>
<p>However,
according to the definition of convex functions, we have</p>
<div class="arithmatex">\[\begin{aligned}
    f(\lambda x^{\ast} + (1-\lambda) x') &amp;\leq \lambda f(x^{\ast}) + (1-\lambda) f(x') \\
    &amp;&lt; \lambda f(x^{\ast}) + (1-\lambda) f(x^{\ast}) \\
    &amp;= f(x^{\ast}),
\end{aligned}\]</div>
<p>which contradicts with our statement that <span class="arithmatex">\(x^{\ast}\)</span> is a local minimum.
Therefore, there does not exist <span class="arithmatex">\(x' \in \mathcal{X}\)</span> for which <span class="arithmatex">\(f(x') &lt; f(x^{\ast})\)</span>. The local minimum <span class="arithmatex">\(x^{\ast}\)</span> is also the global minimum.</p>
<p>For instance, the convex function <span class="arithmatex">\(f(x) = (x-1)^2\)</span> has a local minimum at <span class="arithmatex">\(x=1\)</span>, which is also the global minimum.</p>
<div class="input highlight"><pre><span></span><code><span class="c1">#@tab all</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">set_figsize</span><span class="p">()</span>
<span class="n">d2l</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">segment</span><span class="p">],</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">f</span><span class="p">(</span><span class="n">segment</span><span class="p">)],</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;f(x)&#39;</span><span class="p">)</span>
</code></pre></div>
<p>The fact that the local minima for convex functions are also the global minima is very convenient. 
It means that if we minimize functions we cannot "get stuck". 
Note, though, that this does not mean that there cannot be more than one global minimum or that there might even exist one. For instance, the function <span class="arithmatex">\(f(x) = \mathrm{max}(|x|-1, 0)\)</span> attains its minimum value over the interval <span class="arithmatex">\([-1, 1]\)</span>. Conversely, the function <span class="arithmatex">\(f(x) = \exp(x)\)</span> does not attain a minimum value on <span class="arithmatex">\(\mathbb{R}\)</span>: for <span class="arithmatex">\(x \to -\infty\)</span> it asymptotes to <span class="arithmatex">\(0\)</span>, but there is no <span class="arithmatex">\(x\)</span> for which <span class="arithmatex">\(f(x) = 0\)</span>.</p>
<h3 id="below-sets-of-convex-functions-are-convex">Below Sets of Convex Functions Are Convex<a class="headerlink" href="#below-sets-of-convex-functions-are-convex" title="Permanent link">⚓︎</a></h3>
<p>We can conveniently 
define convex sets 
via <em>below sets</em> of convex functions.
Concretely,
given a convex function <span class="arithmatex">\(f\)</span> defined on a convex set <span class="arithmatex">\(\mathcal{X}\)</span>,
any below set</p>
<div class="arithmatex">\[\mathcal{S}_b \stackrel{\textrm{def}}{=} \{x | x \in \mathcal{X} \textrm{ and } f(x) \leq b\}\]</div>
<p>is convex. </p>
<p>Let's prove this quickly. Recall that for any <span class="arithmatex">\(x, x' \in \mathcal{S}_b\)</span> we need to show that <span class="arithmatex">\(\lambda x + (1-\lambda) x' \in \mathcal{S}_b\)</span> as long as <span class="arithmatex">\(\lambda \in [0, 1]\)</span>. 
Since <span class="arithmatex">\(f(x) \leq b\)</span> and <span class="arithmatex">\(f(x') \leq b\)</span>,
by the definition of convexity we have </p>
<div class="arithmatex">\[f(\lambda x + (1-\lambda) x') \leq \lambda f(x) + (1-\lambda) f(x') \leq b.\]</div>
<h3 id="convexity-and-second-derivatives">Convexity and Second Derivatives<a class="headerlink" href="#convexity-and-second-derivatives" title="Permanent link">⚓︎</a></h3>
<p>Whenever the second derivative of a function <span class="arithmatex">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> exists it is very easy to check whether <span class="arithmatex">\(f\)</span> is convex. 
All we need to do is check whether the Hessian of <span class="arithmatex">\(f\)</span> is positive semidefinite: <span class="arithmatex">\(\nabla^2f \succeq 0\)</span>, i.e., 
denoting the Hessian matrix <span class="arithmatex">\(\nabla^2f\)</span> by <span class="arithmatex">\(\mathbf{H}\)</span>,
<span class="arithmatex">\(\mathbf{x}^\top \mathbf{H} \mathbf{x} \geq 0\)</span>
for all <span class="arithmatex">\(\mathbf{x} \in \mathbb{R}^n\)</span>.
For instance, the function <span class="arithmatex">\(f(\mathbf{x}) = \frac{1}{2} \|\mathbf{x}\|^2\)</span> is convex since <span class="arithmatex">\(\nabla^2 f = \mathbf{1}\)</span>, i.e., its Hessian is an identity matrix.</p>
<p>Formally, a twice-differentiable one-dimensional function <span class="arithmatex">\(f: \mathbb{R} \rightarrow \mathbb{R}\)</span> is convex
if and only if its second derivative <span class="arithmatex">\(f'' \geq 0\)</span>. For any twice-differentiable multidimensional function <span class="arithmatex">\(f: \mathbb{R}^{n} \rightarrow \mathbb{R}\)</span>,
it is convex if and only if its Hessian <span class="arithmatex">\(\nabla^2f \succeq 0\)</span>.</p>
<p>First, we need to prove the one-dimensional case.
To see that 
convexity of <span class="arithmatex">\(f\)</span> implies 
<span class="arithmatex">\(f'' \geq 0\)</span>  we use the fact that</p>
<div class="arithmatex">\[\frac{1}{2} f(x + \epsilon) + \frac{1}{2} f(x - \epsilon) \geq f\left(\frac{x + \epsilon}{2} + \frac{x - \epsilon}{2}\right) = f(x).\]</div>
<p>Since the second derivative is given by the limit over finite differences it follows that</p>
<div class="arithmatex">\[f''(x) = \lim_{\epsilon \to 0} \frac{f(x+\epsilon) + f(x - \epsilon) - 2f(x)}{\epsilon^2} \geq 0.\]</div>
<p>To see that 
<span class="arithmatex">\(f'' \geq 0\)</span> implies that <span class="arithmatex">\(f\)</span> is convex
we use the fact that <span class="arithmatex">\(f'' \geq 0\)</span> implies that <span class="arithmatex">\(f'\)</span> is a monotonically nondecreasing function. Let <span class="arithmatex">\(a &lt; x &lt; b\)</span> be three points in <span class="arithmatex">\(\mathbb{R}\)</span>,
where <span class="arithmatex">\(x = (1-\lambda)a + \lambda b\)</span> and <span class="arithmatex">\(\lambda \in (0, 1)\)</span>.
According to the mean value theorem,
there exist <span class="arithmatex">\(\alpha \in [a, x]\)</span> and <span class="arithmatex">\(\beta \in [x, b]\)</span>
such that</p>
<div class="arithmatex">\[f'(\alpha) = \frac{f(x) - f(a)}{x-a} \textrm{ and } f'(\beta) = \frac{f(b) - f(x)}{b-x}.\]</div>
<p>By monotonicity <span class="arithmatex">\(f'(\beta) \geq f'(\alpha)\)</span>, hence</p>
<div class="arithmatex">\[\frac{x-a}{b-a}f(b) + \frac{b-x}{b-a}f(a) \geq f(x).\]</div>
<p>Since <span class="arithmatex">\(x = (1-\lambda)a + \lambda b\)</span>,
we have</p>
<div class="arithmatex">\[\lambda f(b) + (1-\lambda)f(a) \geq f((1-\lambda)a + \lambda b),\]</div>
<p>thus proving convexity.</p>
<p>Second, we need a lemma before 
proving the multidimensional case:
<span class="arithmatex">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span>
is convex if and only if for all <span class="arithmatex">\(\mathbf{x}, \mathbf{y} \in \mathbb{R}^n\)</span></p>
<div class="arithmatex">\[g(z) \stackrel{\textrm{def}}{=} f(z \mathbf{x} + (1-z)  \mathbf{y}) \textrm{ where } z \in [0,1]\]</div>
<p>is convex.</p>
<p>To prove that convexity of <span class="arithmatex">\(f\)</span> implies that <span class="arithmatex">\(g\)</span> is convex,
we can show that for all <span class="arithmatex">\(a, b, \lambda \in [0, 1]\)</span> (thus
<span class="arithmatex">\(0 \leq \lambda a + (1-\lambda) b \leq 1\)</span>)</p>
<div class="arithmatex">\[\begin{aligned} &amp;g(\lambda a + (1-\lambda) b)\\
=&amp;f\left(\left(\lambda a + (1-\lambda) b\right)\mathbf{x} + \left(1-\lambda a - (1-\lambda) b\right)\mathbf{y} \right)\\
=&amp;f\left(\lambda \left(a \mathbf{x} + (1-a)  \mathbf{y}\right)  + (1-\lambda) \left(b \mathbf{x} + (1-b)  \mathbf{y}\right) \right)\\
\leq&amp; \lambda f\left(a \mathbf{x} + (1-a)  \mathbf{y}\right)  + (1-\lambda) f\left(b \mathbf{x} + (1-b)  \mathbf{y}\right) \\
=&amp; \lambda g(a) + (1-\lambda) g(b).
\end{aligned}\]</div>
<p>To prove the converse,
we can show that for 
all <span class="arithmatex">\(\lambda \in [0, 1]\)</span> </p>
<div class="arithmatex">\[\begin{aligned} &amp;f(\lambda \mathbf{x} + (1-\lambda) \mathbf{y})\\
=&amp;g(\lambda \cdot 1 + (1-\lambda) \cdot 0)\\
\leq&amp; \lambda g(1)  + (1-\lambda) g(0) \\
=&amp; \lambda f(\mathbf{x}) + (1-\lambda) f(\mathbf{y}).
\end{aligned}\]</div>
<p>Finally,
using the lemma above and the result of the one-dimensional case,
the multidimensional case
can be proven as follows.
A multidimensional function <span class="arithmatex">\(f: \mathbb{R}^n \rightarrow \mathbb{R}\)</span> is convex
if and only if for all <span class="arithmatex">\(\mathbf{x}, \mathbf{y} \in \mathbb{R}^n\)</span> <span class="arithmatex">\(g(z) \stackrel{\textrm{def}}{=} f(z \mathbf{x} + (1-z)  \mathbf{y})\)</span>, where <span class="arithmatex">\(z \in [0,1]\)</span>,
is convex.
According to the one-dimensional case,
this holds if and only if
<span class="arithmatex">\(g'' = (\mathbf{x} - \mathbf{y})^\top \mathbf{H}(\mathbf{x} - \mathbf{y}) \geq 0\)</span> (<span class="arithmatex">\(\mathbf{H} \stackrel{\textrm{def}}{=} \nabla^2f\)</span>)
for all <span class="arithmatex">\(\mathbf{x}, \mathbf{y} \in \mathbb{R}^n\)</span>,
which is equivalent to <span class="arithmatex">\(\mathbf{H} \succeq 0\)</span>
per the definition of positive semidefinite matrices.</p>
<h2 id="constraints">Constraints<a class="headerlink" href="#constraints" title="Permanent link">⚓︎</a></h2>
<p>One of the nice properties of convex optimization is that it allows us to handle constraints efficiently. That is, it allows us to solve <em>constrained optimization</em> problems of the form:</p>
<div class="arithmatex">\[\begin{aligned} \mathop{\textrm{minimize~}}_{\mathbf{x}} &amp; f(\mathbf{x}) \\
    \textrm{ subject to } &amp; c_i(\mathbf{x}) \leq 0 \textrm{ for all } i \in \{1, \ldots, n\},
\end{aligned}\]</div>
<p>where <span class="arithmatex">\(f\)</span> is the objective and the functions <span class="arithmatex">\(c_i\)</span> are constraint functions. To see what this does consider the case where <span class="arithmatex">\(c_1(\mathbf{x}) = \|\mathbf{x}\|_2 - 1\)</span>. In this case the parameters <span class="arithmatex">\(\mathbf{x}\)</span> are constrained to the unit ball. If a second constraint is <span class="arithmatex">\(c_2(\mathbf{x}) = \mathbf{v}^\top \mathbf{x} + b\)</span>, then this corresponds to all <span class="arithmatex">\(\mathbf{x}\)</span> lying on a half-space. Satisfying both constraints simultaneously amounts to selecting a slice of a ball.</p>
<h3 id="lagrangian">Lagrangian<a class="headerlink" href="#lagrangian" title="Permanent link">⚓︎</a></h3>
<p>In general, solving a constrained optimization problem is difficult. One way of addressing it stems from physics with a rather simple intuition. Imagine a ball inside a box. The ball will roll to the place that is lowest and the forces of gravity will be balanced out with the forces that the sides of the box can impose on the ball. In short, the gradient of the objective function (i.e., gravity) will be offset by the gradient of the constraint function (the ball need to remain inside the box by virtue of the walls "pushing back"). 
Note that some constraints may not be active:
the walls that are not touched by the ball
will not be able to exert any force on the ball.</p>
<p>Skipping over the derivation of the <em>Lagrangian</em> <span class="arithmatex">\(L\)</span>,
the above reasoning
can be expressed via the following saddle point optimization problem:</p>
<div class="arithmatex">\[L(\mathbf{x}, \alpha_1, \ldots, \alpha_n) = f(\mathbf{x}) + \sum_{i=1}^n \alpha_i c_i(\mathbf{x}) \textrm{ where } \alpha_i \geq 0.\]</div>
<p>Here the variables <span class="arithmatex">\(\alpha_i\)</span> (<span class="arithmatex">\(i=1,\ldots,n\)</span>) are the so-called <em>Lagrange multipliers</em> that ensure that constraints are properly enforced. They are chosen just large enough to ensure that <span class="arithmatex">\(c_i(\mathbf{x}) \leq 0\)</span> for all <span class="arithmatex">\(i\)</span>. For instance, for any <span class="arithmatex">\(\mathbf{x}\)</span> where <span class="arithmatex">\(c_i(\mathbf{x}) &lt; 0\)</span> naturally, we'd end up picking <span class="arithmatex">\(\alpha_i = 0\)</span>. Moreover, this is a saddle point optimization problem where one wants to <em>maximize</em> <span class="arithmatex">\(L\)</span> with respect to all <span class="arithmatex">\(\alpha_i\)</span> and simultaneously <em>minimize</em> it with respect to <span class="arithmatex">\(\mathbf{x}\)</span>. There is a rich body of literature explaining how to arrive at the function <span class="arithmatex">\(L(\mathbf{x}, \alpha_1, \ldots, \alpha_n)\)</span>. For our purposes it is sufficient to know that the saddle point of <span class="arithmatex">\(L\)</span> is where the original constrained optimization problem is solved optimally.</p>
<h3 id="penalties">Penalties<a class="headerlink" href="#penalties" title="Permanent link">⚓︎</a></h3>
<p>One way of satisfying constrained optimization problems at least <em>approximately</em> is to adapt the Lagrangian <span class="arithmatex">\(L\)</span>. 
Rather than satisfying <span class="arithmatex">\(c_i(\mathbf{x}) \leq 0\)</span> we simply add <span class="arithmatex">\(\alpha_i c_i(\mathbf{x})\)</span> to the objective function <span class="arithmatex">\(f(x)\)</span>. This ensures that the constraints will not be violated too badly.</p>
<p>In fact, we have been using this trick all along. Consider weight decay in :numref:<code>sec_weight_decay</code>. In it we add <span class="arithmatex">\(\frac{\lambda}{2} \|\mathbf{w}\|^2\)</span> to the objective function to ensure that <span class="arithmatex">\(\mathbf{w}\)</span> does not grow too large. From the constrained optimization point of view we can see that this will ensure that <span class="arithmatex">\(\|\mathbf{w}\|^2 - r^2 \leq 0\)</span> for some radius <span class="arithmatex">\(r\)</span>. Adjusting the value of <span class="arithmatex">\(\lambda\)</span> allows us to vary the size of <span class="arithmatex">\(\mathbf{w}\)</span>.</p>
<p>In general, adding penalties is a good way of ensuring approximate constraint satisfaction. In practice this turns out to be much more robust than exact satisfaction. Furthermore, for nonconvex problems many of the properties that make the exact approach so appealing in the convex case (e.g., optimality) no longer hold.</p>
<h3 id="projections">Projections<a class="headerlink" href="#projections" title="Permanent link">⚓︎</a></h3>
<p>An alternative strategy for satisfying constraints is projections. Again, we encountered them before, e.g., when dealing with gradient clipping in :numref:<code>sec_rnn-scratch</code>. There we ensured that a gradient has length bounded by <span class="arithmatex">\(\theta\)</span> via</p>
<div class="arithmatex">\[\mathbf{g} \leftarrow \mathbf{g} \cdot \mathrm{min}(1, \theta/\|\mathbf{g}\|).\]</div>
<p>This turns out to be a <em>projection</em> of <span class="arithmatex">\(\mathbf{g}\)</span> onto the ball of radius <span class="arithmatex">\(\theta\)</span>. More generally, a projection on a convex set <span class="arithmatex">\(\mathcal{X}\)</span> is defined as</p>
<div class="arithmatex">\[\textrm{Proj}_\mathcal{X}(\mathbf{x}) = \mathop{\mathrm{argmin}}_{\mathbf{x}' \in \mathcal{X}} \|\mathbf{x} - \mathbf{x}'\|,\]</div>
<p>which is the closest point in <span class="arithmatex">\(\mathcal{X}\)</span> to <span class="arithmatex">\(\mathbf{x}\)</span>. </p>
<p><img alt="Convex Projections." src="../../img/projections.svg" />
:label:<code>fig_projections</code></p>
<p>The mathematical definition of projections may sound a bit abstract. :numref:<code>fig_projections</code> explains it somewhat more clearly. In it we have two convex sets, a circle and a diamond. 
Points inside both sets (yellow) remain unchanged during projections. 
Points outside both sets (black) are projected to 
the points inside the sets (red) that are closet to the original points (black).
While for <span class="arithmatex">\(\ell_2\)</span> balls this leaves the direction unchanged, this need not be the case in general, as can be seen in the case of the diamond.</p>
<p>One of the uses for convex projections is to compute sparse weight vectors. In this case we project weight vectors onto an <span class="arithmatex">\(\ell_1\)</span> ball,
which is a generalized version of the diamond case in :numref:<code>fig_projections</code>.</p>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">⚓︎</a></h2>
<p>In the context of deep learning the main purpose of convex functions is to motivate optimization algorithms and help us understand them in detail. In the following we will see how gradient descent and stochastic gradient descent can be derived accordingly.</p>
<ul>
<li>Intersections of convex sets are convex. Unions are not.</li>
<li>The expectation of a convex function is no less than the convex function of an expectation (Jensen's inequality).</li>
<li>A twice-differentiable function is convex if and only if its Hessian (a matrix of second derivatives) is positive semidefinite.</li>
<li>Convex constraints can be added via the Lagrangian. In practice we may simply add them with a penalty to the objective function.</li>
<li>Projections map to points in the convex set closest to the original points.</li>
</ul>
<h2 id="exercises">Exercises<a class="headerlink" href="#exercises" title="Permanent link">⚓︎</a></h2>
<ol>
<li>Assume that we want to verify convexity of a set by drawing all lines between points within the set and checking whether the lines are contained.<ol>
<li>Prove that it is sufficient to check only the points on the boundary.</li>
<li>Prove that it is sufficient to check only the vertices of the set.</li>
</ol>
</li>
<li>Denote by <span class="arithmatex">\(\mathcal{B}_p[r] \stackrel{\textrm{def}}{=} \{\mathbf{x} | \mathbf{x} \in \mathbb{R}^d \textrm{ and } \|\mathbf{x}\|_p \leq r\}\)</span> the ball of radius <span class="arithmatex">\(r\)</span> using the <span class="arithmatex">\(p\)</span>-norm. Prove that <span class="arithmatex">\(\mathcal{B}_p[r]\)</span> is convex for all <span class="arithmatex">\(p \geq 1\)</span>.</li>
<li>Given convex functions <span class="arithmatex">\(f\)</span> and <span class="arithmatex">\(g\)</span>, show that <span class="arithmatex">\(\mathrm{max}(f, g)\)</span> is convex, too. Prove that <span class="arithmatex">\(\mathrm{min}(f, g)\)</span> is not convex.</li>
<li>Prove that the normalization of the softmax function is convex. More specifically prove the convexity of
    <span class="arithmatex">\(f(x) = \log \sum_i \exp(x_i)\)</span>.</li>
<li>Prove that linear subspaces, i.e., <span class="arithmatex">\(\mathcal{X} = \{\mathbf{x} | \mathbf{W} \mathbf{x} = \mathbf{b}\}\)</span>, are convex sets.</li>
<li>Prove that in the case of linear subspaces with <span class="arithmatex">\(\mathbf{b} = \mathbf{0}\)</span> the projection <span class="arithmatex">\(\textrm{Proj}_\mathcal{X}\)</span> can be written as <span class="arithmatex">\(\mathbf{M} \mathbf{x}\)</span> for some matrix <span class="arithmatex">\(\mathbf{M}\)</span>.</li>
<li>Show that for  twice-differentiable convex functions <span class="arithmatex">\(f\)</span> we can write <span class="arithmatex">\(f(x + \epsilon) = f(x) + \epsilon f'(x) + \frac{1}{2} \epsilon^2 f''(x + \xi)\)</span> for some <span class="arithmatex">\(\xi \in [0, \epsilon]\)</span>.</li>
<li>Given a convex set <span class="arithmatex">\(\mathcal{X}\)</span> and two vectors <span class="arithmatex">\(\mathbf{x}\)</span> and <span class="arithmatex">\(\mathbf{y}\)</span>, prove that projections never increase distances, i.e., <span class="arithmatex">\(\|\mathbf{x} - \mathbf{y}\| \geq \|\textrm{Proj}_\mathcal{X}(\mathbf{x}) - \textrm{Proj}_\mathcal{X}(\mathbf{y})\|\)</span>.</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/350">Discussions</a></p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 25, 2023</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="页脚" >
        
          
          <a href="../adam/" class="md-footer__link md-footer__link--prev" aria-label="上一页: Adam">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                上一页
              </span>
              <div class="md-ellipsis">
                Adam
              </div>
            </div>
          </a>
        
        
          
          <a href="../gd/" class="md-footer__link md-footer__link--next" aria-label="下一页: Gradient Descent">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                下一页
              </span>
              <div class="md-ellipsis">
                Gradient Descent
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ean Yang
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/YQisme" target="_blank" rel="noopener" title="github主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://space.bilibili.com/244185393?spm_id_from=333.788.0.0" target="_blank" rel="noopener" title="b站主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://eanyang7.com" target="_blank" rel="noopener" title="个人主页" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M112 48a48 48 0 1 1 96 0 48 48 0 1 1-96 0zm40 304v128c0 17.7-14.3 32-32 32s-32-14.3-32-32V256.9l-28.6 47.6c-9.1 15.1-28.8 20-43.9 10.9s-20-28.8-10.9-43.9l58.3-97c17.4-28.9 48.6-46.6 82.3-46.6h29.7c33.7 0 64.9 17.7 82.3 46.6l58.3 97c9.1 15.1 4.2 34.8-10.9 43.9s-34.8 4.2-43.9-10.9L232 256.9V480c0 17.7-14.3 32-32 32s-32-14.3-32-32V352h-16z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.prune", "navigation.top", "toc.follow", "header.autohide", "navigation.footer", "search.suggest", "search.highlight", "search.share", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.6c14ae12.min.js"></script>
      
    
  </body>
</html>